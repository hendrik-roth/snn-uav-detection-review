title,DOI,year,screening-phase,decision,exclusion_reason,other_comments,source_database,duplicate_info,authors,abstract,url,venue
Cooperative task assignment of heterogeneous unmanned aerial vehicles for simultaneous multi-directional attack on a moving target,10.1016/j.engappai.2024.109595,2025,a,x,X1,,ACM,,"Shahid, Sami; Zhen, Ziyang; Javaid, Umair",,https://doi.org/10.1016/j.engappai.2024.109595,Eng. Appl. Artif. Intell.
Gyro: A Digital Spiking Neural Network Architecture for Multi-Sensory Data Analytics,10.1145/3444950.3444951,2021,a,x,X1,,ACM,,"Corradi, Federico; Adriaans, Guido; Stuijk, Sander","Unmanned Aerial Vehicles (UAVs) that interact with the physical world in real-time make use of a multitude of sensors and often execute deep neural network workloads for perceiving the state of the environment. To increase UAV’s operations, it is required to execute these workloads in the most power-efficient manner. Spiking Neural Networks (SNNs) have been proposed as an alternative solution for the execution of deep neural networks in an energy-efficient way. We introduce Gyro, a digital event-driven architecture capable of executing spiking neural networks. The architecture is tailored towards sensory fusion applications and it is optimized for Field-Programmable Gate Arrays (FPGAs). In hardware, we demonstrate the performance of a sensory fusion task using a public dataset of bi-temporal optical-radar data for pixel-wise crop classification. We achieve an accuracy of 99,7%, a peak throughput of 31,82 Giga Synaptic Operations per Second (GSOPS) while consuming 50 pico Joule / Synaptic Operation (pJ/SO).",https://doi.org/10.1145/3444950.3444951,Proceedings of the 2021 Drone Systems Engineering and Rapid Simulation and Performance Evaluation: Methods and Tools Proceedings
ST-FlowNet: An efficient Spiking Neural Network for event-based optical flow estimation,10.1016/j.neunet.2025.107730,2025,f,x,X4,optical flow prediction,ACM,,"Sun, Hongze; Wang, Jun; Cai, Wuque; Chen, Duo; Liao, Qianqian; He, Jiayi; Cui, Yan; Yao, Dezhong; Guo, Daqing",,https://doi.org/10.1016/j.neunet.2025.107730,Neural Netw.
Development of a Self-Regulating Evolving Spiking Neural Network for classification problem,10.1016/j.neucom.2015.07.086,2016,a,x,X4,medical images classification,ACM,,"Dora, S.; Subramanian, K.; Suresh, S.; Sundararajan, N.","This paper presents a new spiking neural network for pattern classification problems, referred to as the Self-Regulating Evolving Spiking Neural (SRESN) classifier, that regulates the learning process of the network. It uses a two layered spiking neural network and the input layer consists of receptive field neurons, which convert a real valued input to spikes using the population coding scheme without any delays. The output layer consists of leaky integrate-and-fire neurons. Since SRESN does not use any delays, the number of network parameters for SRESN is significantly lower than that used by other spiking neural networks, used in this study. During training, the learning algorithm for SRESN, automatically evolves neurons in the output layer based on the training data stream and the current knowledge stored in the network. Depending on the knowledge in the sample and the class specific knowledge stored in the network, it can choose to either add a neuron or update the network parameters or skip learning the sample resulting in self-regulation of the learning process. In case of neuron addition, the weights for the newly added neuron are initialized using a modified rank order scheme which facilitates SRESN for use in online/sequential as well as batch learning modes. The parameter update strategy in SRESN ensures that connections with non-zero postsynaptic potential at the time of the spike are alone updated which helps prevent over training. While evaluating the performance of SRESN, first a study is conducted to assess the impact of various parameters on its performance and establish guidelines to choose suitable values for these parameters. Next, the performance of SRESN, operating in batch mode, is compared with other spiking neural classifiers, including SpikeProp and MuSpiNN, for the UCI benchmark problems of Iris flower classification and Wisconsin breast cancer. Subsequently, the performance of SRESN in online and batch learning mode is compared with an evolving spiking neural classifier for five benchmark data sets from the UCI machine learning repository. Finally, SRESN is applied to solve the practical problem of Epilepsy detection. The performance comparison clearly indicates that SRESN provides a higher generalization accuracy using fewer network parameters.",https://doi.org/10.1016/j.neucom.2015.07.086,Neurocomput.
DCSNN: An Efficient and High-speed sEMG-based Transient-state Micro-gesture Recognition Method on Wearable Devices,10.1145/3729494,2025,f,x,X1,Section 5.2: application drone operation,ACM,,"Han, Youfang; Zhao, Wei; Gao, Ge; Chen, Xiangjin; Yin, Jiliang; Wang, Lin; Meng, Xin; Yu, Yang; Zhang, Tengxiang","Micro-gesture recognition using wearable devices is an important research topic in human-computer interaction. Surface electromyography (sEMG) is widely researched for gesture recognition due to its ability to capture muscle signals that precede actual gestures. Most existing methods are based on artificial neural networks (ANN), which may lead to high latency, high power consumption, and high memory usage when deployed on wearable devices. We propose a deep compressed spiking neural network (DCSNN) to address the challenges. The DCSNN can significantly reduce the inference power consumption and memory usage while improving recognition accuracy. In addition, we designed a linear method of action detection called leaky integrate-and-fire for transient-state action detection (TAD-LIF), which can improve the robustness of recognition systems effectively. To evaluate our method, we developed two lightweight sEMG wristbands respectively for two interaction modes, and collected two datasets from about 40 subjects. The experiment results show that DCSNN had a higher recognition accuracy than existing methods with values of 88.55% and 95.76% on the two datasets. In addition, its inference latency, power consumption, and memory usage are only about 0.4%, 0.05%, and 2% of those of popular convolutional neural network (CNN) methods. Our method enables precise, high-speed, and low-power micro-gesture recognition on a plethora of resource-constrained consumer-level intelligent wearable devices.",https://doi.org/10.1145/3729494,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.
3TFL-XLnet-CP: A Novel Transformer-Based Crop Yield Prediction Framework with Weighted Loss Based 3-Tier Feature Learning Model,10.1007/s42979-025-03778-9,2025,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Anoop, G. L.; Nandini, C.; Naresh, E.","The advancement of crop yield prediction through artificial intelligence (AI) has gained significant attention. However, the existing AI-based approaches for maximizing agricultural productivity, specifically in crop yield prediction, have not consistently delivered satisfactory results. In response to this challenge, we propose a novel framework named as Three Tier Feature Learning with XLnet based Crop Prediction (3TFL-XLnet-CP) that enhances agricultural productivity by accurately predicting crop yield. The 3TFL-XLnet-CP framework employs a three-tier feature learning approach in combination with the powerful XLnet transformer-based crop prediction model. The three-tier feature learning involves the integration of Spiking Neural Network (SNN), Graphical Neural Network (GNN), and Convolutional Neural Network (CNN) to extract distinct feature vectors from the preprocessed data. These feature vectors are then concatenated using Jaccard Similarity to measure their similarity score. Additionally, a weighted Loss function is introduced to optimize feature learning, further enhanced by a novel self-adaptive Spider Monkey Optimization algorithm (SASMO). The concatenated features are subsequently fed into the classification layer for making precise crop yield predictions. The proposed model is implemented using the Python platform and evaluated against existing models such as ANN, RNN, DNN, and BiLSTM. The comparison demonstrates the superiority of our proposed 3TFL-XLnet-CP framework in accurately predicting crop yield.",https://doi.org/10.1007/s42979-025-03778-9,SN Comput. Sci.
Disaster management with efficient user allocation using quantum-inspired cuckoo search and UAV-edge computing,10.1007/s10586-025-05453-3,2025,a,x,X1,,ACM,,"Reddy, Thandava Purandeswar; Teja, Gokarakonda Nikhil Sri Sai; Dayanand, Bhukya; Goud, A. Swamy; Balaji, Banavath Naik; Bhaumik, Gopa; Das, Bhabani Shankar","Efficient allocation of Internet of Things (IoT) devices and timely real-time data processing in disaster-affected areas pose significant challenges due to energy constraints, limited infrastructure, and the urgent need for rapid response. Unmanned Aerial Vehicles (UAVs), when integrated with Edge Computing (EC), offer a promising solution for collecting and processing data. In this paper, we propose a novel hashing-based quantum-inspired cuckoo search optimization (QICSO) algorithm to address key challenges in disaster management, including user allocation, processor allocation, energy consumption, and time delay factors. The QICSO algorithm is designed to optimize resource utilization by addressing key objectives such as minimizing energy consumption, reducing data processing delays, and improving the allocation rates of users and processors. A novel fitness function is formulated by considering these factors to ensure efficient disaster response. A novel representation of the quantum cuckoo and qubit has been developed, where quantum cuckoos are encoded and decoded using a novel hashing technique. The fitness function incorporates four objectives: user allocation rate, processor allocation rate, energy consumption, and delay. The proposed approach is simulated across multiple scenarios against the latest existing algorithms. Results demonstrate that the proposed algorithm significantly outperforms the compared methods. Additionally, statistical analyses, including analysis of variance (ANOVA) and the Friedman test, have been conducted. The Taguchi parametric statistical technique is employed to further evaluate performance. The simulation results indicate that QICSO surpassed existing approaches in terms of energy consumption by 18.3% and delay by 3.5%.",https://doi.org/10.1007/s10586-025-05453-3,Cluster Computing
S4-KD: A single step spiking SiamFC+ + for object tracking with knowledge distillation,10.1016/j.neunet.2025.107478,2025,f,x,X4,only tracking without target identification,ACM,,"Liu, Wenzhuo; Xiang, Shuiying; Zhang, Tao; Han, Yanan; Zhang, Yahui; Guo, Xingxing; Yu, Licun; Hao, Yue",,https://doi.org/10.1016/j.neunet.2025.107478,Neural Netw.
A Virtual Fence for Drones: Efficiently Detecting Propeller Blades with a DVXplorer Event Camera,10.1145/3546790.3546800,2022,f,x,X2,"MLP, no SNN, but neuromorphic camera",ACM,,"Stewart, Terrence; Drouin, Marc-Antoine; Picard, Michel; Djupkep Dizeu, Frank Billy; Orth, Anthony; Gagné, Guillaume","In previous work, we prototyped a portable drone detection system using a DAVIS 346 event camera and a Raspberry Pi 4, running in 5.14 W. Here, we expand on this work by switching to the higher-resolution DVXplorer and by including a small neural network classifier system. The resulting system improves the range at which drones can be recognized (from 9m to 19m). We also demonstrate our novel in-lab test system, capable of generating controlled training data across a wide variety of lighting and optical conditions. The new 100-neuron classification system runs at 100Hz with an accuracy of 98% on our field test and 96% on the in-lab test suite.",https://doi.org/10.1145/3546790.3546800,Proceedings of the International Conference on Neuromorphic Systems 2022
Edge-Cloud collaborative spatial perception and positioning system,10.1145/3773365.3773621,2025,f,x,X4,spatial perception for navigation,ACM,,"Wu, Sheng; Yang, Chunshan; Qin, Haodong; Wang, Shuaishuai; Xu, Qiyu; Cai, Yansong","Spatial perception and positioning technology significantly enhances users' perceptual experience of the real world by integrating virtual information with the physical environment. This technology has been widely applied across multiple industries, including warehousing, chemical engineering, education, and gaming. However, to foster the further development of spatial perception and positioning-related applications, a reasonable framework design is crucial. This paper proposes a spatial perception and positioning scheme for large-space fast-motion scenarios, which covers functional modules such as front-end rendering SDK, back-end positioning services, and cloud data processing. Additionally, the scheme introduces event cameras and spiking neural networks (SNN) to improve visual odometry calculation, loop closure detection, and other aspects, thereby enhancing system efficiency.",https://doi.org/10.1145/3773365.3773621,Proceedings of the 2025 8th International Conference on Computer Information Science and Artificial Intelligence
DMPNet: A lightweight remote sensing forest wildfire detection network based on multi-scale heterogeneous attention mechanism and dynamic scaling fusion strategy,10.1016/j.dsp.2025.105252,2025,t,x,X4,forest fire detection,ACM,,"Long, Yingping; Ding, Hongwei; Zhu, Yuanjing; Yang, Zhijun; Li, Bo",,https://doi.org/10.1016/j.dsp.2025.105252,Digit. Signal Process.
A Real-time Cooperative Optimization System for Photography Parameters Based on SNN Low-Power Margin Calculation,10.1145/3770445.3770496,2025,f,x,"X1,X4",No hint to uav detection,ACM,,"Hua, Peng","Industrial inspection and multimedia applications demand urgent improvements in energy efficiency and multi-device coordination for real-time image acquisition. Addressing the low efficiency and slow response of existing photographic parameter optimization schemes, this research proposes a real-time collaborative optimization system based on low-power computation via spiking neural networks. The system employs an event-driven spiking neural network architecture to process visual information, significantly reducing computational energy consumption. Combined with a low-power edge computing model, it enables dynamic management of energy budgets. Through a distributed collaborative decision-making mechanism, it supports real-time parameter negotiation and consistent adjustments across multiple devices. Test results demonstrate that the system reduces power consumption by 62.5% compared to traditional approaches in typical scenarios, while maintaining the parameter differences among multiple devices within 0.3 EV. This effectively enhances the energy efficiency and collaborative performance of photographic systems in complex environments, providing a viable technical solution for practical applications in distributed visual systems.",https://doi.org/10.1145/3770445.3770496,Proceedings of the 2025 International Conference on Generative AI and Digital Media Arts
Neuromorphic event-based recognition boosted by motion-aware learning,10.1016/j.neucom.2025.129678,2025,f,x,X4,,ACM,,"Liu, Yuhan; Deng, Yongjian; Xie, Bochen; Liu, Hai; Yang, Zhen; Li, Youfu",,https://doi.org/10.1016/j.neucom.2025.129678,Neurocomput.
A sequential learning algorithm for a spiking neural classifier,10.1016/j.asoc.2015.06.062,2015,f,x,X4,No hint to uav detection,ACM,,"Dora, S.; Suresh, S.; Sundararajan, N.","Graphical abstractOverview of the sequential learning algorithm for a spiking neural classifier. SLSNC consists of a two layered fully connected spiking neural network and a separate decision block. The input layer in the neural network encodes the presented real valued features into spike patterns consisting of varying amplitude and firing times. These spike patterns generated by the input layer neurons is the presynaptic input for the intermediate neurons which are modelled as 'Integrate-and-Fire' neurons. The decision block intercepts the output of the intermediate neurons and estimates the predicted class label according to the neuron which fires first. Display Omitted HighlightsLSNC automatically evolves the architecture.Real valued data is encoded using a 2-D encoding having spike amplitude and time.Sequential learning algorithm developed for SLSNC.Learning algorithm relies on computationally inexpensive operations. This paper presents a biologically inspired, sequential learning spiking neural classifier (SLSNC) for pattern classification problems. It consists of a two layered neural network and a separate decision block which estimates the predicted class label. Inspired by observations in the neuroscience literature, the input layer employs a new neuron model which converts real valued stimuli into spikes with varying amplitudes and firing times. The intermediate layer neurons are modeled as integrate-and-fire spiking neurons. The decision block identifies that intermediate neuron which fires first and returns the class label associated with that neuron as the predicted class label. The sequential learning algorithm for the spiking neural network automatically determines the network structure from the training samples and adapts its synaptic weights by long term potentiation and long term depression. Performance of SLSNC has been evaluated using a number of benchmark classification problems and the results have been compared with other well-known spiking neural network classifiers in the literature as well as with the standard support vector machine (SVM) with a Gaussian kernel and the fast learning Extreme Learning Machine (ELM) classifiers. The results clearly indicate that the described spiking neural network produces similar or better generalization performance with a smaller network.",https://doi.org/10.1016/j.asoc.2015.06.062,Appl. Soft Comput.
Drone-assisted automated plant diseases identification using spiking deep conventional neural learning,10.3233/AIC-210009,2021,t,x,X4,wrong detection task → plant disease detection,ACM,,"Demir, Kubilay; Tümen, Vedat","Detection and diagnosis of the plant diseases in the early stage significantly minimize yield losses. Image-based automated plant diseases identification (APDI) tools have started to been widely used in pest managements strategies. The current APDI systems rely on images captured in laboratory conditions, which hardens the usage of the APDI systems by smallholder farmers. In this study, we investigate whether the smallholder farmers can exploit APDI systems using their basic and cheap unmanned autonomous vehicles (UAVs) with standard cameras. To create the tomato images like the one taken by UAVs, we build a new dataset from a public dataset by using image processing tools. The dataset includes tomato leaf photographs separated into 10 classes (diseases or healthy). To detect the diseases, we develop a new hybrid detection model, called SpikingTomaNet, which merges a novel deep convolutional neural network model with spiking neural network (SNN) model. This hybrid model provides both better accuracy rates for the plant diseases identification and more energy efficiency for the battery-constrained UAVs due to the SNN’s event-driven architecture. In this hybrid model, the features extracted from the CNN model are used as the input layer for SNNs. To assess our approach’s performance, firstly, we compare the proposed CNN model inside the developed hybrid model with well-known AlexNet, VggNet-5 and LeNet models. Secondly, we compare the developed hybrid model with three hybrid models composed of combinations of the well-known models and SNN model. To train and test the proposed neural network, 32022 images in the dataset are exploited. The results show that the SNN method significantly increases the success, especially in the augmented dataset. The experiment result shows that while the proposed hybrid model provides 97.78% accuracy on original images, its success on the created datasets is between 59.97%–82.98%. In addition, the results shows that the proposed hybrid model provides better overall accuracy in the classification of the diseases in comparison to the well-known models and LeNet and their combination with SNN.",https://doi.org/10.3233/AIC-210009,AI Commun.
Oppositional poor and rich optimization with deep learning enabled secure internet of drone communication system,10.1016/j.compeleceng.2022.108368,2022,a,x,X4,intrusion detection in drone communication,ACM,,"Al-Wesabi, Fahd N.; Alrowais, Fadwa; Alzahrani, Jaber S.; Marzouk, Radwa; Al Duhayyim, Mesfer; alkhayyat, Ahmed; Gupta, Deepak",,https://doi.org/10.1016/j.compeleceng.2022.108368,Comput. Electr. Eng.
Towards an Energy-Efficient and Sustainable IIoT using Embedded Neuromorphic AI,10.1145/3770501.3770529,2025,f,x,X4,,ACM,,"Azadi, Behrooz; Anzengruber-Tanase, Bernhard; Sopidis, Georgios; Haslgrübler, Michael; Ferscha, Alois","Leveraging AI hardware, such as GPUs and NPUs, in the Industrial Internet of Things continues to grow, and therefore, the number of IoT devices is increasing. While this growth provides computational advantages, it also creates a major challenge: these devices consume significant amounts of energy. Neuromorphic hardware offers a promising alternative, with the potential for much lower energy consumption and inference latency compared to GPU-based computing. Throughout this study, we investigate this claim and compare the energy consumption and inference latency of BrainChip Akida and NVIDIA Orin NX. Our results indicate that the quantized model runs faster on the Akida than on the Orin for inference, with an average of 22.54 seconds compared to 181.66 seconds for 10k test samples from the MNIST dataset, respectively. Furthermore, the measured active power and, therefore, energy consumption associated with Akida during idle time are considerably lower than that of NVIDIA Orin. Additionally, our uncontrolled long-term monitoring confirms that the neuromorphic hardware consumes significantly lower energy over 25 days, with an average active power of 4.36 W compared to 9.17 W and energy consumption of 2.6 kWh compared to 5.5 kWh.",https://doi.org/10.1145/3770501.3770529,Proceedings of the 15th International Conference on the Internet of Things
Invited: Neuromorphic Vision Modalities in the NimbleAI 3D Chip,10.1145/3649329.3689622,2024,f,x,X4,,ACM,,"Iturbe, Xabier; Linares-Barranco, Bernabe; Ieng, Sio-Hoi; Erdmann, Arne; Peres, Luca; Rhodes, Oliver; Tornero, Rafael; Sifalakis, Manolis; Burgwal, Marcel van de; Yousefzadeh, Amirreza; Kooli, Maha; Alidori, Riccardo; Zaykov, Pavel","This paper provides an overview of the ongoing work to enable novel modalities of passive monocular neuromorphic vision in the NimbleAI sensing-processing architecture; namely, foveated and light-field event-driven vision with selective visual attention. The latter vision modality encodes 3D visual surroundings as sparse visual events in a 4D spatiotemporal domain, adding depth to current representation of visual information delivered by Dynamic Vision Sensors (DVS). The NimbleAI architecture implements hardware support for efficient execution of mainstream computer vision algorithms and AI models using these visual inputs. The architecture is designed to harness the latest advancements in 3D silicon integration, making it possible to squeeze sensing and spiking circuitry, memory, and processing engines into a miniature silicon volume.",https://doi.org/10.1145/3649329.3689622,Proceedings of the 61st ACM/IEEE Design Automation Conference
NeuroMoCo: a neuromorphic momentum contrast learning method for spiking neural networks: NeuroMoCo: a neuromorphic momentum contrast learning...,10.1007/s10489-024-05982-1,2024,f,x,X4,,ACM,,"Ma, Yuqi; Wang, Huamin; Shen, Hangchi; Chen, Xuemei; Duan, Shukai; Wen, Shiping",,https://doi.org/10.1007/s10489-024-05982-1,Applied Intelligence
Broad Learning System Routing to Mitigate the Impact of Dynamic Changing Topology for 3D Flying Ad Hoc Networks,10.1007/s11036-024-02325-9,2024,f,x,X1,,ACM,"Count: 2 | Sources: ACM, Springer Link","Zhang, Hongguang; Chen, Liangqian; Ma, Shengwen; Zhang, Puyan; Zheng, Hao; Liu, Yuanan","As unmanned aerial vehicles (UAVs) achieve technological breakthroughs, it is an inevitable trend for UAV swarms to engage in increasingly larger-scale, prolonged, and collaborative missions. Nevertheless, the maneuverability of UAVs leads to highly dynamic networks. Therefore, we have to consider the practical requirements for these 3D application scenarios. To mitigate the impact of dynamic changing topology for 3D flying ad hoc networks (FANETs), we propose broad learning system routing (BLSR). As the kernel of BLSR, the broad learning system is used to choose forwarding nodes because it can better adapt to dynamic environments due to its incremental learning. On the other hand, the residual multi-hop-link lifetime (RML) as an input of the broad learning system is defined by us as the maximum duration for all multi-hop links to the base station. Worth noting that, for each UAV, the multi-hop topologies in 3D dynamic scenarios may be analogous to static topologies during the RML. Lastly, some stable-link nodes near the base station are selected as backbone networks, which are usually chosen by other UAVs to forward data packets, thus expanding the stable-link topology of the base station. Compared to four protocols, BLSR demonstrates superior performance in terms of both packet delivery rate and energy efficiency ratio.",https://doi.org/10.1007/s11036-024-02325-9,Mob. Netw. Appl.
Efficient learning in spiking neural networks,10.1016/j.neucom.2024.127962,2024,f,x,X4,SNN learning,ACM,,"Rast, Alexander; Aoun, Mario Antoine; Elia, Eleni G.; Crook, Nigel",,https://doi.org/10.1016/j.neucom.2024.127962,Neurocomput.
Robust Classification of Contraband Substances using Longwave Hyperspectral Imaging and Full Precision and Neuromorphic Convolutional Neural Networks,10.1016/j.procs.2022.11.095,2022,a,x,X4,substance threat classification,ACM,,"Park, Kyung Chae; Forest, Jeremy; Chakraborty, Sudeepto; Daly, James T.; Chelian, Suhas; Vasan, Srini",,https://doi.org/10.1016/j.procs.2022.11.095,Procedia Comput. Sci.
On-Chip Optimization and Deep Reinforcement Learning in Memristor Based Computing,10.1145/3611315.3633242,2024,f,x,X4,RL ,ACM,,"Alam, Md; Yakopcic, Chris; Taha, Tarek M","Reinforcement learning (RL) has shown its viability to learn when an agent interacts continually with the environment to optimize a policy. This work presents a memristor-based deep reinforcement learning (Mem-DRL) system for on-chip training, where the learning process takes place in a dynamic cartpole environment. Memristor device variability is taken into account to make the study more realistic. The proposed system utilized an analog ReLU module to reduce analog to digital converter usage. The analog Mem-DRL system consumed 191 times less energy than an optimized digital FP16 computing system. Our Mem-DRL system reduced the ADC usages by 40%, which led to reduced the overall system energy by 42%. Mem-DRL is 2.4 times faster than the FP16 system and performs 9.27 GOPS during DRL training. The system exhibited an energy efficiency of 23.8 TOPS/W.",https://doi.org/10.1145/3611315.3633242,Proceedings of the 18th ACM International Symposium on Nanoscale Architectures
Using improved density peak clustering algorithm for flower cluster identification and apple central and peripheral flower detection,10.1016/j.compag.2025.110095,2025,t,x,X4,,ACM,,"Geng, Mingyang; Shang, Yuying; Xiang, Shiyu; Wang, Jiachen; Wang, Lei; Song, Huaibo",,https://doi.org/10.1016/j.compag.2025.110095,Comput. Electron. Agric.
SkinDWNet: a novel deep learning model for multiclass classification of skin cancers using dermoscopic images,10.1007/s00530-025-01952-w,2025,t,x,X4,,ACM,,"Naeem, Ahmad; Malik, Hassaan; Din, Mui-zzud; Sadeghi-Niaraki, Abolghasem; Jeong, Daesik; Naqvi, Rizwan Ali","Skin cancer is recognized as one of the most hazardous types of cancer. The physical analysis for the identification of skin cancer is an exhaustive approach that cannot be easily performed by any individual with lesser skill. Therefore, an efficient classifier is needed that can help diagnose skin cancer at an early stage. The presence of noise in dermoscopic images, such as hair, air bubbles, etc., hinders the classification of skin cancer. To eliminate hair and other artifacts from dermoscopic images, this study uses several image preprocessing techniques. In this research, we proposed a novel SkinDWNet (Skin Depthwise Dilated Convolutions Network) based on deep learning for the multiclassification of skin cancer. The SkinDWNet is constructed by using depth-wise dilated convolutions (DDCs) and feature reuse residual blocks (FRBs). The DDCs and FRBs are used to extract relevant features from the dermoscopy images. Furthermore, the Gradient Boosting (GB) technique is employed to identify the prompt feature maps provided by SkinDWNet. SkinDWNet and GB together help to achieve satisfactory improvements in performance. Moreover, the SMOTE Tomek approach is employed to handle the problem of unequal class distribution in the ISIC 2019 data. To assess the performance of the SkinDWNet + GB model, the model is compared with six baseline deep learning models and state-of-the-art (SOTA) models. The SkinDWNet + GB model surpassed the baseline model&nbsp;and achieved the highest&nbsp;accuracy rate of 97.04% on the ISIC 2019 dataset for multiclass classification of skin cancer. Furthermore, ANOVA and McNemar's statistical test demonstrate that the SkinDWNet + GB model outperforms the other models. Thus, the study concludes that the proposed SkinDWNet + GB model produced significant outcomes as compared to baseline models and SOTA models.",https://doi.org/10.1007/s00530-025-01952-w,Multimedia Syst.
Deep learning framework for land cover and land use classification: five case studies with hyperspectral and RGB imagery,10.1007/s00521-025-11644-1,2025,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Arain, Bilal; Ali, Ahmed M.; Alrashdi, Ibrahim; Sallam, Karam M.; Abdel-Basset, Mohamed","Land Cover and Land Use (LCLU) classification is critical in remote sensing, especially when analyzing hyperspectral and RGB images. LCLU classification with these image types is inherently challenging due to the limited availability of training samples. In this paper, a deep learning (DL) approach is developed to address this issue. For hyperspectral image analysis, multiple models were constructed, including 2D and 3D Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), Gated Recurrent Units, and bidirectional LSTM models. Pre-trained CNN architectures such as VGG16, VGG19, ResNet50, ResNet50 V2, and MobileNet were employed for RGB image analysis. These models were applied to five datasets: Pavia University (PU), Kennedy Space Center (KSC), and Indian Pines (IP) for hyperspectral images, and Eurosat (ES) and UC Merced (UCM) for RGB images. The proposed models achieved high accuracy, with bidirectional LSTM reaching 99.2% accuracy on the PU dataset, 2D CNN attaining 99.6% on the KSC dataset, and 2D CNN achieving 100% on the IP dataset. For RGB image analysis, VGG16 achieved 97.81% accuracy on the ES dataset, while ResNet50 reached 98.6% on the UCM dataset. Comparative analysis with the other nine different DL models indicates that the proposed approach demonstrates superior accuracy and performance across all tested datasets.",https://doi.org/10.1007/s00521-025-11644-1,Neural Comput. Appl.
Towards crossing the reality gap with evolved plastic neurocontrollers,10.1145/3377930.3389843,2020,a,x,X1,,ACM,,"Qiu, Huanneng; Garratt, Matthew; Howard, David; Anavatti, Sreenatha","A critical issue in evolutionary robotics is the transfer of controllers learned in simulation to reality. This is especially the case for small Unmanned Aerial Vehicles (UAVs), as the platforms are highly dynamic and susceptible to breakage. Previous approaches often require simulation models with a high level of accuracy, otherwise significant errors may arise when the well-designed controller is being deployed onto the targeted platform. Here we try to overcome the transfer problem from a different perspective, by designing a spiking neurocontroller which uses synaptic plasticity to cross the reality gap via online adaptation. Through a set of experiments we show that the evolved plastic spiking controller can maintain its functionality by self-adapting to model changes that take place after evolutionary training, and consequently exhibit better performance than its non-plastic counterpart.",https://doi.org/10.1145/3377930.3389843,Proceedings of the 2020 Genetic and Evolutionary Computation Conference
Current-Mode Memristor Crossbars for Neuromorphic Computing,10.1145/3320288.3320298,2019,f,x,X4,,ACM,,"Merkel, Cory","Motivated by advantages of current-mode design, this paper explores the implementation of weight matrices in neuromemristive systems via current-mode memristor crossbar circuits. After deriving theoretical results for the range and distribution of weights in the current-mode design, it is shown that any weight matrix based on voltage-mode crossbars can be mapped to a current-mode crossbar if the voltage-mode weights are carefully bounded. Then, a modified gradient descent rule is derived for the current-mode design that can be used to perform backpropagation training. Behavioral simulations on the MNIST dataset indicate that both voltage and current-mode designs are able to achieve similar accuracy and have similar defect tolerance. However, analysis of trained weight distributions reveals that current-mode and voltage-mode designs may use different feature representations.",https://doi.org/10.1145/3320288.3320298,Proceedings of the 7th Annual Neuro-Inspired Computational Elements Workshop
A new multi-objective hyperparameter optimization algorithm for COVID-19 detection from x-ray images,10.1007/s00500-024-09872-z,2024,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Gülmez, Burak","The coronavirus occurred in Wuhan (China) first and it was declared a global pandemic. To detect coronavirus X-ray images can be used. Convolutional neural networks (CNNs) are used commonly to detect illness from images. There can be lots of different alternative deep CNN models or architectures. To find the best architecture, hyper-parameter optimization can be used. In this study, the problem is modeled as a multi-objective optimization (MOO) problem. Objective functions are multi-class cross entropy, error ratio, and complexity of the CNN network. For the best solutions to the objective functions, multi-objective hyper-parameter optimization is made by NSGA-III, NSGA-II, R-NSGA-II, SMS-EMOA, MOEA/D, and proposed Swarm Genetic Algorithms (SGA). SGA is a swarm-based algorithm with a cross-over process. All six algorithms are run and give Pareto optimal solution sets. When the figures obtained from the algorithms are analyzed and algorithm hypervolume values are compared, SGA outperforms the NSGA-III, NSGA-II, R-NSGA-II, SMS-EMOA, and MOEA/D algorithms. It can be concluded that SGA is better than others for multi-objective hyper-parameter optimization algorithms for COVID-19 detection from X-ray images. Also, a sensitivity analysis has been made to understand the effect of the number of the parameters of CNN on model success.",https://doi.org/10.1007/s00500-024-09872-z,Soft Comput.
Neuromorphic processor-oriented hybrid Q-format multiplication with adaptive quantization for tiny YOLO3,10.1007/s00521-023-08280-y,2023,f,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Li, Tao; Ma, Yitao; Endoh, Tetsuo","Deep neural networks (DNNs) have delivered unprecedented achievements in the modern Internet of Everything society, encompassing autonomous driving, expert diagnosis, unmanned supermarkets, etc. It continues to be challenging for researchers and engineers to develop a high-performance neuromorphic processor for deployment in edge devices or embedded hardware. DNNs’ superpower derives from their enormous and complex network architecture, which is computation-intensive, time-consuming, and energy-heavy. Due to the limited perceptual capacity of humans, accurate processing results from DNNs require a substantial amount of computing time, making them redundant in some applications. Utilizing adaptive quantization technology to compress the DNN model with sufficient accuracy is crucial for facilitating the deployment of neuromorphic processors in emerging edge applications. This study proposes a method to boost the development of neuromorphic processors by conducting fixed-point multiplication in a hybrid Q-format using an adaptive quantization technique on the convolution of tiny YOLO3. In particular, this work integrates the sign-bit check and bit roundoff techniques into the arithmetic of fixed-point multiplications to address overflow and roundoff issues within the convolution’s adding and multiplying operations. In addition, a hybrid Q-format multiplication module is developed to assess the proposed method from a hardware perspective. The experimental results prove that the hybrid multiplication with adaptive quantization on the tiny YOLO3’s weights and feature maps possesses a lower error rate than alternative fixed-point representation formats while sustaining the same object detection accuracy. Moreover, the fixed-point numbers represented by Q(6.9) have a suboptimal error rate, which can be utilized as an alternative representation form for the tiny YOLO3 algorithm-based neuromorphic processor design. In addition, the 8-bit hybrid Q-format multiplication module exhibits low power consumption and low latency in contrast to benchmark multipliers.",https://doi.org/10.1007/s00521-023-08280-y,Neural Comput. Appl.
Recognizing High-Speed Moving Objects with Spike Camera,10.1145/3581783.3612054,2023,f,x,X2,"No SNNs, only spiking cameras",ACM,,"Zhao, Junwei; Ye, Jianming; Shiliang, Shiliang; Yu, Zhaofei; Huang, Tiejun","Spike camera is a novel bio-inspired vision sensor that mimics the sampling mechanism of the primate fovea. It presents high temporal resolution and dynamic range, showing great potentials in the high-speed moving object recognition task, which has not been fully explored in the Multimedia community due to the lack of data and annotations. This paper contributes the first large-scale High-Speed Spiking Recognition (HSSR) dataset, by recording high-speed moving objects using a spike camera. The HSSR dataset contains 135,000 indoor objects annotated using ImageNet labels and 3,100 outdoor objects collected from real-world scenarios. Furthermore, we propose an original spiking recognition framework, which employs long-term spike stream features to supervise the feature learning from short-term spike streams. This framework improves the recognition accuracy, meanwhile substantially decreasing the recognition latency, making our method can accurately recognize moving objects at an equivalent speed of 514 km/h, using only 1 ms of spike stream. Experimental results show that, the proposed method achieves 76.5% accuracy for recognizing 100 fine-grained indoor objects and 84.3% accuracy for recognizing 8 outdoor objects using 1 ms of spike streams. Resources will be available at https://github.com/Evin-X/HSSR.",https://doi.org/10.1145/3581783.3612054,Proceedings of the 31st ACM International Conference on Multimedia
Optimization Driven Spike Deep Belief Neural Network classifier: a deep-learning based Multichannel Spike Sorting Neural Signal Processor (NSP) module for high-channel-count Brain Machine Interfaces (BMIs),10.1007/s10462-023-10575-4,2023,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Reddy, Vanga Karunakar; Melingi, Sunil Babu; Kumar, Ch. V. M. S. N. Pavan; Kumar, K. Ashok; Mojjada, Ramesh Kumar","An Optimization Driven Spike Deep Belief Neural Networks is a type of neural network that is inspired by the functioning of the human brain. It is a variant of the more general class of Deep Belief Networks (DBNs), which are artificial neural networks composed of multiple layers of hidden units. Spike sorting is a critical process in neural signal processing that involves separating and identifying individual action potentials, spikes, from extracellular recordings of neuronal activity. This process is essential for understanding the behaviour of individual neurons and for decoding neural signals in various applications, such as Brain Machine Interfaces (BMIs) and neuro science research. Spike sorting is challenging due to the complexity of the recorded signals, including overlapping spikes and noise from other sources. This manuscript proposes A deep-learning based Multichannel Spike Sorting Neural Signal Processor (SSNSP) Module for High-Channel-Count Brain Machine Interfaces to record spike activity (SA) of brain neuron signals with less noise. Here first data acquisition is first step and the data’s are took form Neural Signal Processor (NSP). Then the collected features are stored in BMIs. After this process feature is extracted using Haar DWT. Haar DWT is a frequency based feature extractor used to extract the spike or noisy signals from the neuron signals. Then the extracted features are given to driven spike DBN, this is a combination of multi-layer perceptron&nbsp;(MLP)&nbsp;layer and DBN. To increase the accuracy, Adam-Cuckoo Search optimization is used, which optimize the driven spike DBN weight parameter. An FPGA was used to construct and test a prototype 32-channel SSNSP component based on this analysis. Synthesised signals are used at various signals to noise ratios. Then, human neurons are classified based on the channels containing neural spike data. The impact of busy as well as idle state prediction errors on the spectrum efficacy is examined. The proposed technique is implemented in MATLAB platform. Finally, the proposed technique attains better detection accuracy 22.86%, 28.94%, 31.11% and 27.34% compared to the existing models, like Deep Learning Laser Speckle Contrast ESNN (DL-LSC-ESNN), Highly Stretchable Hydro gels as Wearable with Implantable Sensors for Recording Physiological with Brain Neural Signals (HSN-WIS-RPBNS), Lower-power band of neuronal spiking action dominated through local single units enhances the Presentation of BMI (LPB-NSA-LSU-BMI) and Emotion Categorization Utilizing Feature Fusion of Multimodal Data along Deep Learning in Brain-Inspired Spiking Neural Network (EC-FFMD-BISNN) respectively.",https://doi.org/10.1007/s10462-023-10575-4,Artif. Intell. Rev.
TSOM: Small object motion detection neural network inspired by avian visual circuit,10.1016/j.neunet.2024.106881,2025,f,x,X4,tiny object detection from uav view,ACM,,"Hu, Pingge; Zhang, Xiaoteng; Li, Mengmeng; Zhu, Yingjie; Shi, Li",,https://doi.org/10.1016/j.neunet.2024.106881,Neural Netw.
ESOD: Event-Based Small Object Detection,10.1145/3746027.3755486,2025,f,i,,Don’t use SNNs but comparing with SNN methods → „lack of dedicated datasets“,ACM,,"Liang, Quanmin; Lu, Jinyi; Li, Qiang; Liu, Shuai; Zhao, Zhihao; Zhao, Yinzheng; Zhang, Wei; Huang, Kai; Tian, Yonghong","Event-based object detection plays a crucial role in scenarios involving high-speed motion, extreme lighting conditions, and high-frequency detection. However, existing methods fail to address the challenges posed by small objects, including discriminative feature deficiency, the loss of critical information, and the inherent sparsity of event data. Moreover, the lack of benchmark datasets has significantly hindered progress in this field. To tackle these issues, we propose the Fully Deformable Detection Network (FDDNet), a lightweight framework that dynamically adapts to extract key features. First, we introduce a Long-Term Deformable Temporal Receptive Module (LDTR), which aligns critical features across consecutive event streams and leverages a State Space Model for long-range temporal modeling, enhancing the detection of high-speed small objects. Second, to address the sparsity of event data and the concentration of key features along object edges, we design a Sparse Feature Aggregation Block (SFAB) within the backbone and a coarse-to-fine deformable detection head, enabling hierarchical feature refinement from local to global, and improving the detection quality of sparse targets. Finally, to mitigate the lack of event-based small object datasets, we develop a high-quality, annotation-free data acquisition method and collect a real-world benchmark dataset for validation. Extensive experiments demonstrate that our approach achieves state-of-the-art (SOTA) performance on event-based small object detection tasks, with a mAP of 37.4% (+2.4%) on our benchmark and runs at 88 FPS, showcasing both accuracy and real-time capability. Our code and Supplement are available at https://github.com/Lqm26/ESOD.",https://doi.org/10.1145/3746027.3755486,Proceedings of the 33rd ACM International Conference on Multimedia
PT-spike: A precise-time-dependent single spike neuromorphic architecture with efficient supervised learning,10.1109/ASPDAC.2018.8297383,2018,f,x,X4,only MNIST and not noted if also applicable for UAV detection,ACM,"Count: 3 | Sources: ACM, IEEE Xplore","Liu, Tao; Jiang, Lei; Jin, Yier; Quan, Gang; Wen, Wujie","One of the most exciting advancements in Artificial Intelligence (AI) over the last decade is the wide adoption of Artificial Neural Networks (ANNs), such as Deep Neural Network (DNN) and Convolutional Neural Network (CNN), in real world applications. However, the underlying massive amounts of computation and storage requirement greatly challenge their applicability in resource-limited platforms like drone, mobile phone and IoT devices etc. The third generation of neural network model-Spiking Neural Network (SNN), inspired by the working mechanism and efficiency of human brain, has emerged as a promising solution for achieving more impressive computing and power efficiency within light-weighted devices (e.g. single chip). However, the relevant research activities have been narrowly carried out on conventional rate-based spiking system designs for fulfilling the practical cognitive tasks, underestimating SNN's energy efficiency, throughput and system flexibility. Although the time-based SNN can be more attractive conceptually, its potentials are not unleashed in realistic applications due to lack of efficient coding and practical learning schemes. In this work, a Precise-Zime-Dependent Single Spike Neuromorphic Architecture, namely “PT-Spike”, is developed to bridge this gap. Three constituent hardware-favorable techniques: precise single-spike temporal encoding, efficient supervised temporal learning and fast asymmetric decoding are proposed accordingly to boost the energy efficiency and data processing capability of the time-based SNN at a more compact neural network model size when executing real cognitive tasks. Simulation results show that “PT-Spike” demonstrates significant improvements in network size, processing efficiency and power consumption with marginal classification accuracy degradation, when compared with the rate-based SNN and ANN under the similar network configuration.",https://doi.org/10.1109/ASPDAC.2018.8297383,2018 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)
Futuristic person re-identification over internet of biometrics things (IoBT): Technical potential versus practical reality,10.1016/j.patrec.2021.08.007,2021,t,x,X4,,ACM,,"Behera, Nayan Kumar Subhashis; Behera, Tanmay Kumar; Nappi, Michele; Bakshi, Sambit; Sa, Pankaj Kumar",,https://doi.org/10.1016/j.patrec.2021.08.007,Pattern Recogn. Lett.
Robust iterative value conversion: Deep reinforcement learning for neurochip-driven edge robots,10.1016/j.robot.2024.104782,2024,t,x,X4,,ACM,,"Kadokawa, Yuki; Kodera, Tomohito; Tsurumine, Yoshihisa; Nishimura, Shinya; Matsubara, Takamitsu",,https://doi.org/10.1016/j.robot.2024.104782,Robot. Auton. Syst.
Energy and Area Efficiency in Neuromorphic Computing for Resource Constrained Devices,10.1145/3194554.3194611,2018,f,x,X4,,ACM,,"Chakma, Gangotree; Skuda, Nicholas D.; Schuman, Catherine D.; Plank, James S.; Dean, Mark E.; Rose, Garrett S.","Resource constrained devices are the building blocks of the internet of things (IoT) era. Since the idea behind IoT is to develop an interconnected environment where the devices are tiny enough to operate with limited resources, several control systems have been built to maintain low energy and area consumption while operating as IoT edge devices. Several researchers have begun work on implementing control systems built from resource constrained devices using machine learning. However, there are many ways such devices can achieve lower power consumption and area utilization while maximizing application efficiency. Spiky neuromorphic computing (SNC) is an emerging paradigm that can be leveraged in resource constrained devices for several emerging applications. While delivering the benefits of machine learning, SNC also helps minimize power consumption. For example, low energy memory devices (memristors) are often used to achieve low power operation and also help in reducing system area. In total, we anticipate SNC will provide computational efficiency approaching that of deep learning while using low power, resource constrained devices.",https://doi.org/10.1145/3194554.3194611,Proceedings of the 2018 Great Lakes Symposium on VLSI
An event-based motion scene feature extraction framework,10.1016/j.patcog.2024.111320,2025,f,x,X4,,ACM,,"Liu, Zhaoxin; Wu, Jinjian; Shi, Guangming; Yang, Wen; Ma, Jupo",,https://doi.org/10.1016/j.patcog.2024.111320,Pattern Recogn.
DTL-IDS: An optimized Intrusion Detection Framework using Deep Transfer Learning and Genetic Algorithm,10.1016/j.jnca.2023.103784,2024,t,x,X4,,ACM,,"Latif, Shahid; Boulila, Wadii; Koubaa, Anis; Zou, Zhuo; Ahmad, Jawad",,https://doi.org/10.1016/j.jnca.2023.103784,J. Netw. Comput. Appl.
Hyper real-time flame detection: Dynamic insights from event cameras and FlaDE dataset,10.1016/j.eswa.2024.125746,2025,t,x,X4,,ACM,,"Ding, Saizhe; Zhang, Haorui; Zhang, Yuxin; Huang, Xinyan; Song, Weiguo",,https://doi.org/10.1016/j.eswa.2024.125746,Expert Syst. Appl.
Hybridized Dragonfly and Jaya algorithm for optimal sensor node location identification in mobile wireless sensor networks,10.1007/s11227-023-05326-9,2023,t,x,X4,,ACM,,"Khedr, Ahmed M.; Rani, S. Sheeja; Saad, Mohamed","A wireless sensor network (WSN) consists of an extensive number of low-power sensor nodes to gather information from their environment and monitor physical activities. This makes node localization a crucial aspect in most WSN applications since measurement data is worthless unless the location from where the data is acquired is known precisely. The majority of localization solutions rely on anchor nodes for estimating the node locations with different localization accuracy, complexity, and hence different applicability. But, the cost and complexity in the localization of large-scale WSNs are not significantly reduced. In this paper, a novel Hybridized Dragonfly and Jaya Optimization technique (HyDAJ) is introduced for improving localization accuracy and performance of mobile WSNs. The proposed hybrid technique combines the advantages of Dragonfly algorithm and Jaya algorithm to localize the sensor nodes in a more efficient way and overcomes the limitations of the original algorithm. The hybrid algorithm verifies that all target nodes are precisely localized with higher accuracy. Simulation results reveal that HyDAJ outperforms existing methods under multiple metrics including localization efficiency, mean localization error, computation time, and energy consumption.",https://doi.org/10.1007/s11227-023-05326-9,J. Supercomput.
"A design methodology for analog integrated artificial neural networks circuits: architectures, design and training",10.1007/s10470-025-02480-3,2025,a,x,X4,,ACM,,"Alimisis, Vassilis; Cheliotis, Konstantinos; Moustakas, Vasileios; Mylona, Anna; Dimas, Christos; Sotiriadis, Paul P.","A general methodology for designing analog integrated artificial neural networks is presented in this work. Each high-level architecture is composed of different analog integrated circuits operating in the sub-threshold region. Modularity and scalability are key considerations in the design of each implementation, enabling successful adaptation to changes in classification parameters. The operating principles of each neural network are thoroughly explained, and the proposed designs are implemented as fully adjustable, low-power, low-voltage systems targeted at electrical impedance tomography applications. This design methodology was implemented using the Cadence IC Suite for both schematic design and simulation, employing a TSMC 90&nbsp;nm CMOS process. During the verification stage, simulation results were meticulously compared with software-based implementations of each neural network. The comparison study and simulation results validate the proposed design methodology. Monte Carlo simulations, incorporating process variations and mismatches, along with corner-case analysis, are conducted to verify the robustness of the design methodology.",https://doi.org/10.1007/s10470-025-02480-3,Analog Integr. Circuits Signal Process.
Person re-identification: A taxonomic survey and the path ahead,10.1016/j.imavis.2022.104432,2022,t,x,X4,,ACM,,"Behera, Nayan Kumar Subhashis; Sa, Pankaj Kumar; Bakshi, Sambit; Padhy, Ram Prasad",,https://doi.org/10.1016/j.imavis.2022.104432,Image Vision Comput.
PL-MCT: pseudo-labeling and multi-frame consistency training for semi-supervised visual tracking: PL-MCT: pseudo-labeling and multi-frame consistency training...,10.1007/s00371-024-03651-5,2024,f,x,X2,,ACM,,"Huang, Yiqian; Liu, Shuqi; Dong, Fei; Li, Xu; Yang, Xin; Zhou, Ya; Huang, Jinxiang; Song, Yong","The exploitation of unlabeled videos for visual object tracking has recently drawn increasing attention. However, unreliable pseudo-labels cause an incomplete appearance of the object and an incorrect search region, which hinders bounding box regression learning. To address this issue, we propose a novel semi-supervised learning method, termed pseudo-labeling and multi-frame consistency training (PL-MCT), for visual tracking, which successfully improves the reliability of pseudo-labels and the robustness of the tracker. Specifically, we introduce a pseudo-label evaluation (PLE) module to provide the reliability score of the pseudo-label and design a prediction-training alternation (PTA) strategy to effectively mitigate the bias of noisy pseudo-labels, which contributes to selecting high-quality pseudo-labels as training pairs. Meanwhile, to cope with the appearance variations of objects in complex scenarios, we employ a multi-frame consistency training scheme that introduced an online update head (OUH) to continue training the tracker to learn the signal in the temporal dimension of videos and update online. Extensive experiments demonstrate the effectiveness of the proposed method. Our method (PL-MCT) achieves a precision score of 0.856 on OTB2015 and 0.408 on LaSOT, which achieves advanced performance compared to other unsupervised methods and has comparable results to preceding supervised methods. Project will be available at .",https://doi.org/10.1007/s00371-024-03651-5,Vis. Comput.
Security of neuromorphic computing: thwarting learning attacks using memristor's obsolescence effect,10.1145/2966986.2967074,2016,t,x,X4,,ACM,,"Yang, Chaofei; Liu, Beiye; Li, Hai; Chen, Yiran; Wen, Wujie; Barnell, Mark; Wu, Qing; Rajendran, Jeyavijayan","Neuromorphic architectures are widely used in many applications for advanced data processing, and often implements proprietary algorithms. In this work, we prevent an attacker with physical access from learning the proprietary algorithm implemented by the neuromorphic hardware. For this purpose, we leverage the obsolescence effect in memristors to judiciously reduce the accuracy of outputs for any unauthorized user. For a legitimate user, we regulate the obsolescence effect, thereby controlling the accuracy of outputs. We also analyze the security vs. cost trade-offs for different applications. Our methodology is compatible with mainstream classification applications, memristor devices, and security and performance constraints.",https://doi.org/10.1145/2966986.2967074,Proceedings of the 35th International Conference on Computer-Aided Design
"Anomaly detection in surveillance videos: a thematic taxonomy of deep models, review and performance analysis",10.1007/s10462-022-10258-6,2022,f,x,"X2,X4",,ACM,,"Chandrakala, S.; Deepak, K.; Revathy, G.","The task of anomaly detection has recently gained much attention in the field of visual surveillance. Video surveillance data is often available in large quantities, but manual annotation of activities in video segments is tedious. Anomaly detection plays a crucial role in various indoor and outdoor surveillance applications. Video anomaly detection is highly challenging and provides a lot of scope and demand for improving detection performance in real-time scenarios. Recently, deep learning-based approaches are promising to detect single-scene video anomalies in real-time. This work starts by highlighting the over-view of deep learning-based video anomaly detection. A thematic taxonomy that includes four major categories and several sub-categories is presented. State-of-the-art deep learning approaches under these categories are reviewed. In addition, few recent one class model based deep learning approaches are evaluated and analyzed in terms of performance. Out of the approaches presented, Generative Adversarial Network (GAN) and Adversarial Autoencoder-based approaches provide a better detection rate. A few important directions are outlined for further research in the field of video surveillance applications.",https://doi.org/10.1007/s10462-022-10258-6,Artif. Intell. Rev.
Optimal deep convolutional neural network based crop classification model on multispectral remote sensing images,10.1016/j.micpro.2022.104626,2022,a,x,X4,,ACM,,"Chamundeeswari, G.; Srinivasan, S.; Bharathi, S. Prasanna; Priya, P.; Kannammal, G. Rajendra; Rajendran, Sasikumar",,https://doi.org/10.1016/j.micpro.2022.104626,Microprocess. Microsyst.
Sign potential-driven multiplicative optimization for robust deep reinforcement learning,10.1016/j.neunet.2025.107492,2025,t,x,X4,,ACM,,"Avramelou, Loukia; Kirtas, Manos; Passalis, Nikolaos; Tefas, Anastasios",,https://doi.org/10.1016/j.neunet.2025.107492,Neural Netw.
Rigid propagation of visual motion in the insect’s neural system,10.1016/j.neunet.2024.106874,2025,f,x,X4,,ACM,,"Chen, Hao; Fan, Boquan; Li, Haiyang; Peng, Jigen",,https://doi.org/10.1016/j.neunet.2024.106874,Neural Netw.
Quantum federated learning with pole-angle quantum local training and trainable measurement,10.1016/j.neunet.2025.107301,2025,f,x,"X4,X2",,ACM,,"Park, Soohyun; Lee, Hyunsoo; Son, Seok Bin; Jung, Soyi; Kim, Joongheon",,https://doi.org/10.1016/j.neunet.2025.107301,Neural Netw.
Spare parts inventory classification using Neutrosophic Fuzzy EDAS method in the aviation industry,10.1016/j.eswa.2023.120008,2023,a,x,X4,,ACM,,"Cakmak, Emre; Guney, Eda",,https://doi.org/10.1016/j.eswa.2023.120008,Expert Syst. Appl.
"Disruptive 6G architecture: Software-centric, AI-driven, and digital market-based mobile networks",10.1016/j.comnet.2024.110682,2024,a,x,"X1,X4",,ACM,,"Alberti, Antônio M.; Pivoto, Diego G.S.; Rezende, Tibério T.; Leal, Alexis V.A.; Both, Cristiano B.; Facina, Michelle S.P.; Moreira, Rodrigo; de Oliveira Silva, Flávio",,https://doi.org/10.1016/j.comnet.2024.110682,Comput. Netw.
Spiking networks for improved cognitive abilities of edge computing devices,10.1145/3316782.3321546,2019,f,x,"X3,X4","concept paper only, no benchmarking etc and also not drone detection",ACM,,"Akusok, Anton; Björk, Kaj-Mikael; Leal, Leonardo Espinosa; Miche, Yoan; Hu, Renjie; Lendasse, Amaury","This concept paper highlights a recently opened opportunity for large scale analytical algorithms to be trained directly on edge devices. Such approach is a response to the arising need of processing data generated by natural person (a human being), also known as personal data. Spiking Neural networks are the core method behind it: suitable for a low latency energy-constrained hardware, enabling local training or re-training, while not taking advantage of scalability available in the Cloud.",https://doi.org/10.1145/3316782.3321546,Proceedings of the 12th ACM International Conference on PErvasive Technologies Related to Assistive Environments
Integrating control-theoretic predictive deep learning for resource-efficient computing systems,10.1007/s10844-025-00919-7,2025,f,x,X1,,ACM,"Count: 2 | Sources: ACM, Springer Link","Machidon, Alina L.; Pejović, Veljko","Deep learning (DL) powers numerous applications on ubiquitous edge devices, but its high resource demands pose a challenge. Approximate computing is often proposed to alleviate this, yet such calculation usually suffers from a fixed level of accuracy loss. We propose a novel control-theoretic approach for predictive DL inference on resource constrained devices. Our system dynamically adjusts approximation levels based on a trade-off between resource utilisation and accuracy, considering future demands. Extensive experiments across diverse domains - human activity recognition, acoustic scene profiling, and computer vision - with various neural network architectures and approximation techniques, demonstrate that our approach achieves up to 50% energy savings while maintaining the desired inference accuracy and incurring minimal runtime overhead. Furthermore, we showcase our method in a real-world deployment on low-power edge devices and confirm its superiority over current state-of-the-art solutions.",https://doi.org/10.1007/s10844-025-00919-7,J. Intell. Inf. Syst.
"Walking motion real-time detection method based on walking stick, IoT, COPOD and improved LightGBM",10.1007/s10489-022-03264-2,2022,a,x,X4,,ACM,,"Wang, Junyi; Jiang, Xuezheng; Meng, Qinggang; Saada, Mohamad; Cai, Haibin","Real-time walking behavior monitoring is essential in ensuring safety and improving people’s physical conditions with mobility difficulties. In this paper, a real-time walking motion detection system based on the intelligent walking stick, mobile phone and multi-label imbalance classification method combining focal loss and LightGBM (MFGBoost) is proposed. The Internet of Things (IoT) technology is utilized for communicating between the walking stick and mobile phone. The new MFGBoost is embedded into the Raspberry Pi to classify human motions. MFGBoost is scalable, and other boosting models, such as XGBoost, could also be used as its base classifier. An improved derivation method of the multi-classification focal loss function is proposed in this paper, which is the key to the combination of multi-classification focal loss and Boosting algorithms. We propose a novel denoise method based on window matrix and COPOD algorithm (W-OD). The window matrix is designed to extract data features and smooth noise, and COPOD could output the noise level of the model. A weighted loss function is designed to adjust the model’s attention to different samples based on the W-OD algorithm. We evaluate the latest classification model from multiple perspectives on multiple benchmark datasets and demonstrate that MFGBoost and W-OD-MFGBoost could improve classification performance and decision-making efficiency. Experiments conducted on human motion datasets show that W-OD-MFGBoost could achieve more than 97 percent classification accuracy.",https://doi.org/10.1007/s10489-022-03264-2,Applied Intelligence
Biologically-inspired visual place recognition with adaptive multiple scales,10.1016/j.robot.2017.07.015,2017,t,x,X4,,ACM,,"Fan, Chen; Chen, Zetao; Jacobson, Adam; Hu, Xiaoping; Milford, Michael","In this paper we present a novel adaptive multi-scale system for performing visual place recognition. Unlike recent previous multi-scale place recognition systems that use manually pre-fixed scales, we present a system that adaptively selects the spatial scales. This approach differs from previous multi-scale methods, where place recognition is performed through a non-optimized distance metric in a fixed and pre-determined scale space. Instead, we learn an optimized distance metric which creates a new recognition space for clustering images with similar features while separating those with different features. Consequently, the method exploits the natural spatial scales present in the operating environment. With these adaptive scales, a hierarchical recognition mechanism with multiple parallel channels is then proposed. Each channel performs place recognition from a coarse match to a fine match. We present specific techniques for training each channel to recognize places at varying spatial scales and for combining the place recognition hypotheses from these parallel channels. We also conduct a systematic series of experiments and parameter studies that determine the effect on performance of using different numbers of combined recognition channels. The results demonstrate that the adaptive multi-scale approach outperforms the previous fixed multi-scale approach and is capable of producing better than state of the art performance compared to existing robotic navigation algorithms. The system complexity is linear in the number of places in the reference static map and can realize the online place recognition in mobile robotics on typical dataset sizes We analyze the results and provide theoretical analysis of the performance improvements. Finally, we discuss interesting insights gained with respect to future work in robotics and neuroscience in this area. A clustering-based algorithm for adaptively calculating the spatial scales.Specific scale-encoding rules to model the grid cells encoding patterns.A novel coarse-to-fine framework for recognizing places at multiple scales in a parallel manner.A comprehensive analysis of how and why the significant performance. improvements are achieved using this new approach.",https://doi.org/10.1016/j.robot.2017.07.015,Robot. Auton. Syst.
Acre-Scale Grape Bunch Detection and Predict Grape Harvest Using YOLO Deep Learning Network,10.1007/s42979-023-02572-9,2024,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Sneha, N.; Sundaram, Meenakshi; Ranjan, Rajeev","To provide the harvesting weight of grapes in real time to the farmer in the form of acres or square feet of land, the proposed system provides an estimate of grape harvest in the form of kilograms. Some of the challenges in the field where crop harvest may vary due to differences in soil, the size of grapes, maturate of the grapes, color, disease, etc. The proposed system uses YoloV5, a real-time object detection system, to detect the grape bunches, and the total bunch count is based on several images collected from the forms. The total area of acres is divided into bins, which are in turn divided into sectors. The grape data are collected from the Dodballapur district; Karnataka, which consist of 4000 grape images and manual annotation was performed on each image to classify the grape bunch and leaves. Pre-trained YoloV5 is used to detect the grapes by extracting visual features from the training images. The visual images are fetched and used to build a detection network using YoloV5. The research presents three-object detection-pre-trained YOLO models such as YoloV3, YoloV4, and YoloV5, which perform detection of grape bunches. Three models are trained on grape bunches and were compared with precision, F1 Score, and recognition recall value, achieving good results with YoloV5 along with counting grapes, which helps in knowing the harvesting status of the bunch 98%. The recall and F1 Scores are 90.2, 91.25, 95.63 and 92.21, 92.68, 93.21 for YoloV3, YoloV4, YoloV5, respectively. The network also calculates the total bunches in each image, and multiplied with average gram of a bunch and provides the final kilograms expected from each acre for the set of images collected for the particular acre.",https://doi.org/10.1007/s42979-023-02572-9,SN Comput. Sci.
Integration of a Lightweight Customized 2D CNN Model to an Edge Computing System for Real-Time Multiple Gesture Recognition,10.1007/s10723-023-09715-5,2023,t,x,"X4,X2",,ACM,"Count: 2 | Sources: ACM, Springer Link","Jin, Hulin; Jin, Zhiran; Kim, Yong-Guk; Fan, Chunyang","The human-machine interface (HMI) collects electrophysiology signals incoming from the patient and utilizes them to operate the device. However, most applications are currently in the testing phase and are typically unavailable to everyone. Developing wearable HMI devices that are intelligent and more comfortable has been a focus of study in recent times. This work developed a portable, eight-channel electromyography (EMG) signal-based device that can distinguish 21 different types of motion. To identify the EMG signals, an analog front-end (AFE) integrated chip (IC) was created, and an integrated EMG signal acquisition device combining a stretchy wristband was made. Using the EMG movement signals of 10 volunteers, a SIAT database of 21 gestures was created. Using the SIAT dataset, a lightweight 2D CNN-LSTM model was developed and specialized training was given. The signal recognition accuracy is 96.4%, and the training process took a median of 14&nbsp;min 13&nbsp;s. The model may be used on lower-performance edge computing devices because of its compact size, and it is anticipated that it will eventually be applied to smartphone terminals.",https://doi.org/10.1007/s10723-023-09715-5,J. Grid Comput.
Optical flow for spike camera with hierarchical spatial-temporal spike fusion,10.1609/aaai.v38i7.28581,2024,f,x,X4,optical flow prediction,ACM,,"Zhao, Rui; Xiong, Ruiqin; Zhang, Jian; Zhang, Xinfeng; Yu, Zhaofei; Huang, Tiejun","As an emerging neuromorphic camera with an asynchronous working mechanism, spike camera shows good potential for high-speed vision tasks. Each pixel in spike camera accumulates photons persistently and fires a spike whenever the accumulation exceeds a threshold. Such high-frequency fine-granularity photon recording facilitates the analysis and recovery of dynamic scenes with high-speed motion. This paper considers the optical flow estimation problem for spike cameras. Due to the Poisson nature of incoming photons, the occurrence of spikes is random and fluctuating, making conventional image matching inefficient. We propose a Hierarchical Spatial-Temporal (HiST) fusion module for spike representation to pursue reliable feature matching and develop a robust optical flow network, dubbed as HiST-SFlow. The HiST extracts features at multiple moments and hierarchically fuses the spatial-temporal information. We also propose an intra-moment filtering module to further extract the feature and suppress the influence of randomness in spikes. A scene loss is proposed to ensure that this hierarchical representation recovers the essential visual information in the scene. Experimental results demonstrate that the proposed method achieves state-of-the-art performance compared with the existing methods. The source codes are available at https://github.com/ruizhao26/HiST-SFlow.",https://doi.org/10.1609/aaai.v38i7.28581,Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence and Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence and Fourteenth Symposium on Educational Advances in Artificial Intelligence
Analysis and codesign of electronic–photonic integrated circuit hardware accelerator for machine learning application,10.1007/s10825-023-02123-8,2024,f,x,X4,"mnist, no hint for drone detection",ACM,"Count: 2 | Sources: ACM, Springer Link","Mosses, A.; Joe Prathap, P. M.","Innovations in deep learning technology have recently focused on photonics as a computing medium. Integrating an electronic and photonic approach is the main focus of this work utilizing various photonic architectures for machine learning applications. The speed, power, and reduced footprint of these photonic hardware accelerators (HA) are expected to greatly enhance inference. In this work, we propose a hybrid design of an electronic and photonic integrated circuit (EPIC) hardware accelerator (EPICHA), an electronic–photonic framework that uses architecture-level integrations for better performance. The proposed EPICHA has a systematic structure of reconfigurable directional couplers (RDCs) to build a scalable, efficient machine learning accelerator for inference applications. In the simulation framework, the input and output layers of a fully integrated photonic neural network use the same integrated photodetector and RDC technology as the activation function. Our system only compromises on latency because of the electro–optical conversion process and the hand-off between the electronic and photonic domains. Insertion losses in photonic components have a small negative impact on accuracy when using more deep learning stages. Our proposed EPICHA utilizes coherent operation, and hence uses a single wavelength of λ = 1550&nbsp;nm. We used the interoperability feature of the Ansys Lumerical MODE, DEVICE, and INTERCONNECT tools for component modeling in the photonic and electrical domain, and circuit-level simulation using S-parameters with MATLAB. The electronic component acts as the controller, which generates the required analog voltage control signals for each RDC present in the photonic processing engine. We employed MathWorks MATLAB 2022b for the classification of handwritten digits from the MNIST database; the proposed coherent EPICHA achieved accuracy of 94%.",https://doi.org/10.1007/s10825-023-02123-8,J. Comput. Electron.
Unveiling the frontiers of deep learning: Innovations shaping diverse domains,10.1007/s10489-025-06259-x,2025,f,x,X4,,ACM,,"Ahmed, Shams Forruque; Alam, Md. Sakib Bin; Kabir, Maliha; Afrin, Shaila; Rafa, Sabiha Jannat; Mehjabin, Aanushka; Gandomi, Amir H.",,https://doi.org/10.1007/s10489-025-06259-x,Applied Intelligence
Isolating Uncertainty of the Face Expression Recognition with the Meta-Learning Supervisor Neural Network,10.1145/3480433.3480447,2021,t,x,X4,,ACM,,"Selitskiy, Stanislav; Christou, Nikolaos; Selitskaya, Natalya","We investigate whether the well-known poor performance of the head-on usage of the convolutional neural networks for the facial expression recognition task may be improved in terms of reducing the false positive and false negative errors. An uncertainty isolating technique is used that introduces an additional “unknown” class. A self-attention supervisor artificial neural network is used to “learn about learning” of the underlying convolutional neural networks, in particular, to learn patterns of the underlying neural network parameters that accompany wrong or correct verdicts. A novel data set containing artistic makeup and occlusions images is used to aggravate the problem of the training data not representing the test data distribution.",https://doi.org/10.1145/3480433.3480447,2021 5th International Conference on Artificial Intelligence and Virtual Reality (AIVR)
Dual-mode Index Modulation based on Affine Frequency Division Multiplexing,10.1016/j.phycom.2025.102628,2025,f,x,X1,communication standard,ACM,,"A., Anoop; Thomas, Christo Kurisummoottil; S., Kala; Benifa, J.V. Bibal; Saad, Walid",,https://doi.org/10.1016/j.phycom.2025.102628,Phys. Commun.
Network traffic feature representation with contrastive learning for traffic engineering in hybrid software defined networks,10.1016/j.jnca.2025.104270,2025,t,x,X4,network traffic,ACM,,"Zhou, Weihong; Yang, Ruiyu; Guo, Yingya; Luo, Huan",,https://doi.org/10.1016/j.jnca.2025.104270,J. Netw. Comput. Appl.
Edge computing in Internet of Vehicles: A federated learning method based on Stackelberg dynamic game,10.1016/j.ins.2024.121452,2025,a,x,X4,,ACM,,"Kang, Hong-Shen; Chai, Zheng-Yi; Li, Ya-Lun; Huang, Hao; Zhao, Ying-Jie",,https://doi.org/10.1016/j.ins.2024.121452,Inf. Sci.
Performance of evolutionary wavelet neural networks in acrobot control tasks,10.1007/s00521-019-04347-x,2020,t,x,X4,control,ACM,,"Khan, Maryam Mahsal; Mendes, Alexandre; Chalup, Stephan K.","Wavelet neural networks (WNN) combine the strength of artificial neural networks and the multiresolution ability of wavelets. Determining the structure and, more specifically, the appropriate number of neurons in a WNN is a time-consuming process. We propose a type of multidimensional evolutionary WNN and, using an acrobot, evaluate this approach with two benchmark nonlinear control tasks: a height task and a hand-stand task. To facilitate direct comparison with other methods, we report on swing-up and balance times. In 50 trials, the controllers produced faster swing-up times—1.0 s for the best controller and 2.3 s on average—than any other methods reported in the literature. Moreover, the controller with the best swing-up time had a maximum balance time of 1.25 s, surpassing most other methods.",https://doi.org/10.1007/s00521-019-04347-x,Neural Comput. Appl.
Trajectory prediction of flying vehicles based on deep learning methods,10.1007/s10489-022-04098-8,2022,f,x,X4,,ACM,,"Tan, Minghu; Shen, Hong; Xi, Kang; Chai, Bin","To deal with the threat from flying vehicles, it is of great significance to accurately predict the flight trajectory of flying vehicles using the known historical position data. In this paper, we investigate eight typical types of maneuvers of flying vehicles. Then, according to the kinematics model of the flying vehicle, eight kinds of typical maneuver trajectory equations are introduced. Next, the data set for neural network training is created by varying the critical parameters of the trajectory equation. Accordingly, we train the offline Long-Short Term Memory (LSTM) using 1/12 of the dataset of trajectories, and results show that the trained network can classify types of trajectories accurately. Based on the results of classification using the offline LSTM, we propose two trajectory prediction methods, and both of them achieve excellent prediction with and without noise interference. Furthermore, we propose an online prediction method, and it can accurately predict the subsequent trajectory of flying vehicles when the type of trajectory is not clear. And we propose a filter to improve the accuracy of the online prediction method for trajectory prediction with noise. The simulation results verify that all three previously proposed methods can accurately predict the next move based on historical data.",https://doi.org/10.1007/s10489-022-04098-8,Applied Intelligence
A review of green artificial intelligence: Towards a more sustainable future,10.1016/j.neucom.2024.128096,2024,f,x,X4,mention only drones as data collector,ACM,,"Bolón-Canedo, Verónica; Morán-Fernández, Laura; Cancela, Brais; Alonso-Betanzos, Amparo",,https://doi.org/10.1016/j.neucom.2024.128096,Neurocomput.
A Trajectory Evaluator by Sub-tracks for Detecting VOT-based Anomalous Trajectory,10.1145/3490032,2022,t,x,X4,,ACM,,"Gao, Fei; Li, Jiada; Ge, Yisu; Shao, Jianwen; Lu, Shufang; Weng, Libo","With the popularization of visual object tracking (VOT), more and more trajectory data are obtained and have begun to gain widespread attention in the fields of mobile robots, intelligent video surveillance, and the like. How to clean the anomalous trajectories hidden in the massive data has become one of the research hotspots. Anomalous trajectories should be detected and cleaned before the trajectory data can be effectively used. In this article, a Trajectory Evaluator by Sub-tracks (TES) for detecting VOT-based anomalous trajectory is proposed. Feature of Anomalousness is defined and described as the Eigenvector of classifier to filter Track Lets anomalous trajectory and IDentity Switch anomalous trajectory, which includes Feature of Anomalous Pose and Feature of Anomalous Sub-tracks (FAS). In the comparative experiments, TES achieves better results on different scenes than state-of-the-art methods. Moreover, FAS makes better performance than point flow, least square method fitting and Chebyshev Polynomial Fitting. It is verified that TES is more accurate and effective and is conducive to the sub-tracks trajectory data analysis.",https://doi.org/10.1145/3490032,ACM Trans. Knowl. Discov. Data
Rethinking Similar Object Interference in Single Object Tracking,10.1145/3638584.3638644,2024,f,x,X2,"no SNN, and SOI dataset doesn’t contain drone afaik",ACM,,"Wang, Yipei; Hu, Shiyu; Zhao, Xin","Similar object interference (SOI) problem challenges the single object tracking (SOT) task, leading to the failure of feature-based trackers and subsequent performance degradation. Unfortunately, current generic SOT benchmarks do not effectively tackle this critical challenge, while popular SOT algorithms consistently underestimate the influence they have on tracking performance. To bridge this gap and further enhance the investigation of similar object interference in SOT, we adopt the following viewpoints: (1) By examining the operational principles of mainstream trackers and their performance on representative SOT datasets, we redefine similar objects, taking into account the cognitive bias that exists between trackers and humans when dealing with this challenge. (2) Subsequently, we develop a mining methodology that enables the extraction of the SOI sub-dataset from SOT datasets without relying on human intervention. This methodology comprises two main components: determining the SOI challenge and screening the SOI sequences. The SOI dataset is acquired from representative SOT dataset using our proposed approach, known as SOI2023. This dataset serves as an ideal environment to facilitate the investigation of challenges related to similar object interference. (3) Additionally, we conduct extensive tracking experiments with 20 typical trackers and their variants on SOI2023 and analyze their performance for similar object interference scenes in several dimensions. The experimental results demonstrate the effectiveness of our proposed mining method, while revealing the strengths and weaknesses of current trackers when faced with the challenge of similar object interference. We hope this work can provide inspiration to the tracking community and also provide support and insights for robust tracking under the SOI challenge.",https://doi.org/10.1145/3638584.3638644,Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence
Parallel hyperparameter optimization of spiking neural networks,10.1016/j.neucom.2024.128483,2024,f,x,X4,"MNIST, gesture but no drone detection",ACM,,"Firmin, Thomas; Boulet, Pierre; Talbi, El-Ghazali",,https://doi.org/10.1016/j.neucom.2024.128483,Neurocomput.
HDPG: hyperdimensional policy-based reinforcement learning for continuous control,10.1145/3489517.3530668,2022,t,x,X4,,ACM,,"Ni, Yang; Issa, Mariam; Abraham, Danny; Imani, Mahdi; Yin, Xunzhao; Imani, Mohsen","Traditional robot control or more general continuous control tasks often rely on carefully hand-crafted classic control methods. These models often lack the self-learning adaptability and intelligence to achieve human-level control. On the other hand, recent advancements in Reinforcement Learning (RL) present algorithms that have the capability of human-like learning. The integration of Deep Neural Networks (DNN) and RL thereby enables autonomous learning in robot control tasks. However, DNN-based RL brings both high-quality learning and high computation cost, which is no longer ideal for currently fast-growing edge computing scenarios.In this paper, we introduce HDPG, a highly-efficient policy-based RL algorithm using Hyperdimensional Computing. Hyperdimensional computing is a lightweight brain-inspired learning methodology; its holistic representation of information leads to a well-defined set of hardware-friendly high-dimensional operations. Our HDPG fully exploits the efficient HDC for high-quality state value approximation and policy gradient update. In our experiments, we use HDPG for robotics tasks with continuous action space and achieve significantly higher rewards than DNN-based RL. Our evaluation also shows that HDPG achieves 4.7× faster and 5.3× higher energy efficiency than DNN-based RL running on embedded FPGA.",https://doi.org/10.1145/3489517.3530668,Proceedings of the 59th ACM/IEEE Design Automation Conference
Flow-event autoencoder: event stream object recognition dataset generation with arbitrary high temporal resolution,10.1609/aaai.v38i21.30545,2024,f,x,X4,,ACM,,"Chen, Minghai","Event camera has unique advantages in high temporal resolution and dynamic range. However, due to the novelty of this hardware, there's a lack of large benchmark DVS event-stream datasets, including datasets for object recognition. In this work, we proposed an encoder-decoder method to augment event stream dataset from image and optical flow with arbitrary temporal resolution for object recognition task. We believe this proposed method can be generalized well in augmenting event stream vision data for object recognition and will help advance the development of event vision paradigm.",https://doi.org/10.1609/aaai.v38i21.30545,Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence and Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence and Fourteenth Symposium on Educational Advances in Artificial Intelligence
Process planning of parameter intelligent adjustment for batch machining based on historical data segmented modeling,10.1016/j.engappai.2025.110180,2025,a,x,X4,,ACM,,"Lu, Juan; Tu, Shiying; Li, Ying; Zhang, Liang; Liao, Xiaoping",,https://doi.org/10.1016/j.engappai.2025.110180,Eng. Appl. Artif. Intell.
Deep learning techniques to detect cybersecurity attacks: a systematic mapping study,10.1007/s10664-023-10302-1,2023,t,x,X4,,ACM,,"Torre, Damiano; Mesadieu, Frantzy; Chennamaneni, Anitha",,https://doi.org/10.1007/s10664-023-10302-1,Empirical Softw. Engg.
ST-CSNN: a novel method for vehicle counting,10.1007/s00138-021-01233-2,2021,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Yin, Kang; Wang, Liantao; Zhang, Jinxia","Vehicle counting using computer vision techniques has potential to alleviate traffic congestion in intelligent transportation system. In this paper, we propose a novel method to count vehicles in a human-like manner. This paper has two main contributions. Firstly, we propose ST-CSNN, which is an efficient, lightweight vehicle counting method. The method counts based on vehicle identity comparison to omit duplicate instances. Combined with the spatio-temporal information between frames, it is able to accelerate speed and improve accuracy of counting. Secondly, we strengthen the method’s performance by proposing an improved loss function on the basis of Siamese neural network. Besides, we conduct experiments on several datasets to evaluate the performance of the proposed loss function for verification and the whole method for counting. The experimental results show the practicability of this method for real counting scenes.",https://doi.org/10.1007/s00138-021-01233-2,Mach. Vision Appl.
Artificial Intelligence for Safety-Critical Systems in Industrial and Transportation Domains: A Survey,10.1145/3626314,2024,f,x,"X2,X4",,ACM,,"Perez-Cerrolaza, Jon; Abella, Jaume; Borg, Markus; Donzella, Carlo; Cerquides, Jesús; Cazorla, Francisco J.; Englund, Cristofer; Tauber, Markus; Nikolakopoulos, George; Flores, Jose Luis","Artificial Intelligence (AI) can enable the development of next-generation autonomous safety-critical systems in which Machine Learning (ML) algorithms learn optimized and safe solutions. AI can also support and assist human safety engineers in developing safety-critical systems. However, reconciling both cutting-edge and state-of-the-art AI technology with safety engineering processes and safety standards is an open challenge that must be addressed before AI can be fully embraced in safety-critical systems. Many works already address this challenge, resulting in a vast and fragmented literature. Focusing on the industrial and transportation domains, this survey structures and analyzes challenges, techniques, and methods for developing AI-based safety-critical systems, from traditional functional safety systems to autonomous systems. AI trustworthiness spans several dimensions, such as engineering, ethics and legal, and this survey focuses on the safety engineering dimension.",https://doi.org/10.1145/3626314,ACM Comput. Surv.
OFPO &amp; KGFPO: Ontology and knowledge graph for flood process observation,10.1016/j.envsoft.2025.106317,2025,t,x,X4,,ACM,,"Du, Wenying; Liu, Chang; Xia, Qingyun; Wen, Mengtian; Hu, Ying; Chen, Zeqiang; Xu, Lei; Zhang, Xiang; Terfa, Berhanu Keno; Chen, Nengcheng",,https://doi.org/10.1016/j.envsoft.2025.106317,Environ. Model. Softw.
Improving robustness and efficiency of edge computing models,10.1007/s11276-022-03115-5,2022,a,x,X4,,ACM,,"Li, Yilan; Lu, Yantao; Cui, Helei; Velipasalar, Senem","Existing designs of edge computing models are mostly targeted to improve the performance of accuracy. Yet, besides accuracy, robustness and inference efficiency are also crucial attributes to the performance. To achieve satisfied performance in edge-cloud computing frameworks, each distributed model is required to be both robust to perturbations and feasible for information uploading in wireless environments with limited bandwidth. In other words, feature encoders should be more robust and have faster inference time while maintaining accuracy at a competitive level. Therefore, to design accurate, robust and efficient models for bandwidth limited edge computing, we propose a systematic approach to autonomously optimize parameters and architectures of arbitrary deep neural networks. This approach employs a genetic algorithm based bi-generative adversarial network, which is utilized to autonomously develop and select the number of filters (for convolutional layers) and the number of neurons (for fully connected layers) from a wide range of values. To demonstrate the performance, we test our approach on ImageNet and ModelNet databases, and compare it with the state-of-the-art 3D volumetric network and two exclusively GA-based methods. Our results show that the proposed method can significantly improve performance by simultaneously optimizing multiple neural network parameters, regardless of the depth of the network.",https://doi.org/10.1007/s11276-022-03115-5,Wirel. Netw.
Energy-Efficient Approximate Edge Inference Systems,10.1145/3589766,2023,f,x,"X2,X4",,ACM,,"Ghosh, Soumendu Kumar; Raha, Arnab; Raghunathan, Vijay","The rapid proliferation of the Internet of Things and the dramatic resurgence of artificial intelligence based application workloads have led to immense interest in performing inference on energy-constrained edge devices. Approximate computing (a design paradigm that trades off a small degradation in application quality for disproportionate energy savings) is a promising technique to enable energy-efficient inference at the edge. This article introduces the concept of an approximate edge inference system (AxIS) and proposes a systematic methodology to perform joint approximations between different subsystems in a deep neural network (DNN)-based edge inference system, leading to significant energy benefits compared to approximating individual subsystems in isolation. We use a smart camera system that executes various DNN-based image classification and object detection applications to illustrate how the sensor, memory, compute, and communication subsystems can all be approximated synergistically. We demonstrate our proposed methodology using two variants of a smart camera system: (a) CamEdge, where the DNN is executed locally on the edge device, and (b) CamCloud, where the edge device sends the captured image to a remote cloud server that executes the DNN. We have prototyped such an approximate inference system using an Intel Stratix IV GX-based Terasic TR4-230 FPGA development board. Experimental results obtained using six large DNNs and four compact DNNs running image classification applications demonstrate significant energy savings (≈ 1.6× -4.7× for large DNNs and ≈ 1.5× -3.6× for small DNNs), for minimal (&lt;1%) loss in application-level quality. Furthermore, results using four object detection DNNs exhibit energy savings of ≈ 1.5× -5.2× for similar quality loss. Compared to approximating a single subsystem in isolation, AxIS achieves 1.05× -3.25× gains in energy savings for image classification and 1.35× -4.2× gains for object detection on average, for minimal (&lt;1%) application-level quality loss.",https://doi.org/10.1145/3589766,ACM Trans. Embed. Comput. Syst.
Adaptive neural output feedback control of automobile PEM fuel cell air-supply system with prescribed performance,10.1007/s10489-022-03765-0,2022,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Wang, Yunlong; Liu, Yan; Wang, Yongfu","Oxygen excess ratio (OER) is a key specification of fuel cells, which influences the net power and health state. To reconstitute the unmeasurable variable and achieve precise tracking accuracy, the observer-based adaptive neural network control using a prescribed performance function is proposed for the polymer electrolyte membrane (PEM) fuel cell air-supply system. Firstly, an observer is designed to recover the unmeasurable variable based on the transformed canonical system. Secondly, a finite-time prescribed performance function is constructed to guarantee the maximal overshoot and steady-state tracking error within the quantitative boundary. The contribution of the proposed control scheme can be concluded that: 1) the different errors are simultaneously used to update the neural network weights for the improvement of the observer performance; 2) the restriction that the initial error is required to be within the performance function bound is relaxed by proposing a tuning function and 3) the convergence time and residual set of OER tracking error can be determined qualitatively. The signals included in the air-supply system are proved to be uniformly ultimately bounded. Different numerical simulations and hardware-in-loop (HIL) experiments show that the more accurate estimation is provided by the proposed observer. Meanwhile, the tracking errors are restricted within the predefined bounds. From the experimental results, the proposed observer and controller show the best performance indexes including the root mean square error (RMSE), the mean absolute error (MAE) and the standard deviation (SD) in different conditions.",https://doi.org/10.1007/s10489-022-03765-0,Applied Intelligence
"Random vector functional link network: Recent developments, applications, and future directions",10.1016/j.asoc.2023.110377,2023,f,x,X4,,ACM,,"Malik, A.K.; Gao, Ruobin; Ganaie, M.A.; Tanveer, M.; Suganthan, Ponnuthurai Nagaratnam",,https://doi.org/10.1016/j.asoc.2023.110377,Appl. Soft Comput.
Federated learning for energy constrained devices: a systematic mapping study,10.1007/s10586-022-03763-4,2022,f,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","El Mokadem, Rachid; Ben Maissa, Yann; El Akkaoui, Zineb","Federated machine learning (Fed ML) is a new distributed machine learning technique using clients’ local data applied to collaboratively train a global model without transmitting the datasets. Nodes, the participating devices in the ML training, only send parameter updates (e.g., weight updates in the case of neural networks), which are fused together by the server to build the global model without compromising raw data privacy. Fed ML guarantees its confidentiality by not divulging node data to third party, central servers. Privacy of data is a crucial network security aspect of Fed ML that will enable the technique for use in the context of data-sensitive Internet of Things (IoT) and mobile applications (including smart geo-location and smart grid infrastructure). However, most IoT and mobile devices are particularly energy constrained, which requires optimization of the Fed ML process for efficient training tasks and optimized power consumption. This paper, to the best of our knowledge, is the first Systematic Mapping Study (SMS) on Fed ML for energy constrained devices. First, we selected a total of 67 from 800 papers that satisfy our criteria, then provide a structured overview of the field using a set of carefully chosen research questions. Finally, we attempt to offer an analysis of the state-of-the-art Fed ML techniques and outline potential recommendations for the research community.",https://doi.org/10.1007/s10586-022-03763-4,Cluster Computing
A Rhythmic Activation Mechanism for Soft Multi-legged Robots,10.1007/s10846-021-01345-x,2021,t,x,"X4,X1",,ACM,"Count: 2 | Sources: ACM, Springer Link","Garcia Sampaio, Rafaela Aparecida; e Silva, Fabrício Lopes; de Carvalho, Cristiano de Souza; Araujo, Gabriel Matos; Pinto, Milena Faria; Haddad, Diego Barreto; França, Felipe Maia Galvão","Compared to standard solutions, soft robotics presents enhanced adaptability to unpredictable and unstructured environments, encompassing advances in fabrication, modeling, and control. The absence of a general theory for the latter is one of the biggest challenges in the field, which constrains these robots’ employment in real-world applications. This research proposes the application of Scheduling by Multiple Edge Reversal (SMER) in the activation of soft legs to be applied in multi-legged robots. A soft device was developed to be tested as a robot’s leg to evaluate the proposed application. A logic controller for this device was designed using the SMER technique. Image processing techniques were used to assess the functionality of the proposed strategy, which demands limited resources. The vision tracking system is composed of a set of infrared-reflective patches, an infrared illuminator, and a pair of cameras with no infrared filters. Results revealed that it is possible to use SMER techniques to activate soft robotics systems and that the methods employed to develop and test the device were appropriate.",https://doi.org/10.1007/s10846-021-01345-x,J. Intell. Robotics Syst.
Survey of Quantization-Aware Training (QAT) Applications in Deep Learning Quantization,10.1145/3776759.3776826,2025,f,x,X4,,ACM,,"Zhang, Jiaqi","With the rapid expansion of the AI era, data volumes and computational demands have grown significantly. Quantization-Aware Training (QAT), introduced in 2018, has emerged as a mainstream approach for enabling the quantization of large-scale models while preserving accuracy under constrained hardware resources. In recent years (2024–2025), QAT has been extensively applied in domains such as image recognition, large language models, and diffusion models. However, these applications have also revealed critical challenges, including unstable gradient propagation, increased computational complexity, and significant accuracy degradation under low-bit quantization. Although numerous improved QAT methods have been proposed, they remain fragmented and lack a systematic review. This paper provides a comprehensive survey of QAT by (i) tracing its historical development, (ii) clarifying its core definition, (iii) contrasting QAT with Post-Training Quantization (PTQ), and (iv) summarizing its applications across major fields. Furthermore, we categorize existing literature into six primary problem areas and four classes of solution strategies. As a survey, this work aims to offer researchers a structured perspective on QAT and to serve as a reference for future efforts in optimizing quantization techniques and facilitating practical deployment.",https://doi.org/10.1145/3776759.3776826,Proceedings of the 2025 International Symposium on Artificial Intelligence and Computational Social Sciences
Event-driven temporal models for explanations - ETeMoX: explaining reinforcement learning,10.1007/s10270-021-00952-4,2022,t,x,X4,,ACM,,"Parra-Ullauri, Juan Marcelo; García-Domínguez, Antonio; Bencomo, Nelly; Zheng, Changgang; Zhen, Chen; Boubeta-Puig, Juan; Ortiz, Guadalupe; Yang, Shufan","Modern software systems are increasingly expected to show higher degrees of autonomy and self-management to cope with uncertain and diverse situations. As a consequence, autonomous systems can exhibit unexpected and surprising behaviours. This is exacerbated due to the ubiquity and complexity of Artificial Intelligence (AI)-based systems. This is the case of Reinforcement Learning (RL), where autonomous agents learn through trial-and-error how to find good solutions to a problem. Thus, the underlying decision-making criteria may become opaque to users that interact with the system and who may require explanations about the system’s reasoning. Available work for eXplainable Reinforcement Learning (XRL) offers different trade-offs: e.g. for runtime explanations, the approaches are model-specific or can only analyse results after-the-fact. Different from these approaches, this paper aims to provide an online model-agnostic approach for XRL towards trustworthy and understandable AI. We present ETeMoX, an architecture based on temporal models to keep track of the decision-making processes of RL systems. In cases where the resources are limited (e.g. storage capacity or time to response), the architecture also integrates complex event processing, an event-driven approach, for detecting matches to event patterns that need to be stored, instead of keeping the entire history. The approach is applied to a mobile communications case study that uses RL for its decision-making. In order to test the generalisability of our approach, three variants of the underlying RL algorithms are used: Q-Learning, SARSA and DQN. The encouraging results show that using the proposed configurable architecture, RL developers are able to obtain explanations about the evolution of a metric, relationships between metrics, and were able to track situations of interest happening over time windows.",https://doi.org/10.1007/s10270-021-00952-4,Softw. Syst. Model.
A fully pipelined FPGA accelerator for scale invariant feature transform keypoint descriptor matching,10.1016/j.micpro.2019.102919,2020,t,x,X4,,ACM,,"Daoud, Luka; Latif, Muhammad Kamran; Jacinto, H.S.; Rafla, Nader",,https://doi.org/10.1016/j.micpro.2019.102919,Microprocess. Microsyst.
Modelling Drosophila motion vision pathways for decoding the direction of translating objects against cluttered moving backgrounds,10.1007/s00422-020-00841-x,2020,a,x,X4,,ACM,,"Fu, Qinbing; Yue, Shigang","Decoding the direction of translating objects in front of cluttered moving backgrounds, accurately and efficiently, is still a challenging problem. In nature, lightweight and low-powered flying insects apply motion vision to detect a moving target in highly variable environments during flight, which are excellent paradigms to learn motion perception strategies. This paper investigates the fruit fly Drosophila motion vision pathways and presents computational modelling based on cutting-edge physiological researches. The proposed visual system model features bio-plausible ON and OFF pathways, wide-field horizontal-sensitive (HS) and vertical-sensitive (VS) systems. The main contributions of this research are on two aspects: (1) the proposed model articulates the forming of both direction-selective and direction-opponent responses, revealed as principal features of motion perception neural circuits, in a feed-forward manner; (2) it also shows robust direction selectivity to translating objects in front of cluttered moving backgrounds, via the modelling of spatiotemporal dynamics including combination of motion pre-filtering mechanisms and ensembles of local correlators inside both the ON and OFF pathways, which works effectively to suppress irrelevant background motion or distractors, and to improve the dynamic response. Accordingly, the direction of translating objects is decoded as global responses of both the HS and VS systems with positive or negative output indicating preferred-direction or null-direction translation. The experiments have verified the effectiveness of the proposed neural system model, and demonstrated its responsive preference to faster-moving, higher-contrast and larger-size targets embedded in cluttered moving backgrounds.",https://doi.org/10.1007/s00422-020-00841-x,Biol. Cybern.
BitBench: a benchmark for bitstream computing,10.1145/3316482.3326355,2019,a,x,X4,,ACM,,"Daruwalla, Kyle; Zhuo, Heng; Schulz, Carly; Lipasti, Mikko","With the recent increase in ultra-low power applications, researchers are investigating alternative architectures that can operate on streaming input data. These target use cases require complex algorithms that must be evaluated under a real-time deadline, but also satisfy the strict available power budget. Stochastic computing (SC) is an example of an alternative paradigm where the data is represented as single bitstreams, allowing designers to implement operations such as multiplication using a simple AND gate. Consequently, the resulting design is both low area and low power. Similarly, traditional digital filters can take advantage of streaming inputs to effectively choose coefficients, resulting in a low cost implementation. In this work, we construct six key algorithms to characterize bitstream computing. We present these algorithms as a new benchmark suite: BitBench.",https://doi.org/10.1145/3316482.3326355,"Proceedings of the 20th ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems"
Retinomorphic Sensing: A Novel Paradigm for Future Multimedia Computing,10.1145/3474085.3479237,2021,t,x,X4,,ACM,,"Kang, Zhaodong; Li, Jianing; Zhu, Lin; Tian, Yonghong","Conventional frame-based cameras for multimedia computing have encountered important challenges in high-speed and extreme light scenarios. However, how to design a novel paradigm for visual perception that overcomes the disadvantages of conventional cameras still remains an open issue. In this paper, we propose a novel solution, namely retinomorphic sensing, which integrates fovea-like and peripheral-like sampling mechanisms to generate asynchronous visual streams using a unified representation as the retina does. Technically, our encoder incorporates an interaction controller to switch flexibly between dynamic and static sensing. Then, the decoder effectively extracts dynamic events for machine vision and reconstructs visual textures for human vision. The results show that our strategy enables it to sense dynamic events and visual textures meanwhile reduce data redundancy. We further build a prototype hybrid camera system to verify this strategy on vision tasks such as image reconstruction and object detection. We believe that this novel paradigm will provide insight into future multimedia computing. The code can be available at https://github.com/acmmm2021-bni-retinomorphic/retinomorphic-sensing.",https://doi.org/10.1145/3474085.3479237,Proceedings of the 29th ACM International Conference on Multimedia
Understanding the impact of IoT security patterns on CPU usage and energy consumption: a dynamic approach for selecting patterns with deep reinforcement learning: Understanding the impact of IoT security patterns on CPU usage and energy...,10.1007/s10207-025-01011-5,2025,t,x,X4,,ACM,,"Jamshidi, Saeid; Nikanjam, Amin; Nafi, Kawser Wazed; Khomh, Foutse","The Internet of Things (IoT) introduces numerous security challenges that require effective solutions. IoT security patterns provide a practical approach to address recurring security issues, yet their impact on edge gateway metrics, e.g., energy consumption, CPU usage, and load, remains largely unexplored. This study empirically evaluates six IoT security patterns (Personal Zone Hub, trusted communication partner, outbound-only connection, blacklist, whitelist, and secure sensor node) in three IoT-edge applications: smart home, smart city, and healthcare. We evaluated the patterns individually and in combination, subjecting them to cyber threats. Subsequently, we analyzed their impact on energy consumption, CPU usage, and load. To address observed resource trade-offs, we also propose a deep reinforcement learning-based intrusion detection system that dynamically selects security patterns based on real-time conditions. Tested against threats (for example, DoS Hulk, Slowloris, DDoS, and GoldenEye), this adaptive approach optimizes security and resource efficiency, selecting the most suitable patterns for each scenario. The findings show that pattern selection significantly impacts resource metrics and that the DRL-based system maintains robust security while minimizing energy and CPU overheads. Based on these findings, we provide guidelines for developers to improve IoT-edge security by optimizing resource consumption.",https://doi.org/10.1007/s10207-025-01011-5,Int. J. Inf. Secur.
"Picking the ICT technology winners - longitudinal analysis of 21st century technologies based on the Gartner hype cycle 2008-2017: trends, tendencies, and weak signals",10.1504/ijwet.2020.113065,2020,f,x,X4,,ACM,,"Kaivo-oja, Jari; Lauraéus, Theresa; Knudsen, Mikkel Stein","We analyse longitudinal data of the 2008-2017 Gartner hype cycles and key ICT technologies (151 technologies) in the world. In this study, we have calculated six different index analyses. Our analyses use the following index analyses: 1) ranking index analysis; 2) technology power index analysis; 3) better than other technology power index analysis; 4) triangulation index analysis; 5) weak signal analysis; 6) outlayer analysis. These six analyses are novel analyses. We ranked the information from hype cycles giving a rank for every observed technology. Information of calculations is public and open in the internet publications of the Gartner Ltd. We were able to see the top ten technologies: 1) augmented reality; 2) human augmentation; 3) quantum computing; 4) speech recognition; 5) mobile robots; 6) autonomous vehicles; 7) speech-to-speech translation; 8) mesh network sensor; 9) local-aware applications; 10) idea management.",https://doi.org/10.1504/ijwet.2020.113065,Int. J. Web Eng. Technol.
The Application of Deep Learning in Image Deblurring,10.1145/3690407.3690586,2024,f,x,X1,drone landing,ACM,,"Jiang, Chengchao; Hu, Lei; Jia, Guotao","Images are an important medium for people to obtain information. In the process of acquiring images, it is inevitable that images will become blurred due to various reasons. Image restoration is a technical method that uses algorithms to enhance image quality and is an important research field in computer vision. It is widely used in industrial, agricultural, and medical image processing. In recent years, with the rapid development of deep learning technology, an increasing number of image restoration algorithms based on deep neural networks have been proposed. This paper mainly introduces image restoration technology based on deep neural networks from the perspective of image deblurring. The paper first elaborates on the overall classification of image restoration algorithms, then discusses the causes of image blurring and commonly used traditional algorithms, deep learning algorithms, and models. Finally, the paper summarizes the advantages and disadvantages of various image restoration methods and prospects for the future development of image restoration technology.",https://doi.org/10.1145/3690407.3690586,"Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms"
Multiple particle tracking in time-lapse synchrotron X-ray images using discriminative appearance and neighbouring topology learning,10.1016/j.patcog.2019.05.007,2019,t,x,X4,,ACM,,"Jung, Hye-Won; Lee, Sang-Heon; Donnelley, Martin; Parsons, David; Stamatescu, Victor; Lee, Ivan",,https://doi.org/10.1016/j.patcog.2019.05.007,Pattern Recogn.
Prediction of Soybean Yield using Self-normalizing Neural Networks,10.1145/3409073.3409092,2020,t,x,X4,,ACM,,"Shu, Kaki","Nowadays, agriculture around the world is facing severe challenges because of global warming and rapid population growth. In order to maximize the agricultural production and minimize the environmental degradation at the same time, careful land-use planning and crop selection come to be crucial, where accurate crop yield prediction plays a key role. This research applies an emerging Deep Learning architecture called Self-normalizing neural networks (SNN) for yield prediction of the soybean, using numerical data obtained from official statistics to ensure high reliability and availability of data. Plentiful work has been done to improve the performance, including careful parameter tuning and application of early stopping and the learning rate scheduler. This study conducts an experiment to evaluate the performance of the model, and the results show that SNN can achieve a lower prediction error with sufficiently large training data compared with traditional machine learning methods, such as Support Vector Regression, and other Deep Learning techniques, such as Batch Normalization.",https://doi.org/10.1145/3409073.3409092,Proceedings of the 2020 5th International Conference on Machine Learning Technologies
CMPFNet: semantic segmentation network for cross-modal phased fusion in extreme light scenes,10.1007/s10044-025-01569-9,2025,f,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Han, Jing; Tian, Zihe; Gao, Koukou; Lyu, Xueqiang","Reliable perception systems are crucial for the stable operation of applications such as autonomous driving and night-time security under extreme lighting conditions, including darkness and low light. The environmental perception modules within these systems typically rely on the precise segmentation of single-frame images. However, Existing RGB-infrared segmentation models often overlook modality discrepancies in feature fusion and suffer from detail loss due to repeated downsampling. To address these issues, we propose CMPFNet (Cross-modal Phased Fusion Net), a semantic segmentation model designed for extreme lighting conditions. CMPFNet employs a two-branch structure to capture local and global features, enhancing the segmentation accuracy of small targets. We introduce a feature rectification and fusion module to mitigate inter-modality gaps and improve feature interaction via multimodal rectification and attention mechanisms. A feature recovery module is introduced to restore fine details lost in deep layers, while a multi-scale decoding module reduce noise interference across scales. Experiments on MFNet and PST900 datasets demonstrate that CMPFNet outperforms mainstream methods, achieving a 60.6% mIoU on MFNet, a 1.7% improvement over the previous best method, validating its effectiveness. This approach provides a technical foundation for robust environmental perception in the above-mentioned scenarios. Code is available at .",https://doi.org/10.1007/s10044-025-01569-9,Pattern Anal. Appl.
Remote glacier monitoring through semantic fusion of geographic and contextual data,10.1016/j.engappai.2025.111366,2025,t,x,X4,,ACM,,"Albamonte, Giacomo; Falcone, Giorgio; Senatore, Sabrina",,https://doi.org/10.1016/j.engappai.2025.111366,Eng. Appl. Artif. Intell.
Accurate indoor location awareness based on machine learning of environmental sensing data,10.1016/j.compeleceng.2021.107676,2022,t,x,X4,,ACM,,"Ge, Hangli; Sun, Zhe; Chiba, Yasuhira; Koshizuka, Noboru",,https://doi.org/10.1016/j.compeleceng.2021.107676,Comput. Electr. Eng.
Motion segmentation with event camera: N-patches optical flow estimation and Pairwise Markov Random Fields,10.1016/j.eswa.2024.124342,2024,f,x,X2,"drone detection but no SNN involved, only event-based camera and also not SNN performance reported",ACM,,"Liu, Xinghua; Zhao, Yunan; Wen, Shiping; Chen, Badong; Ge, Shuzhi Sam",,https://doi.org/10.1016/j.eswa.2024.124342,Expert Syst. Appl.
System Modeling for Prognostic Reasoning and Insight Exploration of Arecanut Crop Using Data Analytics and Formal Statistical Approach,10.1007/s11277-024-11407-6,2024,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Pakkala, Permanki Guthu Rithesh; Rai, Bellipady Shamantha","Agriculture is the primary source of income for the majority of the Indian farming community. Plantation crops play a significant part in improving the farmers' economic condition. The proposed work aims to develop a system model for prognostic reasoning by analyzing the impact of fertilizer and irrigation on areca nut crop yield, as well as to predict diseases that may affect areca nut palms using data analytics and a formal statistical approach. The dataset is constructed by interacting with the farmers in the Mangaluru region of Karnataka, India. To find the optimal features, the formal statistical test chi-square is applied. The performance of various classifiers, such as Logistic Regression, Nave Bayes, Support Vector Machine, Decision Tree, and Random Forest, is examined during prognostic reasoning. For disease prediction and crop yield, the decision tree outperformed other classifiers with an accuracy of 96% and 95.86%, respectively. The most significant irrigation type and fertilizer for increasing areca nut crop yield are also identified.",https://doi.org/10.1007/s11277-024-11407-6,Wirel. Pers. Commun.
Fusion of intelligent learning for COVID-19: A state-of-the-art review and analysis on real medical data,10.1016/j.neucom.2021.06.024,2021,t,x,X4,,ACM,,"Ding, Weiping; Nayak, Janmenjoy; Swapnarekha, H.; Abraham, Ajith; Naik, Bighnaraj; Pelusi, Danilo",,https://doi.org/10.1016/j.neucom.2021.06.024,Neurocomput.
Robust stereo inertial odometry based on self-supervised feature points,10.1007/s10489-022-03278-w,2022,f,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Li, Guangqiang; Hou, Junyi; Chen, Zhong; Yu, Lei; Fei, Shumin","In the application of intelligent mobile robots, the odometry is the key system for implementing positioning. Traditional feature extraction algorithms can not work stably in challenging environments such as low-textured areas, and when the camera moves rapidly, the visual odometry can not track features. To solve the above problems, the paper proposes a robust stereo inertial odometry based on self-supervised feature points. An improved multi-task CNN is designed to extract the feature points in the images acquired by the stereo camera. In addition, we add the Inertial Measurement Unit (IMU) to cope with the rapid motion of the camera. Finally, the fixed number of key frames and IMU errors are optimized in the sliding window by minimizing a combined error function. The experimental results show that the proposed system can run in challenging scenes and maintain real-time performance. The overall performance of the proposed system is better than that of the classical stereo inertial odometry systems, and it is still competitive with the state-of-the-art methods.",https://doi.org/10.1007/s10489-022-03278-w,Applied Intelligence
Contents,10.1016/S1877-0509(17)30187-4,2017,f,x,X4,"whole collection, but no drone detection papers in it, just control with SNNs",ACM,,,,https://doi.org/10.1016/S1877-0509(17)30187-4,Procedia Comput. Sci.
Neural predictive monitoring and a comparison of frequentist and Bayesian approaches,10.1007/s10009-021-00623-1,2021,f,x,"X4,X2",,ACM,"Count: 2 | Sources: ACM, Springer Link","Bortolussi, Luca; Cairoli, Francesca; Paoletti, Nicola; Smolka, Scott A.; Stoller, Scott D.","Neural state classification (NSC) is a recently proposed method for runtime predictive monitoring of hybrid automata (HA) using deep neural networks (DNNs). NSC trains a DNN as an approximate reachability predictor that labels an HA state x as positive if an unsafe state is reachable from x within a given time bound, and labels x as negative otherwise. NSC predictors have very high accuracy, yet are prone to prediction errors that can negatively impact reliability. To overcome this limitation, we present neural predictive monitoring (NPM), a technique that complements NSC predictions with estimates of the predictive uncertainty. These measures yield principled criteria for the rejection of predictions likely to be incorrect, without knowing the true reachability values. We also present an active learning method that significantly reduces the NSC predictor’s error rate and the percentage of rejected predictions. We develop two versions of NPM based, respectively, on the use of frequentist and Bayesian techniques to learn the predictor and the rejection rule. Both versions are highly efficient, with computation times on the order of milliseconds, and effective, managing in our experimental evaluation to successfully reject almost all incorrect predictions. In our experiments on a benchmark suite of six hybrid systems, we found that the frequentist approach consistently outperforms the Bayesian one. We also observed that the Bayesian approach is less practical, requiring a careful and problem-specific choice of hyperparameters.",https://doi.org/10.1007/s10009-021-00623-1,Int. J. Softw. Tools Technol. Transf.
Echo State Network Optimization: A Systematic Literature Review,10.1007/s11063-023-11326-w,2023,a,x,X4,,ACM,,"Soltani, Rebh; Benmohamed, Emna; Ltifi, Hela","In the recent years, numerous studies have demonstrated the importance and efficiency of reservoir computing (RC) approaches. The choice of parameters and architecture in reservoir computing, on the other hand, frequently leads to an optimization task. This paper attempts to present an overview of the related work on echo state network (ESN) and deep echo state network (DeepESN) optimization and to collect research papers through a systematic literature review (SLR). This review covers 129 items published from 2004 to 2022 that are concerned with the issue of our focus. The collected papers are selected, analysed and discussed. The results indicate that there are two techniques of parameters optimization (bio-inspired and non-bio-inspired methods) have been extensively used for various reasons. But Different models employ bio-inspired methods for optimizing in a variety of fields. The potential use of particle swarm optimization (PSO) has also been noted. A significant portion of the research done in this field focuses on the study of reservoirs and how they behave in relation to their unique qualities. In order to test reservoirs with varied parameters, topologies, or training techniques, NARMA, the Mackey glass, and Lorenz time-series prediction dataset are the most commonly employed in the literature. This review debate diverse point of view about ESN's hyper-parameter optimization, metrics, time series benchmarks, real word applications, evaluation measures, and bio-inspired and non-bio-inspired techniques, this paper identifies and explores a number of research gaps.",https://doi.org/10.1007/s11063-023-11326-w,Neural Process. Lett.
RGB-D Visual Perception for Occluded Scenes via Event Camera,10.1007/s11263-025-02438-y,2025,a,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Li, Siqi; Wu, Zongze; Li, Yipeng; Xue, Zhou; Liu, Yu-Shen; Gao, Yue","This paper presents the first RGB-D visual perception method and dataset for densely occluded scenes. Under such dense occlusion scenarios, existing synthetic aperture imaging methods could only recover the 2D appearance of the target scene. In contrast, our proposed method could see through dense foreground occlusions and recover both the 2D appearance and 3D structure of the target scene, which is more beneficial for downstream applications. To achieve this, our proposed method takes the occluded frames and event stream captured by a moving event camera as inputs, which could provide sufficient visual information about the densely occluded scene due to the high temporal resolution of the event camera. To tackle the noise interference caused by dense foreground occlusions, an occlusion segmentation module with the guidance of event epipolar-plane images is proposed to predict occlusion masks of input occluded frames and event stream. Then, invalid occlusions are excluded according to the predicted masks, and valid visual features are extracted to simultaneously predict the appearance and structure of the target scene. A lightweight high-order conditional random fields module is proposed to model multi-pixel higher-order correlations, making pixels with similar color and structure have smoother features. A cross-modal edge consistency mechanism is proposed to achieve consistent RGB-D visual perception. In addition, we construct a hybrid vision acquisition system and collect the first Event-enhanced Occluded scene RGB-D Visual Perception dataset, named THUE-OccVP, which will be released as the first RGB-D visual perception benchmark for densely occluded scenes. Experimental results show that our proposed framework achieves significantly superior results over other baseline solutions, and the ablation experiments further demonstrate the effectiveness of each proposed module.",https://doi.org/10.1007/s11263-025-02438-y,Int. J. Comput. Vision
IBISCape: A Simulated Benchmark for multi-modal SLAM Systems Evaluation in Large-scale Dynamic Environments,10.1007/s10846-022-01753-7,2022,a,x,X4,,ACM,,"Soliman, Abanob; Bonardi, Fabien; Sidibé, Désiré; Bouchafa, Samia","The development process of high fidelity SLAM systems depends on their validation upon reliable datasets. Towards this goal, we propose IBISCape, a simulated benchmark that includes data synchronization and acquisition APIs for telemetry from heterogeneous sensors: stereo-RGB/DVS, LiDAR, IMU, and GPS, along with the ground truth scene segmentation, depth maps and vehicle ego-motion. Our benchmark is built upon the CARLA simulator, whose back-end is the Unreal Engine rendering a high dynamic scenery simulating the real world. Moreover, we offer 43 datasets for Autonomous Ground Vehicles (AGVs) reliability assessment, including scenarios for scene understanding evaluation like accidents, along with a wide range of frame quality based on a dynamic weather simulation class integrated with our APIs. We also introduce the first calibration targets to CARLA maps to solve the unknown distortion parameters problem of CARLA simulated DVS and RGB cameras. Furthermore, we propose a novel pre-processing layer that eases the integration of DVS sensor events in any frame-based Visual-SLAM system. Finally, extensive qualitative and quantitative evaluations of the latest state-of-the-art Visual/Visual-Inertial/LiDAR SLAM systems are performed on various IBISCape sequences collected in simulated large-scale dynamic environments.",https://doi.org/10.1007/s10846-022-01753-7,J. Intell. Robotics Syst.
Trajectory prediction based on the dynamic characteristics and coupling relationships among vehicles in highway scenarios,10.1016/j.engappai.2024.109718,2025,t,x,X4,,ACM,,"Cong, Peichao; Deng, Murong; Xiao, Yixuan; Zhu, Yangang; Zhang, Xin",,https://doi.org/10.1016/j.engappai.2024.109718,Eng. Appl. Artif. Intell.
Multi-domain collaborative feature representation for robust visual object tracking,10.1007/s00371-021-02237-9,2021,f,x,X1,"may could also work for UAV detection, but paper was for deployed on e.g. drone → object detection/tracking",ACM,"Count: 2 | Sources: ACM, Springer Link","Zhang, Jiqing; Zhao, Kai; Dong, Bo; Fu, Yingkai; Wang, Yuxin; Yang, Xin; Yin, Baocai","Jointly exploiting multiple different yet complementary domain information has been proven to be an effective way to perform robust object tracking. This paper focuses on effectively representing and utilizing complementary features from the frame domain and event domain for boosting object tracking performance in challenge scenarios. Specifically, we propose common features extractor to learn potential common representations from the RGB domain and event domain. For learning the unique features of the two domains, we utilize a unique extractor for event based on Spiking neural networks to extract edge cues in the event domain which may be missed in RGB in some challenging conditions, and a unique extractor for RGB based on deep convolutional neural networks to extract texture and semantic information in RGB domain. Extensive experiments on standard RGB benchmark and real event tracking dataset demonstrate the effectiveness of the proposed approach. We show our approach outperforms all compared state-of-the-art tracking algorithms and verify event-based data is a powerful cue for tracking in challenging scenes.",https://doi.org/10.1007/s00371-021-02237-9,Vis. Comput.
GraphGANFed: A Federated Generative Framework for Graph-Structured Molecules Towards Efficient Drug Discovery,10.1109/TCBB.2024.3349990,2024,t,x,X4,,ACM,,"Manu, Daniel; Yao, Jingjing; Liu, Wuji; Sun, Xiang","Recent advances in deep learning have accelerated its use in various applications, such as cellular image analysis and molecular discovery. In molecular discovery, a generative adversarial network (GAN), which comprises a discriminator to distinguish generated molecules from existing molecules and a generator to generate new molecules, is one of the premier technologies due to its ability to learn from a large molecular data set efficiently and generate novel molecules that preserve similar properties. However, different pharmaceutical companies may be unwilling or unable to share their local data sets due to the geo-distributed and sensitive nature of molecular data sets, making it impossible to train GANs in a centralized manner. In this paper, we propose a &lt;underline&gt;Graph&lt;/underline&gt; convolutional network in &lt;underline&gt;G&lt;/underline&gt;enerative &lt;underline&gt;A&lt;/underline&gt;dversarial &lt;underline&gt;N&lt;/underline&gt;etworks via &lt;underline&gt;Fed&lt;/underline&gt;erated learning (GraphGANFed) framework, which integrates graph convolutional neural Network (GCN), GAN, and federated learning (FL) as a whole system to generate novel molecules without sharing local data sets. In GraphGANFed, the discriminator is implemented as a GCN to better capture features from molecules represented as molecular graphs, and FL is used to train both the discriminator and generator in a distributive manner to preserve data privacy. Extensive simulations are conducted based on the three benchmark data sets to demonstrate the feasibility and effectiveness of GraphGANFed. The molecules generated by GraphGANFed can achieve high novelty &lt;inline-formula&gt;&lt;tex-math notation=""LaTeX""&gt;(approx 100)&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;≈&lt;/mml:mo&gt;&lt;mml:mn&gt;100&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=""sun-ieq1-3349990.gif""/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; and diversity &lt;inline-formula&gt;&lt;tex-math notation=""LaTeX""&gt;(&gt; 0.9)&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mrow&gt;&lt;mml:mo&gt;(&lt;/mml:mo&gt;&lt;mml:mo&gt;&gt;&lt;/mml:mo&gt;&lt;mml:mn&gt;0&lt;/mml:mn&gt;&lt;mml:mo&gt;.&lt;/mml:mo&gt;&lt;mml:mn&gt;9&lt;/mml:mn&gt;&lt;mml:mo&gt;)&lt;/mml:mo&gt;&lt;/mml:mrow&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href=""sun-ieq2-3349990.gif""/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt;. The simulation results also indicate that 1) a lower complexity discriminator model can better avoid mode collapse for a smaller data set, 2) there is a tradeoff among different evaluation metrics, and 3) having the right dropout ratio of the generator and discriminator can avoid mode collapse.",https://doi.org/10.1109/TCBB.2024.3349990,IEEE/ACM Trans. Comput. Biol. Bioinformatics
SR-AFU: super-resolution network using adaptive frequency component upsampling and multi-resolution features,10.1007/s11704-021-0562-y,2022,a,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Chen, Ke-Jia; Wu, Mingyu; Zhang, Yibo; Chen, Zhiwei","Image super-resolution (SR) is one of the classic computer vision tasks. This paper proposes a super-resolution network based on adaptive frequency component upsampling, named SR-AFU. The network is composed of multiple cascaded dilated convolution residual blocks (CDCRB) to extract multi-resolution features representing image semantics, and multiple multi-size convolutional upsampling blocks (MCUB) to adaptively upsample different frequency components using CDCRB features. The paper also defines a new loss function based on the discrete wavelet transform, making the reconstructed SR images closer to human perception. Experiments on the benchmark datasets show that SR-AFU has higher peak signal to noise ratio (PSNR), significantly faster training speed and more realistic visual effects compared with the existing methods.",https://doi.org/10.1007/s11704-021-0562-y,Front. Comput. Sci.
Decision-making of transportation vehicle routing based on particle swarm optimization algorithm in logistics distribution management,10.1007/s10586-022-03730-z,2022,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Cai, Linya","Path planning, as the core of transportation vehicle routing decisions in logistics distribution management, has become a hotspot in logistics and distribution. In recent years, particle swarm optimization (PSO) has been proposed. In this paper, a heuristic elastic PSO algorithm was proposed for the advantages and disadvantages of different path planning algorithms. The A* algorithm was used to globally guide the path planning in the large-scale grid. The elastic PSO algorithm used the contraction operation to determine the globally optimal path formed by the local optimal nodes so that the particles can converge quickly. In addition, during the iterative process, the diversity of the particles was ensured by the rebound operation. This paper ensured the diversity of particles through rebound operation. Computer simulation and experimental results showed that the algorithm not only overcomes the disadvantage that the A* algorithm can not produce the shortest path but also avoids the problem that it can not converge to the globally optimal path due to the lack of heuristic. In addition, the algorithm indicated the simplicity and efficiency of the two algorithms. Compared with the genetic algorithm, the results showed that EPSO algorithm improved the convergence speed of particle diversity of the PSO algorithm. The global optimal path can be quickly obtained through the contraction and rebound operations of EPSO algorithm. This algorithm overcomes the shortcoming that the PSO algorithm was easy to falls into optimal local solution.",https://doi.org/10.1007/s10586-022-03730-z,Cluster Computing
"Digital twins for logistics and supply chain systems: Literature review, conceptual framework, research potential, and practical challenges",10.1016/j.cie.2023.109768,2024,t,x,X4,,ACM,,"Le, Tho V.; Fan, Ruoling",,https://doi.org/10.1016/j.cie.2023.109768,Comput. Ind. Eng.
The Computing Landscape of the 21st Century,10.1145/3301293.3302357,2019,a,x,X4,,ACM,,"Satyanarayanan, Mahadev; Gao, Wei; Lucia, Brandon","This paper shows how today's complex computing landscape can be understood in simple terms through a 4-tier model. Each tier represents a distinct and stable set of design constraints that dominate attention at that tier. There are typically many alternative implementations of hardware and software at each tier, but all of them are subject to the same set of design constraints. We discuss how this simple and compact framework has explanatory power and predictive value in reasoning about system design.",https://doi.org/10.1145/3301293.3302357,Proceedings of the 20th International Workshop on Mobile Computing Systems and Applications
Towards Formal Modeling of Subnet Based Hotspot Algorithm in Wireless Sensor Networks,10.1007/s11277-019-06346-6,2019,a,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Ali, Tariq; Yasin, Sana; Draz, Umar; Ayaz, Muhammad","Timely partition of the whole network is extremely difficult task in dynamic large-scale wireless sensor network (WSN). A lot of existing technique that solved this issue with maintaining the network status and relevant information, but these techniques do not provide the proper validation and verification and completely depend upon the simulation. Due to the distributed and heterogeneous nature of WSN, management of such environment is highly complex. The dynamic self-configuring behavior of the nodes and scalable nature of WSN may cause critical issues, like hotspot, power consumption, unnecessary delays, throughput and network lifetime. This paper, therefore, presents the Subnet Based Hotspot Algorithm (SBHA) that not only discus the strategy of network division in the form of subnets but also provide the detail verification proof of correctness. By doing so, routing path towards sink nodes become small in size that reduces the traffic load at the neighboring nodes of the sink. As a result, nodes around the sink will not early depreciate hence the chances of hotspot occurrence will be reduced, ultimately network lifetime will be increased. Firstly, we analyze SBHA with detail formal specifications in order to validate and verify the performance of proposed algorithm with VDM-SL tool box, after this we simulate the SBHA to demonstrate its accuracy and efficiency. The results analysis shows that the E2E delay and network lifetime of SBHA is comparatively 50% and 75% higher than the EE-CBA, while the energy consumption ration for 600 number of nodes consumed 750J by SBHA and 850J by EE-CBA.",https://doi.org/10.1007/s11277-019-06346-6,Wirel. Pers. Commun.
Feedback-motion-planning with simulation-based LQR-trees,10.1177/0278364916647192,2016,a,x,X4,,ACM,,"Reist, Philipp; Preiswerk, Pascal; Tedrake, Russ","The paper presents the simulation-based variant of the LQR-tree feedback-motion-planning approach. The algorithm generates a control policy that stabilizes a nonlinear dynamic system from a bounded set of initial conditions to a goal. This policy is represented by a tree of feedback-stabilized trajectories. The algorithm explores the bounded set with random state samples and, where needed, adds new trajectories to the tree using motion planning. Simultaneously, the algorithm approximates the funnel of a trajectory, which is the set of states that can be stabilized to the goal by the trajectory's feedback policy. Generating a control policy that stabilizes the bounded set to the goal is equivalent to adding trajectories to the tree until their funnels cover the set. In previous work, funnels are approximated with sums-of-squares verification. Here, funnels are approximated by sampling and falsification by simulation, which allows the application to a broader range of systems and a straightforward enforcement of input and state constraints. A theoretical analysis shows that, in the long run, the algorithm tends to improve the coverage of the bounded set as well as the funnel approximations. Focusing on the practical application of the method, a detailed example implementation is given that is used to generate policies for two example systems. Simulation results support the theoretical findings, while experiments demonstrate the algorithm's state-constraints capability, and applicability to highly-dynamic systems.",https://doi.org/10.1177/0278364916647192,Int. J. Rob. Res.
Constructing distributed time-critical applications using cognitive enabled services,10.1016/j.future.2019.04.010,2019,a,x,X4,,ACM,,"Simpkin, Chris; Taylor, Ian; Bent, Graham A.; de Mel, Geeth; Rallapalli, Swati; Ma, Liang; Srivatsa, Mudhakar",,https://doi.org/10.1016/j.future.2019.04.010,Future Gener. Comput. Syst.
Robotics in the AI era: A vision for a Hellenic Robotics Initiative,10.1561/2300000069,2021,a,x,X4,,ACM,,"Pappas, George J.; Daniilidis, Kostas; Guibas, Leonidas; Kavraki, Lydia; Koumoutsakos, Petros; Kyriakopoulos, Kostas; Lygeros, John; Triantafyllou, Michael; Tsiotras, Panagiotis","In January 2021, the Hellenic Institute of Advanced Study (HIAS) assembled a panel including world leading roboticists from the Hellenic diaspora, who volunteered their scientific expertise to provide a vision for Robotics in Greece. This monograph, entitled “Robotics in the Artificial Intelligence (AI) era,” will hopefully trigger a dialogue towards the development of a national robotics strategy. Our vision is that Robotics in the AI era will be an essential technology of the future for the safety and security of the Hellenic nation, its environment and its citizens, for modernizing its economy towards Industry 4.0, and for inspiring and educating the next generation workforce for the challenges of the 21st century. To contribute towards making this vision a reality, after reviewing global trends in robotics and assessing the Greek robotics ecosystem, we arrived at the following key findings and recommendations: Firstly, we think that Greece should develop a national Hellenic Robotics Initiative that serves as the nation’s long-term vision and strategy across the entire Greek robotics ecosystem. Also, certain societal drivers should be key in the areas of focus. Safety and security is an area of national importance necessitating a national initiative, while agrifood, maritime and logistics provide opportunities for internationally leading innovation.We recommend the establishment of a mission-driven, government-funded, organization advancing unmanned vehicles in societal drivers of national importance, and Greece should leverage its unique geography and become a living testbed of robotics innovation turning the country into a development site for exportable technologies. In our opinion, universities should create Centers of Excellence in robotics and AI as well as consider innovation-leading research institutes such as the Italian Institute of Technology. We recommend investing in robotics education using Maker Spaces in order to prepare the workforce with 21st century skills to become Industry 4.0 innovators. Furthermore, we believe that the government should collect, measure, and analyze data on the robotics industry, robotics uses, labor shifts, and brain gain and promote awareness via a Hellenic Robotics Day. And finally, the government should regulate robot safety without stifling innovation, provide safe experimentation areas and mechanisms for certifying safety of locally developed robots. This monograph has many additional suggestions that enhance the above main recommendations. As authors, we advocate bringing the robotics ecosystem together in order to sharpen and expand these findings to an ambitious, long-term, and detailed national strategy and roadmap for robotics in the AI era.",https://doi.org/10.1561/2300000069,Found. Trends Robot
"The role of analog signal processing in upcoming telecommunication systems: Concept, challenges, and outlook",10.1016/j.sigpro.2024.109446,2024,t,x,X4,,ACM,,"Safari, Mir Mahdi; Pourrostam, Jafar",,https://doi.org/10.1016/j.sigpro.2024.109446,Signal Process.
Learning with Limited Samples: Meta-Learning and Applications to Communication Systems,10.1561/2000000115,2023,t,x,X4,,ACM,,"Chen, Lisha; Jose, Sharu Theresa; Nikoloska, Ivana; Park, Sangwoo; Chen, Tianyi; Simeone, Osvaldo","Deep learning has achieved remarkable success in many machine learning tasks such as image classification, speech recognition, and game playing. However, these breakthroughs are often difficult to translate into real-world engineering systems because deep learning models require a massive number of training samples, which are costly to obtain in practice. To address labeled data scarcity, few-shot meta-learning optimizes learning algorithms that can efficiently adapt to new tasks quickly. While meta-learning is gaining significant interest in the machine learning literature, its working principles and theoretic fundamentals are not as well understood in the engineering community.This review monograph provides an introduction to metalearning by covering principles, algorithms, theory, and engineering applications. After introducing meta-learning in comparison with conventional and joint learning, we describe the main meta-learning algorithms, as well as a general bilevel optimization framework for the definition of meta-learning techniques. Then, we summarize known results on the generalization capabilities of meta-learning from a statistical learning viewpoint. Applications to communication systems, including decoding and power allocation, are discussed next, followed by an introduction to aspects related to the integration of meta-learning with emerging computing technologies, namely neuromorphic and quantum computing. The monograph is concluded with an overview of open research challenges.",https://doi.org/10.1561/2000000115,Found. Trends Signal Process.
When machine learning meets Network Management and Orchestration in Edge-based networking paradigms,10.1016/j.jnca.2022.103558,2023,t,x,X4,,ACM,,"Shahraki, Amin; Ohlenforst, Torsten; Kreyß, Felix",,https://doi.org/10.1016/j.jnca.2022.103558,J. Netw. Comput. Appl.
Study on traffic flows with connected vehicles and human-driven vehicles,10.1016/j.amc.2024.129182,2025,t,x,X4,,ACM,,"Cen, Bing-ling; Xue, Yu; Zhang, Kun; Jia, Lisi; He, Hong-di",,https://doi.org/10.1016/j.amc.2024.129182,Appl. Math. Comput.
Deep learning in computational mechanics: a review,10.1007/s00466-023-02434-4,2024,a,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","Herrmann, Leon; Kollmannsberger, Stefan","The rapid growth of deep learning research, including within the field of computational mechanics, has resulted in an extensive and diverse body of literature. To help researchers identify key concepts and promising methodologies within this field, we provide an overview of deep learning in deterministic computational mechanics. Five main categories are identified and explored: simulation substitution, simulation enhancement, discretizations as neural networks, generative approaches, and deep reinforcement learning. This review focuses on deep learning methods rather than applications for computational mechanics, thereby enabling researchers to explore this field more effectively. As such, the review is not necessarily aimed at researchers with extensive knowledge of deep learning—instead, the primary audience is researchers on the verge of entering this field or those attempting to gain an overview of deep learning in computational mechanics. The discussed concepts are, therefore, explained as simple as possible.",https://doi.org/10.1007/s00466-023-02434-4,Comput. Mech.
"Unlocking the black box: an in-depth review on interpretability, explainability, and reliability in deep learning",10.1007/s00521-024-10437-2,2024,t,x,X4,,ACM,"Count: 2 | Sources: ACM, Springer Link","ŞAHiN, Emrullah; Arslan, Naciye Nur; Özdemir, Durmuş","Deep learning models have revolutionized numerous fields, yet their decision-making processes often remain opaque, earning them the characterization of “black-box” models due to their lack of transparency and comprehensibility. This opacity presents significant challenges to understanding the rationale behind their decisions, thereby impeding their interpretability, explainability, and reliability. This review examines 718 studies published between 2015 and 2024 in high-impact journals indexed in SCI, SCI-E, SSCI, and ESCI, providing a crucial reference for researchers investigating methodologies and techniques in related domains. In this exploration, we evaluate a wide array of interpretability and explainability (XAI) strategies, including visual and feature-based explanations, local approach-based techniques, and Bayesian methods. These strategies are assessed for their effectiveness and applicability using a comprehensive set of evaluation metrics. Moving beyond traditional analyses, we propose a novel taxonomy of XAI methods, addressing gaps in the literature and offering a structured classification that elucidates the roles and interactions of these methods. Moreover, we explore the intricate relationship between interpretability and explainability, examining potential conflicts and highlighting the necessity for interpretability in practical applications. Through detailed comparative analysis, we underscore the strengths and limitations of various XAI methods across different data types, ensuring a thorough understanding of their practical performance and real-world utility. The review also examines model robustness against adversarial attacks, emphasizing the critical importance of transparency, reliability, and ethical considerations in model development. A significant emphasis is placed on identifying and mitigating biases in deep learning systems, providing insights into future research directions that aim to enhance fairness and reduce bias. By thoroughly reviewing current challenges and emerging research directions, this article equips researchers with the knowledge and tools to advance the development of more transparent, fair, and reliable deep learning systems. Ultimately, this work aims to bridge existing literature gaps by offering a forward-looking perspective that fosters innovation and progress in the field. This comprehensive review not only illuminates the current state of XAI methodologies but also contributes to the broader understanding and enhancement of deep learning systems, ensuring their ethical and equitable application across various domains.",https://doi.org/10.1007/s00521-024-10437-2,Neural Comput. Appl.
The resurrection of digital triplet: A cognitive pillar of human-machine integration at the dawn of industry 5.0,10.1016/j.jksuci.2023.101846,2023,t,x,X4,,ACM,,"Alimam, Hassan; Mazzuto, Giovanni; Tozzi, Nicola; Emanuele Ciarapica, Filippo; Bevilacqua, Maurizio",,https://doi.org/10.1016/j.jksuci.2023.101846,J. King Saud Univ. Comput. Inf. Sci.
Zespol: A Lightweight Environment for Training Swarming Agents,10.1145/3589737.3606002,2023,t,x,X4,,ACM,,"Snyder, Shay; Zhu, Kevin; Vega, Ricardo; Nowzari, Cameron; Parsa, Maryam","Agent-based modeling (ABM) and simulation have emerged as important tools for studying emergent behaviors, especially in the context of swarming algorithms for robotic systems. Despite significant research in this area, there is a lack of standardized simulation environments, which hinders the development and deployment of real-world robotic swarms. To address this issue, we present Zespol, a modular, Python-based simulation environment that enables the development and testing of multi-agent control algorithms. Zespol provides a flexible and extensible sandbox for initial research, with the potential for scaling to real-world applications. We provide a topological overview of the system and detailed descriptions of its plug-and-play elements. We demonstrate the fidelity of Zespol in simulated and real-word robotics by replicating existing works highlighting the simulation to real gap with the milling behavior. We plan to leverage Zespol's plug-and-play feature for neuromorphic computing in swarming scenarios, which involves using the modules in Zespol to simulate the behavior of neurons and their connections as synapses. This will enable optimizing and studying the emergent behavior of swarm systems in complex environments. Our goal is to gain a better understanding of the interplay between environmental factors and neural-like computations in swarming systems.",https://doi.org/10.1145/3589737.3606002,Proceedings of the 2023 International Conference on Neuromorphic Systems
An Overview of Deep Learning in Power Production,10.1145/3386415.3387080,2020,t,x,X4,,ACM,,"Song, Qiang; Wu, Yonghuan; Liu, Zhenlan","With the deepening of global information and rapid development of technology, the public pay more attention to the value of massive data and constantly explore the internal relationship between data. The researchers try to serve economic and people's life with data. As a national basic industry, electric power plays an important role in economic and social development. Under the background of energy conservation and emission reduction policies, we are badly need to mine data value of electric power to improve the stability of electric power operation. This paper focuses on the combination of deep learning with power production, introduces the current research progress of deep learning and the scenario of deep learning in electric power. Based on the findings, this paper has proposed some future research directions.",https://doi.org/10.1145/3386415.3387080,Proceedings of the 2nd International Conference on Information Technologies and Electrical Engineering
Neural state classification for hybrid systems,10.1145/3313149.3313372,2019,a,x,"X4,X2",,ACM,"Count: 2 | Sources: ACM, Springer Link","Phan, Dung; Paoletti, Nicola; Zhang, Timothy; Grosu, Radu; Smolka, Scott A.; Stoller, Scott D.","Model checking of hybrid systems is usually expressed in terms of the following reachability problem for hybrid automata (HA) [6]: given an HA M, a set of initial states I, and a set of unsafe states U, determine whether there exists a trajectory of M starting in an initial state and ending in an unsafe state. The time-bounded version of this problem considers trajectories that are within a given time bound T.We introduce the State Classification Problem (SCP), a generalization of the model checking problem for hybrid systems. Let B = 0,1 be the set of Boolean values. Given an HA M with state space S(M), time bound T, and set of unsafe states U ⊂ S(M), the SCP problem is to find a function F*: S(M) → B such that for all s ∈ S(M), F* (s) = 1 if M |= Reach (U ,s,T), i.e., if it is possible for M, starting in s, to reach a state in U within time T ; F*(s) = 0 otherwise. A state s ⊂ S(M) is called positive if F*(s) = 1. Otherwise, s is negative. We call such a function a state classifier.State classification is also useful in at least two other contexts. First, due to random disturbances, a hybrid system may restart in a random state outside the initial region, and we may wish to check the system's safety from that state. Secondly, a classifier can be used for online model checking [10], where in the process of monitoring a system's behavior, one would like to determine, in real-time, the fate of the system going forward from the current (non-initial) state.This paper shows how deep neural networks (DNNs) can be used for state classification, an approach we refer to as Neural State Classification (NSC). An NSC classifier is subject to false positives (FPs) and, more importantly, false negatives (FNs). An FP occurs when a state s is deemed positive when it is actually negative, and, likewise, an FN occurs when s is deemed negative when it is actually positive.A well-trained NSC classifier offers high accuracy, runs in constant time (approx. 1 ms in our experiments), and takes constant space (e.g., a DNN with l hidden layers and n neurons only requires functions of dimension l · n for its encoding). This makes NSC classifiers very appealing for applications such as online model checking, a type of analysis subject to strict time and space constraints.Our approach can also classify states of parametric HA by encoding each parameter as an additional input to the classifier. This makes NSC more versatile than state-of-the-art hybrid system reachability tools, which provide little or no support for parametric analysis [3,4].The NSC method is summarized in Figure 1. We train the state classifier using supervised learning, where the training examples are derived by sampling the state and parameter spaces according to some distribution. Reachability values for the examples are computed by invoking an oracle, i.e., an hybrid system model checker [4] or a simulator when the system is deterministic.We evaluate a trained state classifier by estimating its accuracy, false-positive rate, and false-negative rate (together with their confidence intervals) on a test dataset of fresh samples. This allows us to quantify how well the classifier extrapolates to unseen states, i.e., the probability that it correctly predicts reachability for any state.Inspired by statistical model checking [8], we also provide statistical guarantees through sequential hypothesis testing to certify (up to some confidence level) that the classifier meets prescribed accuracy levels on unseen data.We also consider two tuning methods that can reduce and virtually eliminate false negatives: a new method called falsification-guided adaptation that iteratively re-trains the classifier with false negatives found through adversarial sampling; and threshold selection, which adjusts the NN's classification threshold to favor FPs over FNs.We have applied NSC to six nonlinear hybrid system benchmarks, achieving an accuracy of 99.25% to 99.98%, and a false-negative rate of 0.0033 to 0, which we further reduced to 0.0015 to 0 after tuning the classifier. We believe that this level of accuracy is acceptable in many practical applications, and that these results demonstrate the promise of the NSC approach.In the rest of this extended abstract, we provide more details about the NSC approach and discuss experimental results.",https://doi.org/10.1145/3313149.3313372,Proceedings of the Fifth International Workshop on Symbolic-Numeric Methods for Reasoning about CPS and IoT
Recent Trend of Neuromorphic Computing Hardware: Intel's Neuromorphic System Perspective,10.1109/ISOCC50952.2020.9332961,2020,f,x,X4,,IEEE Xplore,,Y. S. Yang; Y. Kim,"Neuromorphic computing has been studied to implement functions inspired by the human brain such as low power, fine-grained parallel processing, and real-time learning beyond the limitations seen by a standard von Neumann processor. In this paper, Intel's Loihi neuromorphic research chip and its hardware systems are introduced and find out how they are applied and used in actual research fields.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332961,2020 International SoC Design Conference (ISOCC)
Blockchain-Enabled Federated Learning with Neuromorphic Edge Devices for Drone Identification and Flight Mode Detection,10.1109/DASC58513.2023.10311304,2023,f,i,,,IEEE Xplore,,A. Henderson; C. Yakopcic; J. Colter; S. Harbour; T. Taha,"Unmanned aerial vehicles (UAVs), also known as drones, are expected to play an integral role in next-generation wireless avionics networks. To help secure these networks from malicious activity, machine learning (ML) based approaches have been proposed to identify drones and their flight modes via direct radio frequency signals. These approaches frequently rely on cloudcentric methods for training, which present serious concerns, such as privacy leakage, resource burden, and undesirable latency. In response to these concerns, a distributed ML paradigm known as federated learning (FL) has been proposed that enables multiple drones to collaboratively train ML models by only exchanging model parameters and not the raw data itself. Unfortunately, the conventional FL framework is strongly dependent on a centralized aggregation server with multiple resource-constrained edge devices, making it susceptible to poisoning attacks and poor network utilization. Recently, it has been found that blockchain technology (BT) holds significant promise for securing and storing data in edge applications with high levels of trust. However, the expanding chain of security blocks consumes a significant amount of computing power, thus limiting its scalability. To bridge the gap between computational efficiency and security, we propose a blockchain-empowered and energy-efficient FL framework with neuromorphic edge devices. To assess the effectiveness of our proposed framework we perform a drone identification and flight mode detection task with a spiking neural network (SNN). Finally, we compare our neuromorphic approach with competitive alternatives to validate the energy and performance gains of our system.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10311304,2023 IEEE/AIAA 42nd Digital Avionics Systems Conference (DASC)
Hyperspectral Image Classification of Brain-Inspired Spiking Neural Network Based on Attention Mechanism,10.1109/LGRS.2022.3172410,2022,f,x,X4,,IEEE Xplore,,Y. Liu; K. Cao; R. Wang; M. Tian; Y. Xie,"Convolutional neural network (CNN) has a complex model structure in hyperspectral image (HSI) classification and the energy consumption during training and inference is high, so it cannot be applied in edge computing devices such as software-defined satellites and unmanned aerial vehicles. In order to solve the classification of HSI in an edge computing environment, inspired by the principle of neuro-dynamics and brain-inspired computing, we use integrate and fire neurons and shuffle squeeze and excitation (SE) module network to construct a spiking neural network (SNN-SSEM). This letter designs an approximate derivative backpropagation algorithm for discontinuous activation function and realizes the training of an SNN. Experiments were conducted on three HSI datasets and the average classification accuracy reached more than 99%. The energy consumption of our model is about 4.5 times that of CNN with the same architecture. This study is an exploration of the application of the scientific theory of brain-inspired computing in hyperspectral remote sensing technology, which can realize real-time classification of HSI in the mobile computing environment.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9767804,IEEE Geoscience and Remote Sensing Letters
Live Demonstration: Real-Time Object Detection & Classification System in IoT with Dynamic Neuromorphic Vision Sensors,10.1109/ISCAS58744.2024.10558174,2024,f,x,"X2,X3","while UAV detection, no SNN only neuromorophic event camera",IEEE Xplore,,Z. Li; W. Lu; Y. Lu; J. Li; Y. Shi; Y. Zheng; T. T. -H. Kim,"In this paper, we demonstrate an energy-efficient real-time object detection and classification system featuring a hybrid event-based frame generation pipeline and a background-removal region proposal algorithm. The event-based frame is generated by aggregating active events within a programmable time interval, generating an event-based binary image (EBBI). This approach enables the utilization of low-complexity algorithms for denoising and object detection. The background-removal region proposal algorithm reduces memory requirements and removes dynamic backgrounds, leading to better detection performance. The proposed system is demonstrated on Zynq-7000 FPGA device with a DAVIS346 sensor. Experimental results show that the proposed system achieves comparable detection accuracy while requiring significantly less computation than existing event-based trackers.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558174,2024 IEEE International Symposium on Circuits and Systems (ISCAS)
Hyperspectral Image Classification of Brain-Inspired Spiking Neural Network Based on Approximate Derivative Algorithm,10.1109/TGRS.2022.3207098,2022,t,x,X4,same as 133 but other algorithm,IEEE Xplore,,Y. Liu; K. Cao; R. Li; H. Zhang; L. Zhou,"Recently, deep learning methods have made significant progress in solving hyperspectral image (HSI) classification problems of high-dimensional features, band redundancy, and spectral mixture. However, the deep neural network is too complex, with a long training time and high energy consumption, making it difficult to deploy on edge computing devices. In order to solve the above problems, this article proposes a brain-inspired computing framework based on the spiking leaky integrate-and-fire neuron model for HSIs’ classification. Then, we design an approximate derivative algorithm to solve the nondifferentiable spike activity of the spiking neuron. The framework uses direct coding to generate spatiotemporal spikes for input HSI and achieves efficient extraction of spatial–spectral features through spiking standard convolution and spiking depthwise separable convolution. Extensive experiments are performed on four benchmark hyperspectral datasets and two public unmanned aerial vehicle-borne hyperspectral datasets. Experiments show that the proposed model has the advantages of high classification accuracy and fewer spiking time steps. The proposed model can save about ten times computational energy consumption compared with the CNN of the same architecture. This research has great significance for overcoming the technical bottleneck of HSI classification based on brain-inspired computing, solving the critical problems of mobile computing in unmanned autonomous systems, and realizing the engineering application of unmanned aerial vehicles and software-defined satellites. The source code will be made available at https://github.com/Katherine-Cao/HSI_SNN.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893181,IEEE Transactions on Geoscience and Remote Sensing
Multi-patch localization Spiking Neural Network for Object Detection,10.1109/ICSICT55466.2022.9963459,2022,i,i,,,IEEE Xplore,,S. Feng; J. Cao; L. Zhang; G. Chen; J. Yan; F. Ling; X. Liu; J. Che; X. Cui; Y. Wang,"As the third generation of neural network after Artificial Neural Network, Spiking Neural Network (SNN) has the advantages of low energy consumption and high computing efficiency. However, due to the complex neurons and non-differentiable characteristics of SNN, the current results mostly stay in the software simulation stage, focusing on tasks with relatively simple processes such as image classification, and less achievements in Object Detection (OD) tasks with more application value. At present, the OD based on SNN mostly uses frequency coding, but the regression problem requires high precision and requires a large number of timesteps, resulting in a long time-consuming inference of a picture and a large overall power consumption. In this regard, based on Two-stage OD network, this paper decouples its detection process classification and localization, and proposes a multi-patch classification with localization network, which is completed by using a classification SNN. And take the drone shot by the infrared camera as the dataset, the OD as the application scene. The OD network is deployed on the neuromorphic chip PAICORE1.0 of Peking University, which proves the feasibility of applying our method to real-world neuromorphic chip and facilitates the development of SNN OD and its neuromorphic chip deployment.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9963459,2022 IEEE 16th International Conference on Solid-State & Integrated Circuit Technology (ICSICT)
SNN-Drone: Low-Power Drone-View Object Detection with Integer-Valued Spiking Neural Networks,10.1109/JIOT.2025.3644346,2025,f,x,X1,its object detection from drone perspective → no hints UAV → UAV detection but may possible,IEEE Xplore,,H. Liao; S. Chen; Y. Liang; F. Min,"Drone-view object detection (DroneDet) is a computer-vision method for locating objects and predicting their categories in aerial images. Popular methods are often plagued by high energy consumption and severe noise interference in dynamic aerial environments. In this study, we propose a novel integer-valued spiking neural network based approach called SNN-Drone to optimize both energy consumption and performance. Regarding high energy consumption, a new Integer-Valued Encoding (IVE) scheme transforms YOLOv8 features into high-fidelity integer spike trains. The IVE effectively reduces the high energy consumption associated with conventional binary spike encoding. For noise interference, our Dual-Branch Spike Block (DBSB) enhances feature representation by separating spatial and semantic processing, while the Normalized Wasserstein Distance (NWD) loss refines localization accuracy for small and densely packed targets. These modules significantly improve detection performance. In addition, we construct UAVDT-SNN, the first large-scale neuromorphic dataset for UAV object detection with temporally encoded motion and diverse aerial scenes. Extensive experiments on the VisDrone 2019, UAVDT, and UAVDT-SNN datasets demonstrate that SNN-Drone achieves state-of-the-art performance, outperforming both baseline ANNs and advanced YOLOv8–v12 variants. Notably, SNN-Drone-s improves energy efficiency by 7.7× compared to YOLOv8s. This work is the first to show that SNNs can serve as an energy-efficient yet competitive solution for drone-view object detection, narrowing the performance–energy gap with ANNs. Our code is available at: https://github.com/iliaohai/SNN-Drone.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11300892,IEEE Internet of Things Journal
Application of SNNS Model Based On Multi-Dimensional Attention In Drone Radio Frequency Signal Classification,10.1109/ICASSP48485.2024.10446694,2024,f,i,,,IEEE Xplore,,Z. Si; C. Liu; J. Liu; Y. Zhou,"Spiking Neural Networks (SNNs) are attracting attention due to their energy efficiency and importance in neuromorphic computing. Therefore, we propose an SNN-based method for classifying drone RF signals in complex electromagnetic environments. Specifically, we designed a new SNNs model called Spiking-EfficientNet based on EfficientNetV2 and improved its performance with a multidimensional attention mechanism. Experimental results demonstrate that Spiking-EfficientNet achieved classification accuracy of 99.13% and 96.02% on the ZK RF and DroneDetectV2 datasets. Importantly, Spiking-EfficientNet not only outperforms traditional Artificial Neural Networks (ANNs) in performance, but also exhibits significantly lower energy consumption. The energy consumption is only 20.1% of EfficientNetV2, 2.56% of VGG11, 10.71% of ResNet18, and 61.15% of MobileNetV2. This study demonstrates the significant potential of SNNs in drone RF signal classification and provides a low-power solution.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10446694,"ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Detection and Classification of Drones Through Acoustic Features Using a Spike-Based Reservoir Computer for Low Power Applications,10.1109/DASC55683.2022.9925735,2022,f,i,,,IEEE Xplore,,A. Henderson; C. Yakopcic; S. Harbour; T. M. Taha,"Over the past few decades, the use of drones for applications such as defense, reconnaissance, agriculture, law enforcement, and others has dramatically increased. Although drones are useful for these applications, they can also be utilized to perform malicious activities, thus compromising the safety and integrity of physical infrastructures. To address this issue, various techniques have been developed to detect and identify drones, including radar, visual analysis, and radio-frequency signal processing. Furthermore, deep learning algorithms based on the recognition of acoustic drone features have been proposed to automate the detection process and overcome the current limitations in modern drone detection systems. This paper presents an auditory drone detection and identification system based on the sparse, event-driven communication nature of Spiking Neural Networks (SNNs). We investigate the use of a spiking reservoir computing model, known as a Liquid State Machine (LSM), that offers a computationally light alternative to the deep learning approaches of previous works. The LSM based auditory drone detection and identification system is demonstrated on a publicly available acoustic drone dataset, achieving an accuracy of 97.13% and 93.25% on the detection and identification tasks, respectively. To the best of our knowledge, this work presents the first spike-based implementation of an auditory drone recognition system. Moreover, this paper highlights the potential for low size, weight, and power neuromorphic hardware deployment for drone applications that may be limited to energy-constrained environments.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9925735,2022 IEEE/AIAA 41st Digital Avionics Systems Conference (DASC)
A VelocitySNN-Fuzzy AI Architecture: Neuromorphic Event-Driven Spiking Neural Network and Fuzzy Logic AI System for 3D Velocity Determination in Martian Flight,10.1109/NAECON65708.2025.11235482,2025,t,x,X4,,IEEE Xplore,,D. A. R. Harbour; V. K. Asari; S. D. Harbour; K. Cohen; M. Kinnison; J. Colter; S. Schlager; T. M. Taha; C. Yakopcic; H. Pennel; A. Mitchel; A. Sultana; S. N. Abouzahra,"We introduce VelocitySNN-Fuzzy AI, a novel neuromorphic system for real-time determination of three-dimensional velocity vectors (Vx, Vy, Vz) during Martian drone flight. Unlike Earth-Based UAVs, Mars operations cannot rely on GPS or conventional visual odometry due to the lack of infrastructure and the extreme lighting and terrain conditions. Our approach integrates a bio-inspired event-based camera, a Spiking Neural Network (SNN) developed using SpikingJelly, and an explainable Fuzzy AI Logic layer to produce reliable and interpretable velocity determination in challenging Mars-Like environments. Validated using publicly available Mars-Style drone datasets, the architecture demonstrates low-latency, high-dynamic-range perception suitable for small, power-constrained UAV platforms. VelocitySNN-Fuzzy AI determines 3D velocity for Martian drones using event-based vision, spiking neural networks, and fuzzy logic. Designed for GPS-denied, low-light environments, it enables real-time, low-power navigation. Validated on FPV drone datasets, it supports autonomous flight with interpretable outputs and deployment on neuromorphic hardware like Loihi and Akida.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11235482,NAECON 2025 - IEEE National Aerospace and Electronics Conference
Toward Neuromorphic TinyML for Efficient Visual Perception,10.1109/ICECS66544.2025.11270596,2025,f,x,X3,"theoretical framework, no hints to UAV detection",IEEE Xplore,,I. Lamaakal; C. Yahyati; I. Ouahbi; K. E. Makkaoui; Y. Maleh,"The rapid growth of edge computing applications in robotics, wearable devices, autonomous systems, and IoT has driven a critical demand for energy-efficient and low-latency visual perception capabilities. Traditional deep learning models, though effective, often exceed the computational and power constraints of embedded devices. TinyML has emerged to address these constraints by enabling machine learning on resource-limited hardware, yet existing TinyML methods typically rely on conventional architectures that are not inherently optimized for sparse or event-driven data. In this paper, we explore a theoretical framework for integrating neuromorphic computing principles into the TinyML paradigm to enhance efficiency in visual perception tasks. We analyze key architectural elements inspired by biological systems such as spiking neural networks, temporal coding, and event-driven processing and assess their potential to reduce power consumption and data redundancy while maintaining perceptual performance. Our approach offers a conceptual foundation for neuromorphic TinyML systems tailored for real-time vision applications in constrained environments. By unifying the low-power advantages of neuromorphic hardware with the scalability of TinyML, this work paves the way for next-generation embedded vision systems that are more responsive, energy-aware, and biologically inspired.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11270596,"2025 32nd IEEE International Conference on Electronics, Circuits and Systems (ICECS)"
An Energy-Efficient Object Detection System in IoT with Dynamic Neuromorphic Vision Sensors,10.1109/ISCAS58744.2024.10558689,2024,f,x,X2,"neuromorphic camera,but no SNN for classification used",IEEE Xplore,,Z. Li; W. Lu; Y. Lu; J. Li; Y. Shi; Y. Zheng; T. T. -H. Kim,"Neuromorphic vision sensors (NVSs) mimic the function of the human visual system, with significant energy-saving potential in IoT-based object detection systems. Unlike conventional sensors, NVSs only generate asynchronous spiking events in response to changes in light intensity. However, the inherent noise generated by NVSs causes a degradation of detection performance. Moreover, an interested object usually occupies only a portion of the entire image frame. Therefore, a real-time, accurate event-based object detection system is needed to identify the region of interest (Rol) and leverage this spatial redundancy to reduce computational load in subsequent recognition modules. In this article, we present an energy-efficient real-time object detection system featuring a hybrid event-based frame generation pipeline and a background-removal region proposal algorithm. The event-based frame is generated by aggregating active events within a programmable time interval, generating an event-based binary image (EBBI). This approach enables the utilization of low-complexity algorithms for denoising and object detection. The background-removal region proposal algorithm reduces memory requirements and removes dynamic backgrounds, leading to better detection performance. The proposed system is demonstrated on Zynq-7000 FPGA device with a DAVIS346 sensor. Experimental results show that the proposed system achieves comparable accuracy while requiring significantly less computation than existing event-based trackers.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10558689,2024 IEEE International Symposium on Circuits and Systems (ISCAS)
Martian Flight: Enabling Motion Estimation of NASA's Next-Generation Mars Flying Drone by Implementing a Neuromorphic Event-Camera and Explainable Fuzzy Spiking Neural Network Model,10.1109/DASC62030.2024.10749524,2024,t,x,X4,,IEEE Xplore,,D. A. Harbour; K. Cohen; S. D. Harbour; B. Ratliff; A. Henderson; H. Pennel; S. Schlager; T. M. Taha; C. Yakopcic; V. K. Asari; J. Boril; A. Sultana; S. N. Abouzahra; A. Bulter; C. Prikkel,"The event camera is researched, developed, and designed to imitate the human eye; it is a groundbreaking vision sensor with the following advantages over a standard camera: a net rate that is much faster, a latency that is far less, a high dynamic range, and it uses far less power. These fundamental properties assist in enabling the design of third-generation algorithms in Spiking Neural Networks intended to mimic the human brain and vision processing. Moreover, these fundamental properties enable swift robotics despite the challenges of motion blur and high latency that standard cameras face. Also, these properties should enable motion estimation from the surface features on Mars, which is difficult to achieve with standard cameras. For this research, the team is using a NASA Space use-case application. For this NASA Space application, the team has chosen a challenging motion-estimation task involving a Mars-based above-ground Helicopter beyond “Ingenuity” and the planet and surface of Mars. Event-based cameras have been gaining interest within the computer vision community. They are particularly suitable for applications with challenging temporal constraints and safety requirements. Thus, Event-based sensors are an excellent match for Spiking Neural Networks (SNNs), as coupling an asynchronous sensor with neuromorphic hardware can result in real-time systems with minimal power requirements. Moreover, methods to verify and validate event-based sensing platforms for space applications are lacking. In this paper, we investigate the addition of fuzzy logic models to arrive at an explainable SNN algorithm for the NASA space use-case. Ultimately, the team aims to develop a unified model yielding reasonably accurate optical flow estimates.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10749524,2024 AIAA DATC/IEEE 43rd Digital Avionics Systems Conference (DASC)
Hyperspectral Image Classification for Remote Sensing Using Low-Power Neuromorphic Hardware,10.1109/IJCNN.2019.8852001,2019,t,x,X4,,IEEE Xplore,,V. Parmar; J. -H. Ahn; M. Suri,"In this paper, we present a novel feature extraction algorithm based approach for performing Hyperspectral Image Classification using a low-power Neuromorphic hardware. The application of interest for this study is HSI image classification for remote sensing. We demonstrate energy-efficient data processing pipeline optimized to use with on-edge neuromorphic hardware. The dataset used for the study is Salinas-A. We use the Brilliant USB stick with 4 NM500 chips for prototyping the application. Achieved recognition time is 18.4 μs and energy consumption is ~10 μJ with an accuracy of ~ 97%.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852001,2019 International Joint Conference on Neural Networks (IJCNN)
Efficient Radio Frequency Fingerprint Identification Using Spiking Neural Networks with Spike-based Self-Attention Mechanism,10.1109/IJCNN64981.2025.11228145,2025,f,i,,RF,IEEE Xplore,,C. Lin; J. Zhao; L. Wang,"Radio Frequency Fingerprint Identification (RFFI) is crucial in wireless security and device authentication, particularly in resource-constrained edge applications such as base stations, drones, and IoT devices. Traditional deep learning approaches achieve high recognition accuracy but are computationally intensive, limiting their deployment in real-time scenarios. In contrast, Spiking Neural Network (SNN) offer energy-efficient, event-driven computation but often face feature extraction and noise robustness challenges. This paper proposes a lightweight SNN-based RFFI model that integrates a Liquid State Machine (LSM) with a spike-based self-attention mechanism to enhance signal fingerprint feature extraction. Unlike conventional approaches, our method leverages self-attention within the spiking domain, allowing the model to focus on discriminative signal characteristics while maintaining computational efficiency. To further improve recognition performance under low signal-to-noise ratio (SNR) conditions, we introduce a knowledge distillation strategy during training, enhancing the model’s robustness. Experimental results demonstrate that our method achieves a recognition accuracy of 94.56%, surpassing the highest previously reported accuracy by 1.16%, while simultaneously reducing the number of trainable parameters by 89%. Moreover, compared to the most computationally efficient baseline, our model reduces multiply-accumulate operations (MACs) by a factor of 100 while achieving a 6.93% accuracy improvement. These results validate our model as an efficient and scalable solution for real-time RFFI applications, addressing the limitations of prior methods in balancing accuracy, computational cost, and robustness in low-SNR environments.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11228145,2025 International Joint Conference on Neural Networks (IJCNN)
System Log Anomaly Detection Based on Spiking Neural Network Trained with Backpropagation,10.1109/ICC59986.2023.10421435,2023,f,x,"X4,X1",intrusion detection on drones,IEEE Xplore,,J. Zheng; Z. Wang,"System log analysis is one of the most important ways to defend attacks and avoid system exceptions. However, rule-based log anomaly detection cannot meet the requirements of complex systems. Log anomaly detection methods based on machine learning and deep learning have gradually become a research hotspot. However, for some complex mobile devices, such as unmanned aerial vehicle (UAV) and intelligent vehicles, log monitoring systems based on complex deep learning or machine learning could be with high power consumption in local anomaly detection. It is an urgent problem to be solved for such energy limited devices. In recent years, brain-like intelligence based on spiking neural networks (SNN) has been proved to have the potential for accurate detection with low power consumption. In this study, we proposed a log anomaly detection method based on SNN, called Log-SNN. This method parsed and converted text logs into embedding vectors with template and parameter information. Then, an SNN model based on backpropagation (BP) training (SNN-BP) was used to detect the log information. We evaluated the proposed method on three commonly used log anomaly datasets and proved the proposed method has higher accuracy than machine learning and deep learning algorithms. The algorithm has high inference speed and low power consumption. The Log-SNN proposed in this study provides an accurate, high-speed, and low-power feasible solution for local log anomaly detection of mobile devices.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10421435,2023 3rd International Conference on Intelligent Communications and Computing (ICC)
Siamese Neural Networks in Unmanned Aerial Vehicle Target Tracking Process,10.1109/ACCESS.2025.3536461,2025,f,x,X2,"no spiking neural network, they refer with SNN=Siamese neural network but they twin networks are no spike based NNS",IEEE Xplore,,A. Sabeeh Hasan Allak; J. Yi; H. M. Al-Sabbagh; L. Chen,"With the continuous maturity of unmanned aerial vehicle (UAV) technology, its application is more and more extensive. At the same time, the problem of UAV target tracking has also been widely concerned. Aiming at the problem of low recognition accuracy of small target, a target tracking model of UAV based on siamese neural network (SNN) is studied. Firstly, based on the YOLOv5 recognition model, convolutional attention module and multi-scale feature fusion network are introduced. On the basis of the intersection over union loss, the effective intersection over union loss is proposed to improve the loss function, and an improved YOLOv5 target recognition model is established. Then, a fine-grained classification regression network is proposed, which uses per-pixel classification regression to train the tracker. A target tracking model based on SNN is established by adjusting the results with a fine-tuning module. The results showed that the improved YOLOv5 model combined with the optimized loss function had the highest average accuracy of 47.84% and a frame rate of 28.34fps, which was better than the traditional YOLOv5 model. The recognition accuracy in the fused dataset is 93.12%, with a loss value of less than 0.01, which is superior to YOLOv3, YOLOv4, and traditional YOLOv5 models. The method has strong anti-jamming ability in the acceptable range. The target tracking model based on SNN has the highest tracking accuracy and still has good tracking performance in color image environment, which shows certain feasibility and superiority. To sum up, the model built in this study has good application effects and plays a certain role in promoting the development of the UAV industry.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10858122,IEEE Access
Inductive Conformal Prediction Enhanced LSTM-SNN Network: Applications to Birds and UAVs Recognition,10.1109/LGRS.2024.3361481,2024,f,i,,,IEEE Xplore,,N. Zhu; Z. Xi; C. Wu; F. Zhong; R. Qi; H. Chen; S. Xu; W. Ji,"Deep learning stands out as a potent state-of-the-art technique for target recognition. Unfortunately, the trustworthiness and reliability of deep learning networks encounter challenges in radar target recognition. In this letter, an inductive conformal prediction (ICP) enhanced long short-term memory spiking neural network (LSTM-SNN) is proposed. It integrates with the concept of conformal prediction in statistical learning theory and deep learning, and is applied to birds and drones’ recognition with radar. The proposed method can provide good recognition results for drones and birds with supplying confidence and credibility for each identification, and it yields a confidence interval containing the true value of the estimated at the desired confidence level, such as 98%. The benefits of the ICP enhanced LSTM-SNN method were demonstrated with the bird detection datasets obtained by radar in the airport.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10419072,IEEE Geoscience and Remote Sensing Letters
Towards Real-Time Machine Learning for Anomaly Detection,10.1109/NSS/MIC42677.2020.9507937,2020,f,x,"X1,X4",,IEEE Xplore,,P. Zhou; S. Abbaszadeh,"We are developing a hardware platform based on FPGA with highly parallel neuromorphic computing architecture that can be utilized in a drone with radiation detector for anomaly detection. Driven by national security threat landscape, there is a need for detectors with readout circuits with low size, weight, and power consumption that are capable of implementing realtime machine learning. Anomalous radioactive source detection task has the limitation of far detecting distance, limited dwell time, and weak source activity, which introduces challenges to detect extremely sparse data dominated by background radiation. However, a detector capable of real-time learning can learn the background signatures and detect anomaly when it appears. In this work, we have performed a simulation study with measured background data and injected simulated source to identify the memory and number of neurons required for anomaly detection in the FPGA platform. The background data was collected with a Kromek D3S detector at the University of Illinois at Urbana-Champaign campus and source data simulated with hyperparameters specified by characteristics of the detector. The simulation result shows that for learning 2048 spectra, 239 neurons with 256 bytes is required. For 1024 spectra anomaly detection, we achieved 99.80% true positive rate and 0.08% false positive rate.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9507937,2020 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)
Brain-Inspired Online Adaptation for Remote Sensing With Spiking Neural Network,10.1109/TGRS.2025.3527039,2025,f,x,X1,Object detection from drone view,IEEE Xplore,,D. Duan; P. Liu; B. Hui; F. Wen,"On-device computing, or edge computing, is becoming increasingly important for remote sensing, particularly in applications like deep network-based perception on on-orbit satellites and unmanned aerial vehicles (UAVs). In these scenarios, two brain-like capabilities are crucial for remote sensing models: 1) high energy efficiency, allowing the model to operate on edge devices with limited computing resources, and 2) online adaptation, enabling the model to quickly adapt to environmental variations, weather changes, and sensor drift. This work addresses these needs by proposing an online adaptation framework based on spiking neural networks (SNNs) for remote sensing. Starting with a pretrained SNN model, we design an efficient, unsupervised online adaptation algorithm, which adopts an approximation of the backpropagation through time (BPTT) algorithm and only involves forward-in-time computation that significantly reduces the computational complexity of SNN adaptation learning. Besides, we propose an adaptive activation scaling (AAS) scheme to boost online SNN adaptation performance, particularly in low time-steps. Furthermore, for the more challenging remote sensing detection task, we propose a confidence-based instance weighting scheme, which substantially improves adaptation performance in the detection task. To our knowledge, this work is the first to address the online adaptation of SNNs. Extensive experiments on seven benchmark datasets across classification, segmentation, and detection tasks demonstrate that our proposed method significantly outperforms existing domain adaptation and domain generalization approaches under varying weather conditions. The proposed method enables energy-efficient and fast online adaptation on edge devices, and has much potential in applications such as remote perception on on-orbit satellites and UAVs. The code is available at https://github.com/ThunderDavid/OASNN.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10833809,IEEE Transactions on Geoscience and Remote Sensing
EMSBS-YOLO: A Vehicle Detection Model Based on Spiking Neural Networks,10.1109/ACAIT63902.2024.11022103,2024,t,x,X1,Object detection from drone view,IEEE Xplore,,J. Hou; W. Chen; G. Yang; L. Cong; X. Qi,"Vehicle detection is a fundamental approach for traffic analysis and management. Current mainstream methods rely on convolutional neural network (CNN) models for object detection; however, deep convolutional network architectures come with high computational costs. To tackle this problem, this paper proposes a vehicle detection model based on SNN, EMSBS-YOLO, which effectively leverages the advantages of spiking neural networks (SNNs) in feature extraction, rapid response, and energy efficiency. The model integrates an improved Spatial Pyramid Down-Sampling (SPDS) module, significantly enhancing its ability to capture detailed information from low-resolution images. This improvement enables the model to better locate and recognize small objects. Furthermore, the model employs a bidirectional feature pyramid network module based on SNNs, effectively capturing multi-scale semantic information and achieving comprehensive integration and utilization of features at different scales. This bidirectional feature pyramid structure associates contextual information over a broader range, enhancing the model's performance in complex visual tasks. By incorporating these innovative modules, the model demonstrates exceptional capabilities in small object detection, multi-scale feature capture, and semantic information extraction. The experimental results on the VisDrone2019 dataset demonstrate the outstanding performance of our model, with an mAP50 of 34.1%. Ablation experiments validated the effectiveness of the proposed improvements, showing a 68.8% increase in mAP50 compared to the baseline model. For object detection models based on traditional convolutional neural networks, our model, when deployed on neuromorphic chips, theoretically achieves an 82.86% reduction in energy consumption.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022103,2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)
Efficient 3-D Tracking and Detection of Multirotor UAVs Using mmWave Radar With Semi-Supervised Learning,10.1109/JSEN.2025.3562322,2025,f,i,,,IEEE Xplore,,R. Xi; W. Wei; M. Zhang,"Small uncrewed aerial vehicles (UAVs) pose security risks to sensitive areas and individuals due to their rapid movement and wide coverage capabilities. Effective monitoring necessitates the deployment of lightweight and energy-efficient surveillance systems. This research introduces an efficient 3-D tracking and detection approach for small UAVs, using millimeter-wave (mmWave) radars and spiking neural networks (SNNs). By capturing micro-Doppler characteristics of UAV movements, it effectively processes low signal-to-noise ratios (SNRs) and uncertain signals. An improved angle estimation algorithm, combining dynamic programming and particle filters, enables real-time 3-D UAV tracking with reduced computational complexity. Then, a simple UAV detection model based on SNN architecture is developed by leveraging UAVs’ position and corresponding Doppler information. Furthermore, a bioinspired semi-supervised method is proposed to facilitate the training of SNNs using a limited number of annotated samples. The effectiveness of the proposed methodology is evaluated under various environmental conditions. Results indicate a significant improvement in tracking computation time efficiency, with the recognition model size reduced to one-tenth of its original size, yet it maintains near-original system performance.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10976494,IEEE Sensors Journal
Synthetic Dataset for Quadcopter Detection Based on Frequency Propeller Signature,10.1109/AIPR60534.2023.10440658,2023,f,x,X2,"only dataset, but no baseline with SNNs",IEEE Xplore,,M. -A. Drouin; M. -A. Rainville; M. Picard; T. C. Stewart; F. Billy Djupkep Dizeu; G. Gagné,"The use of computer graphic tools typically associated with video games is a popular method to generate synthetic datasets for the training of machine learning algorithms. For optical detection of quadcopters, realistic imagery needs to be generated for multiple models of drones, in multiple types of environments and different flight profiles. By itself, the effort required to generate those virtual environments can be as important as flying actual drones. This is particularly true when a physics-based engine is required to model the behavior of the propellers. While some appearance-based drone detection methods may not need accurate propeller behavior, other detection methods that exploit the high-frequency and/or temporal signatures generated by rotating propellers do require such accurate simulations. This is especially the case for neuromorphic sensors, which are generally sensitive to the unique high-frequency visual signal from the propeller blades. We propose a synthetic approach to acquire training datasets for neuromorphic sensors using a flexible hardware system built from quadcopter components. This system allows efficient acquisition of training sets for drone detection sensors based on the propeller’s temporal and/or frequency signature.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10440658,2023 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)
PointLCA-Net: Using Point Clouds for Energy Efficient Sparse Spatio-Temporal Signal Recognition in Neuromorphic Systems,10.1109/IJCNN64981.2025.11229386,2025,f,x,"X4,X1","Object detection, but not Drone detection. From motivation more idea to deploy on a drone",IEEE Xplore,,S. M. Takaghaj,"In recent years, the field of neuromorphic systems has gained significant traction as the demand for AI applications in energy-constrained autonomous systems, such as unmanned aerial vehicles (UAVs) and robotics, continues to grow. The advent of Dynamic Vision Sensor (DVS) and other event-based sensors, which generate sparse spatio-temporal signals, has propelled the field of neuromorphic engineering. This advancement calls for the development of new machine learning models or the refinement of existing ones to effectively leverage neural dynamics and exploit spike-based communication among neurons. These sparse spatio-temporal signals can be treated as 3D point sets (point clouds), representing the space and time at which these events occur, and can be processed using PointNet architectures. However, applying deep learning techniques such as backpropagation and deploying these models on energy-constrained neuromorphic devices presents challenges in computational resources and memory, as well as real-time processing and power consumption. This work presents PointLCA-Net, which leverages the strengths of PointNets for extracting robust features from input point sets, while utilizing the efficiency of Exemplar LCA to encode these features. PointLCA-Net achieves a high accuracy of 93.41% on DVS128 while reducing energy consumption by approximately 92% compared to other spiking neural networks applied to point clouds, making the system more efficient and well-suited for energy-constrained applications.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11229386,2025 International Joint Conference on Neural Networks (IJCNN)
Hypergraph Neural Networks for Collaborative Drone Mission Planning,10.1109/ICRITO66076.2025.11241792,2025,t,x,X4,,IEEE Xplore,,K. Thamaraiselvi; S. S. Peter; T. Sathya; A. S; A. J; M. Sundarrajan; M. D. Choudhry,"Over the past few years, autonomous Unmanned Aerial Vehicles (UAVs) have emerged as a significant presence in activities such as environmental monitoring, disaster response, surveillance, and infrastructure management in smart cities. The classical mission planning frameworks are primarily based on traditional graph-based models, such as Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), and Message Passing Neural Networks (MPNNs). Although useful in some limited aspects, these models have a theoretical drawback in that they are unable to model the higher-order interactions of many agents and tasks, as they focus on modeling the relationships between only a pair of them at a time. To address such difficulties, we introduce a new decision support tool, specifically designed to combat a mission called Hypergraph Neural Network, or HyperGNNs. We applied our suggested architecture, based on HyperGNN, utilizing PyTorch Geometric, and tested it with the help of rigorous simulations on the Google Colab platform. In the proposed experiment, realistic drone limitations were considered, including battery capacity, task type, environmental factors, and safety margins. The comparison analysis revealed that our model achieved a success rate of 93%, whereas the other approaches were GCN (82%), GAT (85%), and MPNN $(87 \%)$. It also showed a 15 to 20 percent reduction in the planning process, a 12 percent increase in energy consumption, and a 75 percent reduction in collision rate compared to baselines. These enhancements suggest the potential for describing collaborative drone missions using hypergraph structures. Overall, our method is scalable and provides an efficient approach to real-time, multi-agent mission planning, offering an excellent platform for extending work to address adaptive, neuromorphic, and real-world systems.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11241792,"2025 12th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)"
Intelligent Sensing-to-Action for Robust Autonomy at the Edge: Opportunities and Challenges,10.23919/DATE64628.2025.10993258,2025,f,x,X1,Drone navigation deployed on drone,IEEE Xplore,,A. R. Trivedi; S. Tayebati; H. Kumawat; N. Darabi; D. Kumar; A. K. Kosta; Y. Venkatesha; D. Jayasuriya; N. Jayasinghe; P. Panda; S. Mukhopadhyay; K. Roy,"Autonomous edge computing in robotics, smart cities, and autonomous vehicles relies on the seamless integration of sensing, processing, and actuation for real-time decision-making in dynamic environments. At its core is the sensing-to-action loop, which iteratively aligns sensor inputs with computational models to drive adaptive control strategies. These loops can adapt to hyper-local conditions, enhancing resource efficiency and responsiveness, but also face challenges such as resource constraints, synchronization delays in multimodal data fusion, and the risk of cascading errors in feedback loops. This article explores how proactive, context-aware sensing-to-action and action-to-sensing adaptations can enhance efficiency by dynamically adjusting sensing and computation based on task demands, such as sensing a very limited part of the environment and predicting the rest. By guiding sensing through control actions, action-to-sensing pathways can improve task relevance and resource use, but they also require robust monitoring to prevent cascading errors and maintain reliability. Multi-agent sensing-action loops further extend these capabilities through coordinated sensing and actions across distributed agents, optimizing resource use via collaboration. Additionally, neuromorphic computing, inspired by biological systems, provides an efficient framework for spike-based, event-driven processing that conserves energy, reduces latency, and supports hierarchical control-making it ideal for multi-agent optimization. This article highlights the importance of end-to-end co-design strategies that align algorithmic models with hardware and environmental dynamics, improve cross-layer inter-dependencies to improve throughput, precision, and adaptability for energy-efficient edge autonomy in complex environments.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10993258,"2025 Design, Automation & Test in Europe Conference (DATE)"
Ultra Low Power Multimodal Remote Sensing Night Emergency Search and Rescue Model for Resource Constrained Unmanned Platforms,10.1109/IGARSS55030.2025.11243366,2025,f,x,"X4,X1",Object detection from drone view,IEEE Xplore,,K. Li; Y. Wan; H. Yao; S. Liu; A. Ma; Y. Zhong,"In nighttime emergency rescue scenarios involving unmanned aerial vehicles, traditional artificial neural network (ANN)-based object detection algorithms are challenging to efficiently deploy on resource-constrained edge computing platforms due to their high computational complexity and energy consumption. In contrast, spiking neural networks (SNN), which emulate the brain’s information processing through sparse event-driven computations, significantly improve energy efficiency. Low-light and infrared images, as critical sources of information for nighttime rescue missions, can provide clear feature representations under low-light and complex environmental conditions. The efficient computational characteristics of SNN are highly compatible with the properties of these modalities, further enhancing their potential for nighttime emergency rescue tasks. For this emergency rescue scenario, this paper proposes a low-power object detection method for nighttime emergency rescue tasks, leveraging the fused characteristics of low-light and infrared imagery and the energy-efficient computational advantages of SNN. The method is based on Spiking-YOLO and was tested on self-constructed emergency rescue tasks. Experimental results demonstrate that, compared to the ANN-based Tiny YOLO, the proposed method achieves theoretical power consumption reduced to 1/2000 of the original network, with performance metrics degradation not exceeding 2%.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11243366,IGARSS 2025 - 2025 IEEE International Geoscience and Remote Sensing Symposium
A Neuromorphic Vision-Based Measurement for Robust Relative Localization in Future Space Exploration Missions,10.1109/TIM.2022.3217513,2024,f,x,"X1,X4",Landmark detection from drone view,IEEE Xplore,,M. Salah; M. Chehadah; M. Humais; M. Wahbah; A. Ayyad; R. Azzam; L. Seneviratne; Y. Zweiri,"Space exploration has witnessed revolutionary changes upon landing of the Perseverance Rover on the Martian surface and demonstrating the first flight beyond Earth by the Mars helicopter, Ingenuity. During their mission on Mars, Perseverance Rover and Ingenuity collaboratively explore the Martian surface, where Ingenuity scouts terrain information for rover’s safe traversability. Hence, determining the relative poses between both the platforms is of paramount importance for the success of this mission. Driven by this necessity, this work proposes a robust relative localization system based on a fusion of neuromorphic vision-based measurements (NVBMs) and inertial measurements. The emergence of neuromorphic vision triggered a paradigm shift in the computer vision community, due to its unique working principle delineated with asynchronous events triggered by variations of light intensities occurring in the scene. This implies that observations cannot be acquired in static scenes due to illumination invariance. To circumvent this limitation, high-frequency active landmarks are inserted in the scene to guarantee consistent event firing. These landmarks are adopted as salient features to facilitate relative localization. A novel event-based landmark identification algorithm using Gaussian mixture models (GMMs) is developed for matching the landmarks correspondences formulating our NVBMs. The NVBMs are fused with inertial measurements in proposed state estimators, landmark tracking Kalman filter (LTKF), and translation decoupled Kalman filter (TDKF) for landmark tracking and relative localization, respectively. The proposed system was tested in a variety of experiments and has outperformed the state-of-the-art (SOTA) approaches in accuracy and range.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931531,IEEE Transactions on Instrumentation and Measurement
Memory Efficient Corner Detection for Event-Driven Dynamic Vision Sensors,10.1109/ICASSP48485.2024.10445937,2024,t,x,X4,,IEEE Xplore,,P. -S. V. Sun; A. Glover; C. Bartolozzi; A. Basu,"Event cameras offer low-latency and data compression for visual applications, through event-driven operation, that can be exploited for edge processing in tiny autonomous agents. Robust, accurate and low latency extraction of highly informative features such as corners is key for most visual processing. While several corner detection algorithms have been proposed, state-of-the-art performance is achieved by ""luvHarris"". However, this algorithm requires a high number of memory accesses per event, making it less-than ideal for low-latency, low-energy implementation in tiny edge processors. In this paper, we propose a new event-driven corner detection implementation tailored for edge computing devices, which requires much lower memory access than lu-vHarris while also improving accuracy. Our method trades computation for memory access, which is more expensive for large memories. For a DAVIS346 camera, our method requires ≈ 3.8X less memory, ≈ 36.6X less memory accesses with only ≈ 2.3X more computes.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445937,"ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
Frequency Analysis on Neuromorphic Data Using Discrete Fourier Transform,10.1109/IPTA59101.2023.10320008,2023,a,x,X4,,IEEE Xplore,,J. Grundmark; H. Hamrell; J. Berneland; D. Gustafsson,"Event cameras are a relatively new sensor technology on the rise that captures changes in the observed scene. Since the signal is asynchronous and tends to be sparse the sensor is very power efficient, has a low latency, and has a remarkably high temporal resolution. Processing event-based signals of this kind in an effective way, taking full advantage of the technology, requires new signal processing methodologies. This paper proposes a simple yet powerful method for frequency analysis of event-based data using a Discrete Fourier Transform (DFT). The method is tested and evaluated on data sequences acquired from modulated light emitting diodes and a small UAV captured using an iniVation DVXplorer event camera. We show that the method can be used to detect frequencies that change relatively quickly (from 10 Hz-1 kHz in one second), several different frequencies in the same image at the same time, and to detect the rotation frequency of a drone propeller. This can be useful e.g. in the field of UAV detection.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10320008,"2023 Twelfth International Conference on Image Processing Theory, Tools and Applications (IPTA)"
E2SIFT: Neuromorphic SIFT via Direct Feature Pyramid Recovery from Events,10.1109/ICIP51287.2024.10647465,2024,a,x,X4,,IEEE Xplore,,C. Henry; P. Maharjan; Z. Li; G. York,"In recent years, event cameras have achieved significant attention due to their advantages over conventional cameras. Event cameras have high dynamic range, no motion blur, and high temporal resolution. Contrary to traditional cameras which generate intensity frames, event cameras output a stream of asynchronous events based on brightness change. There is extensive ongoing research on performing computer vision tasks like object detection, classification, etc via the event camera. However, due to the unconventional output format of the event camera, it is difficult to perform computer vision tasks directly on the event stream. Mostly, works reconstruct the intensity image from the event stream and then perform such tasks. An important and crucial task is feature detection and description. Scale-invariant feature transform (SIFT) is a widely-used scale-invariant keypoint detector and descriptor that is invariant to transformations like scale, rotation, noise, and illumination. In this work, given an event voxel, we directly generate the LoG pyramid for SIFT keypoint detection. We fit a 3rd-degree polynomial and calculate the polynomial roots to compute the scale-space extrema response for SIFT keypoint detection. Since the extrema computation is performed after LoG thresholding, the solution is computationally less expensive. Experimental results validate the effectiveness of our system.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10647465,2024 IEEE International Conference on Image Processing (ICIP)
Auto-Tuned Event-Based Perception Scheme for Intrusion Monitoring With UAS,10.1109/ACCESS.2021.3066529,2021,t,x,X4,intrusion detection ,IEEE Xplore,,J. P. Rodríguez-Gómez; A. G. Eguíluz; J. R. Martínez-De Dios; A. Ollero,"This paper presents an asynchronous event-based scheme for automatic intrusion monitoring using Unmanned Aerial Systems (UAS). Event cameras are neuromorphic sensors that capture the illumination changes in the camera pixels with high temporal resolution and dynamic range. In contrast to conventional frame-based cameras, they are naturally robust against motion blur and lighting conditions, which make them ideal for outdoor aerial robot applications. The presented scheme includes two main perception components. First, an asynchronous event-based processing system efficiently detects intrusions by combining several asynchronous event-based algorithms that exploit the advantages of the sequential nature of the event stream. The second is an off-line training mechanism that adjusts the parameters of the event-based algorithms to a particular surveillance scenario and mission. The proposed perception system was implemented in ROS for on-line execution on board UAS, integrated in an autonomous aerial robot architecture, and extensively validated in challenging scenarios with a wide variety of lighting conditions, including day and night experiments in pitch dark conditions.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380323,IEEE Access
Research on optimization of real-time target detection algorithm based on deep learning,10.1109/ICETCI64844.2025.11084148,2025,f,x,"X2,X4",,IEEE Xplore,,C. Qiu; H. Liang,"Stream-aware entity localization exhibits robust implementation potential across auto-piloted vehicular systems, cognitive monitoring grids, and unmanned aerial wayfinding domains. Prevailing spatial recognition paradigms remain vulnerable to target obfuscation, luminance volatility, and arithmetic throughput bottlenecks in cluttered ecosystems, struggling to achieve dual optimization of recognition fidelity and temporal responsiveness. This investigation pioneers a neuromorphic detection framework through synaptic pruning protocols, specifically countering deficiencies in contemporary dynamic pattern identification architectures. The methodology unfolds through three phased innovations: Primarily, we architect a sparsity-enhanced cortical network backbone integrated with saliency-driven perception gates, employing quantized tensor decomposition to amplify discriminative pattern distillation while implementing computation-aware regularization. Subsequently, a polymorphic feature pyramid consortium is engineered, establishing inter-stratum tensor resonance channels through dilated convolution cascades to mitigate sub-resolution target omission in cluttered spectral environments. Complementarily, an evolutive bounding prior engine is devised, employing probabilistic shape priors and differentiable IoU estimators to dynamically calibrate region proposal distributions, thereby optimizing spatial regression vector fields. Benchmarks conducted on heterogeneous vision corpora demonstrate our paradigm outperforms conventional detectors. The proposed neuro-adaptive detection ecology pioneers novel pathways for implementing bio-inspired machine perception in latency-sensitive scenarios, providing actionable insights for both algorithmic evolution and embedded vision system deployment.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084148,"2025 IEEE 5th International Conference on Electronic Technology, Communication and Information (ICETCI)"
Advancements in Algorithms and Neuromorphic Hardware for Spiking Neural Networks,10.1162/neco_a_01499,2022,f,x,X4,,IEEE Xplore,,A. Javanshir; T. T. Nguyen; M. A. P. Mahmud; A. Z. Kouzani,"Artificial neural networks (ANNs) have experienced a rapid advancement for their success in various application domains, including autonomous driving and drone vision. Researchers have been improving the performance efficiency and computational requirement of ANNs inspired by the mechanisms of the biological brain. Spiking neural networks (SNNs) provide a power-efficient and brain-inspired computing paradigm for machine learning applications. However, evaluating large-scale SNNs on classical von Neumann architectures (central processing units/graphics processing units) demands a high amount of power and time. Therefore, hardware designers have developed neuromorphic platforms to execute SNNs in and approach that combines fast processing and low power consumption. Recently, field-programmable gate arrays (FPGAs) have been considered promising candidates for implementing neuromorphic solutions due to their varied advantages, such as higher flexibility, shorter design, and excellent stability. This review aims to describe recent advances in SNNs and the neuromorphic hardware platforms (digital, analog, hybrid, and FPGA based) suitable for their implementation. We present that biological background of SNN learning, such as neuron models and information encoding techniques, followed by a categorization of SNN training. In addition, we describe state-of-the-art SNN simulators. Furthermore, we review and present FPGA-based hardware implementation of SNNs. Finally, we discuss some future directions for research in this field.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9931070,Neural Computation
Efficient Automatic Modulation Classification in Nonterrestrial Networks With SNN-Based Transformer,10.1109/JIOT.2024.3467284,2025,t,x,X4,,IEEE Xplore,,D. Zeng; Y. Xiao; W. Liu; H. Du; E. Zhang; D. Zhang; Y. Wang; M. Zhang; W. Chen,"With the development of informatization of IoT devices, nonterrestrial networks (NTNs) are becoming more and more important. NTN, including air and space networks, face challenges, such as high-computational complexity, bandwidth requirements, and memory constraints. An intelligent automatic modulation classification (AMC) mechanism based on neural networks plays a pivotal role in enhancing spectrum efficiency, throughput, and link reliability. Past work in AMC has evolved from likelihood-based and feature-based methods to traditional machine learning techniques and, more recently, to deep neural networks (DNNs). However, existing DNN architectures pose challenges for NTN due to high-computational complexity, bandwidth requirements, and memory consumption. Addressing this problems, we proposes a spiking transformer-based model for AMC, exploiting temporal dynamics for enhanced performance. Biologically inspired spiking neural networks enable us to exploit the sparse and binarized activation properties of spiking neurons, allowing us to build AMC models with high-energy efficiency and high availability that can be used in NTN systems. Furthermore, we introduce a weight binarization method to reduce the model size, which also further reduces the bandwidth and memory requirements of AMC in NTN edge deployment. Experimental results demonstrate the superiority of our approach over state-of-the-art methods, with the binarized model achieving comparable accuracy at a fraction of the size.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10693514,IEEE Internet of Things Journal
Stochastic image processing and simultaneous dewarping for aerial vehicles,10.1109/ISCAS.2016.7538990,2016,f,x,X2,"UAV detection, but no SNN used",IEEE Xplore,,J. L. Molin; J. Rattray; R. Etienne-Cummings,"There is increasing interest for aerial vehicles to perform image processing tasks (i.e. object recognition and detection) in real-time. Such systems systems should have minimal data throughput, low computational complexity, and low-power. Traditional frame-based digital cameras are not ideal for meeting such specifications. More recent cameras, inspired by biology, drastically reduce data throughput by representing information in event streams, and in doing so, represent image information temporally. In this work, we utilize the ATIS (Asynchronous Time-based Image Sensor) in conjunction with a Field-Programmable Gate Array implementation of the Integrate-and-Fire Array Transceiver for performing an event-based, simultaneous image dewarping and filtering task. The ATIS output is inherently event-based and stochastic, giving our system the low data throughput and low-power specifications that we seek, as it more directly mimics the communication protocol of biological neurons. We further emphasize how our system can be coupled with aerial vehicles that must perform visual tasks in real-time on a coherent representation of what its camera has captured.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7538990,2016 IEEE International Symposium on Circuits and Systems (ISCAS)
An Embedded Tracking System with Neural Network Accelerator,10.1109/IJCNN.2018.8489157,2018,f,x,"X1,X2,X4",Object detection from drone view,IEEE Xplore,,W. Yang; W. Wang; Y. Gao; Z. Jin,"With robots and unmanned aerial vehicles (UAVs) being more and more employed in real-life scenarios for monitoring and surveillance, there is a increasing demand for deploying various video processing applications in mobile systems. However, with limited on-board computational resources and power consumption, the application in this domain requires that the tracking platforms equipped should have outstanding computing power to handle the tasks in real-time with high-accuracy, while at the same time, fit the highly constrained environment of small size, light weight, and low power consumption (SWaP) for the purpose of long-term surveillance. In this paper, we proposed a new autonomous object tracking system based on an embedded platform, leveraging the emerging neural network hardware which is capable of massive parallel pattern recognition processing and demands only a low level power consumption. Further, a prototype of the tracking system that combines a low-power neural network chip, CogniMem, and an embedded development board, BeagleBone, is developed. Our experimental results show that the power consumption for the entire system is only about 2. 25W, which signifies a promising future of applying ultra-low-power neuromorphic hardware as a accelerator in recognition tasks.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489157,2018 International Joint Conference on Neural Networks (IJCNN)
Biomimetic Motion Detection,10.1109/ISSNIP.2007.4496833,2007,f,x,"X2,X4",,IEEE Xplore,,R. S. Brinkworth; D. C. O'Carroll,"We present the results of a biomimetic model of motion detection in the insect visual system based on an elaborated correlational elementary motion detector. This model incorporates a number of elements known, or predicted, to be in the insect motion processing pathway. The results show that this model greatly diminishes velocity ambiguity across images from different environments. Due to the nature of the algorithms underlying the model it lends itself to implementation in either digital or analogue hardware including neuromorphic analogue VLSI. The successful application of this algorithm has applications in the development of miniature autonomous systems in defence and civilian roles, including robotics, miniature unmanned aerial vehicles and collision avoidance sensors.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4496833,"2007 3rd International Conference on Intelligent Sensors, Sensor Networks and Information"
Toward Near-Real-Time Training With Semi-Random Deep Neural Networks and Tensor-Train Decomposition,10.1109/JSTARS.2021.3096195,2021,f,x,X2,"UAV detection, but no SNN used",IEEE Xplore,,H. Syed; R. Bryla; U. Majumder; D. Kudithipudi,"In recent years, deep neural networks have shown to achieve state-of-the-art performance on several classification and prediction tasks. However, these networks demand undesirable lengthy training times coupled with high computational resources (memory, I/O, processing time). In this work, we explore semi-random deep neural networks to achieve near real-time training and less computational resource usage. Although many works enhance the underlying hardware for real-time training, this work focuses on algorithmic optimization. It is shown that random projection networks with additional skipped connectivity and randomly weighted layers can boost the overall network performance while enabling for real-time training. Additionally, a tensor-train decomposition technique is leveraged to further reduce the model complexity of these networks. Our investigation accomplishes the following: 1) Tensor-train decomposition decreases the complexity of random projection networks, 2) compression of the fully connected hidden layer leads to a minimum ~ 40× decrease in memory size, and 3) training under random projection networks can be achieved in near-real time.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9492908,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing
ColibriES: A Milliwatts RISC-V Based Embedded System Leveraging Neuromorphic and Neural Networks Hardware Accelerators for Low-Latency Closed-loop Control Applications,10.1109/ISCAS46773.2023.10181726,2023,f,x,X4,,IEEE Xplore,,G. Rutishauser; R. Hunziker; A. Di Mauro; S. Bian; L. Benini; M. Magno,"End-to-end event-based computation has the poten-tial to push the envelope in latency and energy efficiency for edge AI applications. Unfortunately, event-based sensors (e.g., DVS cameras) and neuromorphic spike-based processors (e.g., Loihi) have been designed in a decoupled fashion, thereby missing major streamlining opportunities. This paper presents ColibriES, the first-ever neuromorphic hardware embedded system plat-form with dedicated event-sensor interfaces and full processing pipelines. ColibriES includes event and frame interfaces and data processing, aiming at efficient and long-life embedded systems in edge scenarios. ColibriES is based on the Kraken system-on-chip and contains a heterogeneous parallel ultra-low power (PULP) processor, frame-based and event-based camera interfaces, and two hardware accelerators for the computation of both event-based spiking neural networks and frame-based ternary convolutional neural networks. This paper explores and accurately evaluates the performance of event data processing on the example of gesture recognition on ColibriES, as the first step of full-system evaluation. In our experiments, we demonstrate a chip energy consumption of 7.7 mJ and latency of 164.5 ms of each inference with the DVS Gesture event data set as an example for closed-loop data processing, showcasing the potential of ColibriES for battery-powered applications such as wearable devices and UAVs that require low-latency closed-loop control.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10181726,2023 IEEE International Symposium on Circuits and Systems (ISCAS)
SNNTracker: Online High-Speed Multi-Object Tracking With Spike Camera,10.1109/TPAMI.2025.3610696,2026,f,x,"X1,X4","drone view object detection, but not mentioned if also usable for drone detection",IEEE Xplore,,Y. Zheng; C. Li; J. Zhang; Z. Yu; T. Huang,"Multi-object tracking (MOT) is crucial for applications such as autonomous driving and robotics, yet traditional image-based methods struggle in high-speed scenarios due to motion blur and temporal gaps caused by low frame rates. Spike cameras, with their ability to continuously record spatiotemporal signals, overcome these limitations. However, existing spike-based methods often rely on intermediate image reconstruction or discrete clustering, limiting real-time performance and temporal continuity. To address this, we propose SNNTracker, the first fully spiking neural network (SNN)-based MOT algorithm tailored for spike cameras. SNNTracker integrates a dynamic neural field (DNF)-based attention mechanism for target detection and a winner-take-all (WTA)-based tracking module with online spike-timing-dependent plasticity (STDP) for adaptive learning of object trajectories. By directly processing spike streams without reconstruction, SNNTracker reduces latency, computational overhead, and dependency on image quality, making it ideal for ultra-high-speed environments. It maintains robust, continuous tracking even under occlusions, severe lighting variations, or temporary object disappearance, by leveraging SNN-estimated motion predictions and long-term online clustering. We construct three types of spike-camera MOT datasets covering dense and sparse annotations across diverse real-world scenarios, including camera ego-motion, deformable and ultra-fast motion (up to 2600 RPM), occlusion, indoor/outdoor lighting changes, and low-visibility tracking. Extensive experiments demonstrate that SNNTracker consistently outperforms state-of-the-art MOT methods—both ANN- and SNN-based—achieving MOTA scores above 96% and up to 100% in many sequences. Our results highlight the advantages of spike-driven SNNs for low-latency, high-speed, and label-free multi-object tracking, advancing neuromorphic vision for real-time perception.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11165142,IEEE Transactions on Pattern Analysis and Machine Intelligence
AI‐Enabled Energy Management in Mobile Wireless Sensor Network for 6G Internet‐of‐Things (IoT),10.1002/9781394411337.ch1,2025,t,x,X4,,IEEE Xplore,,B. P. SINGH; L. SONI; A. TANEJA,"Summary <p>Mobile wireless sensor networks (MWSNs) within the Internet‐of‐Things (IoT) are undergoing a significant transformation with the advent of sixth generation (6G) technology, which prioritizes low‐latency, high‐speed communication, and efficient energy management. This chapter explores the artificial intelligence (AI)‐driven strategies that enhance the performance of 6G‐enabled MWSNs while optimizing energy consumption and extending network lifespan. It explores the roles of federated learning, deep learning and reinforcement learning in addressing the energy efficiency challenges. The chapter introduces innovative approaches for intelligent and sustainable energy management in next‐generation wireless networks, leveraging neuromorphic computing and quantum‐inspired algorithms to achieve smarter and more eco‐friendly operations. Genetic algorithms may be applied to solve complex, multifarious optimization problems in 6G IoT MWSN energy management.</p>",https://ieeexplore.ieee.org/xpl/ebooks/bookPdfWithBanner.jsp?fileName=11251464.pdf&bkn=11251358&pdfType=chapter,6G Urban Innovation: AI and Digital Twin for Next-Gen Sustainable Cities
Challenges and Perspectives in Neuromorphic-based Visual IoT Systems and Networks,10.1109/ICASSP40776.2020.9054303,2020,f,x,X4,,IEEE Xplore,,M. Martini; N. Khan; Y. Bi; Y. Andreopoulos; H. Saki; M. Shikh-Bahaei,"Neuromorphic sensors, a.k.a. dynamic vision sensors (DVS) or silicon retinas, do not capture full images (frames) at a fixed rate, but asynchronously capture spikes indicating changes of brightness in the scene, following the principles of biological vision and perception in mammals. DVS sensing and processing produces a data representation where the scene can be represented with a very high time resolution with a limited number of bits (an inherent data compression is performed at the time of acquisition). Such representation can be used locally to derive actionable responses and selected parts can be transmitted and then processed in another network location. Due to these features, such sensors represent an excellent choice as visual sensing technology for next-generation Internet-of-Things, e.g. in surveillance, drone technology, and robotics. It is in fact becoming evident that in this framework acquiring, processing, and transmitting frame-based video is inefficient in terms of energy consumption and reaction times, in particular in some scenarios. Hence, we explore here the feasibility of advanced Machine to Machine (M2M) communications systems that directly capture, compress and transmit spike-based visual information to cloud computing services in order to produce content classification or retrieval results with extremely low power and low latency.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9054303,"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
The Dynamic Vision Sensor Stereo Vision Calibration Inspired by Biology,10.1109/INCOFT60753.2023.10425397,2023,f,x,"X1,X4",drone view object detection,IEEE Xplore,,A. Garg,"The bio-inspired Dynamic Vision Sensor's (DVS) ability to get event-based vision with excellent temporal precision, a wide dynamic range, and low power consumption is increasing its appeal. Some examples of where this can be useful include in surveillance, robotics, and self-navigating in hazardous or otherwise unpredictable environments. In this research, we explain how to offer event-based vision for 3D reconstruction of dynamic scenes using a pair of fixed DVS in stereo. With an emphasis on cooperative stereo, we propose a new method that can cut the observed average error by over 50% compared to the state-of-the-art. In order to examine the method's sensitivity to parameter modification and to compare it to other methods, we make use of a publicly accessible real-time data collection for stereo event data.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10425397,2023 2nd International Conference on Futuristic Technologies (INCOFT)
Artificial Intelligence Based High Definition Map Generation From Mobile Mapping Data,10.1109/ACCESS.2025.3587592,2025,t,x,X4,,IEEE Xplore,,Á. József Somogyi; D. Baranyai; M. Dowajy; T. Lovas; Z. Szalay; T. Tettamanti,"The production of High-Definition (HD) maps has become an increasingly researched area in recent years, along with the rise of self-driving vehicles. One area is the automatic evaluation of road networks and their environment. This research presents a workflow for the evaluation of a point cloud dataset generated by a mobile mapping system. In the initial step of the procedure, a Shallow Neural Network (SNN) classification method is utilized to determine the segment of the point cloud corresponding to the path of the mapped area. Then, exploiting the GPS (Global Positioning System) time data of the points, the boundaries of the path are determined, which are used as a last step to carry out the OpenDRIVE structure. The presented workflow has been validated on real measurement data from the ZalaZONE Automotive Proving Ground. The results are convincing and justify the proposed methodology. The median cross-sectional deviation of the path achieved an accuracy of 5 cm, and the areas covered by the path showed a 97% similarity. The High Speed Handling course (one of the proving ground modules) has been used for the testing and validation of the semi-automatic HD map generation workflow. The generated HD maps and related models have been openly shared and also integrated into MATLAB software (since the 2026 release of MATLAB).",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11075677,IEEE Access
Event-based Navigation for Autonomous Drone Racing with Sparse Gated Recurrent Network,10.23919/ECC55457.2022.9838538,2022,t,x,X1,,IEEE Xplore,,K. F. Andersen; H. X. Pham; H. I. Ugurlu; E. Kayacan,"Event-based vision has already revolutionized the perception task for robots by promising faster response, lower energy consumption, and lower bandwidth without introducing motion blur. In this work, a novel deep learning method based on gated recurrent units utilizing sparse convolutions for detecting gates in a race track is proposed using event-based vision for the autonomous drone racing problem. We demonstrate the efficiency and efficacy of the perception pipeline on a real robot platform that can safely navigate a typical autonomous drone racing track in real-time. Throughout the experiments, we show that the event-based vision with the proposed gated recurrent unit and pretrained models on simulated event data significantly improve the gate detection precision. Furthermore, an event-based drone racing dataset11The code and data will be available at https://github.com/open-airlab/neuromorphic_au_drone_racing.git consisting of both simulated and real data sequences is publicly released.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9838538,2022 European Control Conference (ECC)
A 73.53TOPS/W 14.74TOPS Heterogeneous RRAM In-Memory and SRAM Near-Memory SoC for Hybrid Frame and Event-Based Target Tracking,10.1109/ISSCC42615.2023.10067544,2023,f,i,,,IEEE Xplore,,M. Chang; A. S. Lele; S. D. Spetalnick; B. Crafton; S. Konno; Z. Wan; A. Bhat; W. -S. Khwa; Y. -D. Chih; M. -F. Chang; A. Raychowdhury,"Vision-based high-speed target-identification and tracking is a critical application in unmanned aerial vehicles (UAV) with wide military and commercial usage. Traditional frame cameras processed through convolutional neural networks (CNN) exhibit high target-identification accuracy but with low throughput (hence low tracking speed) and high power. On the other hand, event cameras or dynamic vision sensors (DVS) generate a stream of binary asynchronous events corresponding to the changing intensity of the pixels capturing high-speed temporal information, characteristic of high-speed tracking. Such event streams with high spatial sparsity processed with bio-mimetic spiking neural networks (SNN) provide low power consumption and high throughput. However, the accuracy of object detection using such event cameras and SNNs is limited. Thus, a frame pipeline with a CNN and an event pipeline with a SNN (Fig. 29.5.1) possess complementary strengths in capturing and processing the spatial and temporal details, respectively. Hence, a hybrid network that fuses frame data processed using a CNN pipeline with event data processed through an SNN pipeline provides a platform for high-speed, high-accuracy and low-power target-identification and tracking. To address this need, we present a fully-programmable heterogeneous ARM Cortex-based SoC with an in-memory low-power RRAM-based CNN and a near-memory high-speed SRAM-based SNN in a hybrid architecture with applications in high-speed target identification and tracking.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10067544,2023 IEEE International Solid-State Circuits Conference (ISSCC)
Density Invariant Contrast Maximization for Neuromorphic Earth Observations,10.1109/CVPRW59228.2023.00415,2023,t,x,X4,,IEEE Xplore,,S. Arja; A. Marcireau; R. L. Balthazor; M. G. McHarg; S. Afshar; G. Cohen,"Contrast maximization (CMax) techniques are widely used in event-based vision systems to estimate the motion parameters of the camera and generate high-contrast images. However, these techniques are noise-intolerance and suffer from the multiple extrema problem which arises when the scene contains more noisy events than structure, causing the contrast to be higher at multiple locations. This makes the task of estimating the camera motion extremely challenging, which is a problem for neuromorphic earth observation, because, without a proper estimation of the motion parameters, it is not possible to generate a map with high contrast, causing important details to be lost. Similar methods that use CMax addressed this problem by changing or augmenting the objective function to enable it to converge to the correct motion parameters. Our proposed solution overcomes the multiple extrema and noise-intolerance problems by correcting the warped event before calculating the contrast and offers the following advantages: it does not depend on the event data, it does not require a prior about the camera motion and keeps the rest of the CMax pipeline unchanged. This is to ensure that the contrast is only high around the correct motion parameters. Our approach enables the creation of better motion-compensated maps through an analytical compensation technique using a novel dataset from the International Space Station (ISS). Code is available at https://github.com/neuromorphicsystems/event_warping",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10208732,2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
A Memristor-Based Bipolar Cell Neuron Circuit for Motion Detection and Action Prediction,10.1109/TCSII.2024.3380625,2024,a,x,X1,uav navigation,IEEE Xplore,,Z. Feng; J. Zou; W. Guo; X. Fang; T. Chen; X. Ma; R. Yu; S. Tan; Y. Hu; Z. Wang; Z. Xu; Y. Zhu; Y. Dai; Z. Wu,"In this brief, inspired by biological vision systems, a memristor-based bipolar cell neuron circuit (BCNC) is proposed, which can efficiently process incremental information to accurately encode changes in analog signals, improving the system’s ability to perceive direction information of object movement. To further verify the feasibility, a BCNC based sensory nervous system constructed for detecting motion and predicting actions. Simulation results demonstrate that compared with traditional LIF neurons, BCNC has enhanced performance (14.2%) in accurately identifying motion and predicting actions in unmanned aerial vehicle (UAV) navigation tasks. This brief provides a new idea for enriching the function of memristor based neuron circuit, and provides a new solution for the development of artificial neuron circuit with better biological similarity, and lays a foundation for the development of more intelligent artificial neuromorphic computing systems.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10478080,IEEE Transactions on Circuits and Systems II: Express Briefs
Fusing Event-based Camera and Radar for SLAM Using Spiking Neural Networks with Continual STDP Learning,10.1109/ICRA48891.2023.10160681,2023,a,x,X1,uav navigation,IEEE Xplore,,A. Safa; T. Verbelen; I. Ocket; A. Bourdoux; H. Sahli; F. Catthoor; G. Gielen,"This work proposes a first-of-its-kind SLAM architecture fusing an event-based camera and a Frequency Modulated Continuous Wave (FMCW) radar for drone navigation. Each sensor is processed by a bio-inspired Spiking Neural Network (SNN) with continual Spike-Timing-Dependent Plasticity (STDP) learning, as observed in the brain. In contrast to most learning-based SLAM systems, our method does not require any offline training phase, but rather the SNN continuously learns features from the input data on the fly via STDP. At the same time, the SNN outputs are used as feature descriptors for loop closure detection and map correction. We conduct numerous experiments to benchmark our system against state-of-the-art RGB methods and we demonstrate the robustness of our DVS-Radar SLAM approach under strong lighting variations.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10160681,2023 IEEE International Conference on Robotics and Automation (ICRA)
Multiple Simultaneous Rotation Event-Based Angular Speed Measurement,10.1109/JSEN.2025.3528230,2025,f,x,X4,"motor speed measurement. Could be may even used for UAV detection, but not reported",IEEE Xplore,,G. O. d. A. Azevedo; L. H. d. S. Silva; A. Freire; R. P. d. Araújo; B. J. T. Fernandes,"Monitoring rotating machines is essential for evaluating operations, preventing failures, and improving efficiency. Traditional rotational measurement methods, like magnetic induction or optical sensors, typically require dedicated hardware for each rotating part, making them costly and complex to implement, especially in industrial scenarios. The challenge intensifies when multiple rotations must be measured simultaneously. This study introduces a novel method using a single-event-based vision sensor, or dynamic vision sensor (DVS), which offers asynchronous pixel activation, high temporal resolution, and a wide dynamic range. Unlike traditional frame-based sensors, which require high frame rates and generate large data volumes, the DVS analyzes event streams and processes signals to identify crossing edges and time intervals. This enables simultaneous measurement of multiple rotating parts. The method was tested on a fan propeller, a CNC lathe, and drone propellers, demonstrating a relative mean absolute error (MAE) of around 0.5%. This method allows safe distance measurements without altering the original production line due to its non-contact nature.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10844046,IEEE Sensors Journal
STDP-Driven Development of Attention-Based People Detection in Spiking Neural Networks,10.1109/TCDS.2022.3210278,2024,t,x,X4,,IEEE Xplore,,A. Safa; I. Ocket; A. Bourdoux; H. Sahli; F. Catthoor; G. G. E. Gielen,"This letter provides, to the best of our knowledge, a first analysis of how biologically plausible spiking neural networks (SNNs) equipped with spike-timing-dependent plasticity (STDP) can learn to detect people on the fly from nonindependent and identically distributed (non-i.i.d) streams of retina-inspired, event camera data. Our system works as follows. First, a short sequence of event data, capturing a walking human from a flying drone, is forwarded in its natural order to an SNN-STDP system, which also receives teacher spiking signals from the neural activity readout block. Then, when the end of the learning sequence is reached, the learned system is assessed on testing sequences. In addition, we also present a new interpretation of anti-Hebbian plasticity as an overfitting control mechanism and provide experimental demonstrations of our findings. This work contributes to the study of attention-based development and perception in bioinspired systems.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9904898,IEEE Transactions on Cognitive and Developmental Systems
RF Fingerprinting Based on Reservoir Computing Using Narrowband Optoelectronic Oscillators,10.1109/JLT.2022.3198967,2022,f,x,X2,"No SNN, only reservoir computing",IEEE Xplore,,H. Dai; Y. K. Chembo,"Radiofrequency (RF) fingerprinting refers to a range of technologies that recognize transmitters by their intrinsic hardware-level characteristics. These characteristics are often introduced during the fabrication process and form a unique fingerprint of the transmitter that is very hard to counterfeit. RF fingerprinting often serves as a security measure at the physical-layer of communication networks against potentials attacks. In recent years, neuromorphic computing techniques such as convolutional neural networks (CNNs) have been explored as classifiers for RF fingerprinting. However, in radiofrequency communication networks, the transmitted signals are I/Q modulated on multi-GHz carriers while most conventional machine learning algorithms operate at the baseband. Therefore, the I/Q modulated signals have to be demodulated and converted into compatible formats before applying to these platforms – a procedure that inevitably slows down the processing speed. Moreover, the deep learning technologies often require a large amount of data to train the artificial neural networks (ANNs) while in practice, the available amount of data for a new transmitter is limited. Reservoir computing (RC) provides a relatively simple yet powerful structure that is capable of reaching state-of-the-art performance on several benchmarks. However, traditional digital RC also operates at baseband, which is not suitable for directly processing the I/Q modulated signals. In this article, we propose a reservoir computer based on narrowband optoelectronic oscillator (OEO) that can be utilized to directly classify I/Q modulated signals without the need for demodulation. We successfully train and test our narrowband OEO-based RC on three publicly available benchmarks, namely the FIT/CorteXlab RF fingerprinting dataset, the ORACLE RF fingerprinting dataset, and the AirID RF fingerprinting dataset. We show that for all three datasets, the narrowband OEO-based RC demonstrates competing accuracy with much less training data comparing to CNNs, and achieves an accuracy as high as 97%.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9858670,Journal of Lightwave Technology
Enhancing QoS and energy efficiency through hybrid heuristic and metaheuristic techniques in ultra dense small cell deployment,10.1109/ICMCTC62214.2025.11196594,2025,a,x,X4,,IEEE Xplore,,S. V. Kumar; A. Vijayalakshmi; A. Packialatha; S. K. Selvaperumal; M. Moorthi,"In an extremely dense network, the utilization of energy-efficient small cells contributes to the development of a wireless infrastructure that is both greener and better for the environment. In the present cell frameworks, there is a developing interest for enormous network and higher information rates, which small cell networks plan to satisfy. By decisively conveying small cells and improving their use, energy utilization can be fundamentally diminished. The emphasis is on accomplishing ideal asset use and amplifying energy effectiveness, guaranteeing that the small cells work at their maximum capacity while limiting their natural effect. This approach lines up with the rising requirement for manageable and eco-accommodating arrangements in the media communications industry. This paper presents a methodology that consolidates cross breed heuristic and metaheuristic procedures for the arrangement of super thick small cells. The primary objective is to enhance the network’s energy efficiency and quality of service (QoS). By shrewdly upgrading the position and boundaries of small cells, we can improve the general organization execution, guarantee solid network, and limit energy utilization. Our multi-objective artificial flora optimization (MOAFO) algorithm aids in user clustering by enabling the efficient offloading of data traffic from macro cells and an increase in the number of users in small cells. Thusly, it prompts upgraded information throughput for large scale cell clients. The assurance of ideal small cell areas is brought out through the modified anopheles search (MAS) calculation, which considers different plan imperatives. The quality of small base station deployment is also enhanced by our use of a Siamese neural network (SNN) to characterize the traffic distribution model. To evaluate the performance of our proposed methodology, we conduct extensive simulations under different scenarios. These simulations demonstrate the effectiveness of our approach in achieving improved energy efficiency and meeting QoS constraints.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11196594,2025 International Conference on Metaverse and Current Trends in Computing (ICMCTC)
Analog Signal Processing Using Stochastic Magnets,10.1109/ACCESS.2021.3075839,2021,f,x,X4,,IEEE Xplore,,S. Ganguly; K. Y. Camsari; A. W. Ghosh,"We present a low energy-barrier magnet based compact hardware unit for analog stochastic neurons (ASNs) and demonstrate its use as a building-block for neuromorphic hardware. Networks assembled from these units are particularly suited for temporal inferencing and pattern recognition. We demonstrate example applications of these ASNs including multi-layer perceptrons, convolutional neurons, and reservoir computers showing tasks such as temporal sequence learning, processing, and prediction tasks which prove that these units can be used to build efficient, scalable, and adaptive neural network based signal-processors. We also provide an illustrative comparison with digital CMOS based circuits that implement similar functionality with networks built using the presented units, demonstrating a possible two orders of magnitude reduction in component-count and concomitant increase in energy efficiency. Efficient non von-Neumann hardware implementation of such signal-processors can open up a pathway for integration of hardware based cognition in a wide variety of emerging systems such as IoT, industrial controls, bio- and photo-sensors, self-driving automotives, and unmanned aerial vehicles.",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9416458,IEEE Access
Drone Detection Using a&#xa0;Low-Power Neuromorphic Virtual Tripwire,10.1007/978-3-031-92460-6_7,2025,f,i,,,Springer Link,,Anton Eldeborg LundinRasmus WinzellHanna HamrellDavid GustafssonHannes Ovrén,,https://link.springer.com/chapter/10.1007/978-3-031-92460-6_7,Computer Vision – ECCV 2024 Workshops
Spiking SiamFC++: deep spiking neural network for object tracking,10.1007/s11071-024-09525-8,2024,f,x,X4,"While UAV123 dataset includes UAV → UAV tracking/detection, their model does not include target identification, only tracking",Springer Link,,Shuiying XiangTao ZhangShuqing JiangYanan HanYahui ZhangXingxing GuoLicun YuYuechun ShiYue Hao,,https://link.springer.com/article/10.1007/s11071-024-09525-8,Nonlinear Dynamics
Convolutional transform learning based fusion framework for scale invariant long term target detection and tracking in unmanned aerial vehicles,10.1038/s41598-025-09652-1,2025,f,x,X1,drone view object detection,Springer Link,,Fatma S. AlrayesNazir AhmadAsma AlshuhailMenwa AlshammeriAli AlqazzazHassan AlkhiriJehad Saad AlqurniYahia Said,,https://link.springer.com/article/10.1038/s41598-025-09652-1,Scientific Reports
CD-YOLOv8s: an optimized high-altitude real-time UAV recognition method based on image detection,10.1007/s11227-025-07446-w,2025,f,x,X2,Don’t use SNNs but cite another SNN paper (also included in this screening),Springer Link,,Bing SuJie ZhangYifeng Lin,,https://link.springer.com/article/10.1007/s11227-025-07446-w,The Journal of Supercomputing
Low-cost UAV detection via WiFi traffic analysis and machine learning,10.1038/s41598-023-47453-6,2023,f,x,X2,"SNN in their paper means Shallow Neural network, not spiking",Springer Link,,Longtao BiZi-Xin XuLing Yang,,https://link.springer.com/article/10.1038/s41598-023-47453-6,Scientific Reports
A tunable multi-timescale Indium-Gallium-Zinc-Oxide thin-film transistor neuron towards hybrid solutions for spiking neuromorphic applications,10.1038/s44172-024-00248-7,2024,f,x,X4,,Springer Link,,Mauricio Velazquez LopezBernabe Linares-BarrancoJua LeeHamidreza ErfanijaziAlberto Patino-SaucedoManolis SifalakisFrancky CatthoorKris Myny,,https://link.springer.com/article/10.1038/s44172-024-00248-7,Communications Engineering
Memristive dynamics enabled neuromorphic computing systems,10.1007/s11432-023-3739-0,2023,f,x,X4,,Springer Link,,Bonan YanYuchao YangRu Huang,,https://link.springer.com/article/10.1007/s11432-023-3739-0,Science China Information Sciences
On non-von Neumann flexible neuromorphic vision sensors,10.1038/s41528-024-00313-3,2024,a,x,X4,,Springer Link,,Hao WangBin SunShuzhi Sam GeJie SuMing Liang Jin,,https://link.springer.com/article/10.1038/s41528-024-00313-3,npj Flexible Electronics
NeuroMoCo: a neuromorphic momentum contrast learning method for spiking neural networks,10.1007/s10489-024-05982-1,2024,a,x,X4,only cifar and gesture detection,Springer Link,,Yuqi MaHuamin WangHangchi ShenXuemei ChenShukai DuanShiping Wen,,https://link.springer.com/article/10.1007/s10489-024-05982-1,Applied Intelligence
Classification of&#xa0;Hyperspectral Images Using Lightweight and&#xa0;Low-Latency Spiking Neural Networks Based on&#xa0;Knowledge Distillation,10.1007/978-981-96-6972-1_13,2025,t,x,X4,,Springer Link,,Yang LiuKun MeiHuaxu HeKun Cai,,https://link.springer.com/chapter/10.1007/978-981-96-6972-1_13,Neural Information Processing
Flexible neuromorphic transistors for neuromorphic computing and perception application,10.1007/s44275-024-00009-w,2024,a,x,X4,,Springer Link,,Shuo KeYixin ZhuChuanyu FuHuiwu MaoKailu ShiLesheng QiaoQing Wan,,https://link.springer.com/article/10.1007/s44275-024-00009-w,Moore and More
Ensemble genetic and CNN model-based image classification by enhancing hyperparameter tuning,10.1038/s41598-024-76178-3,2025,a,x,X4,mnist classification,Springer Link,,Wajahat HussainMuhammad Faheem MushtaqMobeen ShahrozUrooj AkramEhab Seif GhithMehdi TlijaTai-hoon KimImran Ashraf,,https://link.springer.com/article/10.1038/s41598-024-76178-3,Scientific Reports
Early Detection of&#xa0;Red Palm Weevil on&#xa0;Coconut Trees Using Deep Learning,10.1007/978-981-96-5589-2_23,2026,t,x,X4,,Springer Link,,Thomsy WilliamSilambarasan Elkana Ebinazer,,https://link.springer.com/chapter/10.1007/978-981-96-5589-2_23,Proceedings of International Conference on Advanced Communications and Machine Intelligence
Future Research Directions on Human-Centric Smart Manufacturing,10.1007/978-3-031-82170-7_16,2025,t,x,X4,,Springer Link,,Baicun WangPai ZhengCi SongDimitris MourtzisLihui Wang,,https://link.springer.com/chapter/10.1007/978-3-031-82170-7_16,Human-Centric Smart Manufacturing Towards Industry 5.0
Crop Identification by&#xa0;Using Machine Learning Classification Algorithm,10.1007/978-3-031-79041-6_18,2025,t,x,X4,,Springer Link,,Sunil BagNeelamadhab PadhyRasmita Panigrahi,,https://link.springer.com/chapter/10.1007/978-3-031-79041-6_18,"Computing, Communication and Learning"
Bio-inspired mid-infrared neuromorphic transistors for dynamic trajectory perception using PdSe<sub>2</sub>/pentacene heterostructure,10.1038/s41467-025-60311-5,2025,t,x,X4,,Springer Link,,Huaiyu GaoXiaoyong JiangXinyu MaMinrui YeJie YangJunyao ZhangYangchen GaoTangxin LiHailu WangJian MeiXiao FuXu LiuTongrui SunZiyi GuoPu GuoFansheng ChenKai ZhangJinshui MiaoWeida HuJia Huang,,https://link.springer.com/article/10.1038/s41467-025-60311-5,Nature Communications
Neuromorphic Circuits and Systems: From Neuron Models to Integrate-and-Fire Arrays,10.1007/978-981-16-5540-1_42,2023,a,x,X4,,Springer Link,Count: 2 | Sources: Springer Link,Jamal Lottier MolinRalph Etienne-Cummings,,https://link.springer.com/rwe/10.1007/978-981-16-5540-1_42,Handbook of Neuroengineering
A Top-Down Approach to SNN-STDP Networks,10.1007/978-3-031-63565-6_4,2024,a,x,X4,"MNIST, gesture but no drone detection",Springer Link,,Ali SafaLars KeuninckxGeorges GielenFrancky Catthoor,,https://link.springer.com/chapter/10.1007/978-3-031-63565-6_4,Neuromorphic Solutions for Sensor Fusion and Continual Learning Systems
Sensor Fusion SLAM with Continual STDP Learning,10.1007/978-3-031-63565-6_5,2024,t,x,X4,slam,Springer Link,,Ali SafaLars KeuninckxGeorges GielenFrancky Catthoor,,https://link.springer.com/chapter/10.1007/978-3-031-63565-6_5,Neuromorphic Solutions for Sensor Fusion and Continual Learning Systems
Mammalian-brain-inspired neuromorphic motion-cognition nerve achieves cross-modal perceptual enhancement,10.1038/s41467-023-36935-w,2023,a,x,X4,,Springer Link,,Chengpeng JiangJiaqi LiuYao NiShangda QuLu LiuYue LiLu YangWentao Xu,,https://link.springer.com/article/10.1038/s41467-023-36935-w,Nature Communications
Embodied neuromorphic intelligence,10.1038/s41467-022-28487-2,2022,a,x,X4,,Springer Link,,Chiara BartolozziGiacomo IndiveriElisa Donati,,https://link.springer.com/article/10.1038/s41467-022-28487-2,Nature Communications
F-E Fusion: A Fast Detection Method of&#xa0;Moving UAV Based on&#xa0;Frame and&#xa0;Event Flow,10.1007/978-3-031-44198-1_19,2023,f,i,,,Springer Link,,Xun XiaoZhong WanYuan LiShasha GuoJunbo TieLei Wang,,https://link.springer.com/chapter/10.1007/978-3-031-44198-1_19,Artificial Neural Networks and Machine Learning – ICANN 2023
"Autonomation, Automation, AI, and Industry-Agriculture 5.0 in Sustainable Agro-Ecological Food Production",10.1007/978-3-031-53991-6_42,2024,a,x,X4,,Springer Link,,Pinar DemirciogluIsmail BogrekciM. Numan DurakbasaJorge Bauer,,https://link.springer.com/chapter/10.1007/978-3-031-53991-6_42,Industrial Engineering in the Industry 4.0 Era
Cognitive Architecture for&#xa0;Learning in&#xa0;Autonomous Agents: A Study in&#xa0;Discrete Navigation,10.1007/978-3-032-07175-0_1,2026,t,x,"X1,X4",,Springer Link,,Jorge HernandezMaría F. Pollo-CattaneoDiego H. Peluffo-OrdóñezHector Florez,,https://link.springer.com/chapter/10.1007/978-3-032-07175-0_1,Applied Informatics
A lightweight deep learning model for multi-plant biotic stress classification and detection for sustainable agriculture,10.1038/s41598-025-90487-1,2025,t,x,X4,,Springer Link,,Wasswa ShafikAli TufailLiyanage Chandratilak De SilvaRosyzie Anna Awg Haji Mohd Apong,,https://link.springer.com/article/10.1038/s41598-025-90487-1,Scientific Reports
Trend Factor Smoothing and Tasmanian Devil Optimization based Siamese Neural Network for anomaly detection in predictive maintenance,10.1038/s41598-025-25312-w,2025,t,x,X4,,Springer Link,,Ida HectorRukmani Panjanathan,,https://link.springer.com/article/10.1038/s41598-025-25312-w,Scientific Reports
Speech based emotion recognition by using a faster region-based convolutional neural network,10.1007/s11042-024-19004-2,2024,t,x,X4,,Springer Link,,Chappidi SuneethaRaju Anitha,,https://link.springer.com/article/10.1007/s11042-024-19004-2,Multimedia Tools and Applications
Bioinspired PID Controller Based on Izhikevich Neurons Optimized by Differential Evolution for Neuromorphic Implementations,10.1007/978-3-031-49401-7_11,2024,t,x,X4,,Springer Link,,Júlia Nepomuceno MelloMariane Rodrigues GarciaAlcimar Barbosa SoaresFrederico Caetano Jandre,,https://link.springer.com/chapter/10.1007/978-3-031-49401-7_11,IX Latin American Congress on Biomedical Engineering and XXVIII Brazilian Congress on Biomedical Engineering
"Leveraging AI and Cybersecurity for Proactive Counterterrorism: Strategies, Risks, and Future Trends",10.1007/978-3-031-99235-3_8,2025,t,x,X4,,Springer Link,,VijetaShashank Solanki,,https://link.springer.com/chapter/10.1007/978-3-031-99235-3_8,Artificial Intelligence for Global Counter-Terrorism
Hypergraph-Based Asynchronous Event Processing for Moving Object Classification,10.1007/s12204-024-2699-y,2024,f,x,X4,,Springer Link,,Nannan YuChaoyi WangYu QiaoYuxin WangChenglin ZhengQiang ZhangXin Yang,,https://link.springer.com/article/10.1007/s12204-024-2699-y,Journal of Shanghai Jiaotong University (Science)
Solving the&#xa0;Lunar Lander Problem with&#xa0;Spiking Neural Networks and&#xa0;One-Hot Encoding,10.1007/978-3-031-96239-4_3,2025,t,x,X4,,Springer Link,,Jonas HansertPeter OffermannFranck Gechter,,https://link.springer.com/chapter/10.1007/978-3-031-96239-4_3,Artificial Intelligence Applications and Innovations
Automatic Segmentation of Road Surface Points Using Shallow Neural Network from 3D Colored Point Cloud Data,10.1007/978-3-031-87620-2_11,2025,t,x,X4,,Springer Link,,Mohammad DowajyTamás LovasÁrpád Barsi,,https://link.springer.com/chapter/10.1007/978-3-031-87620-2_11,Proceedings of the 2nd Cognitive Mobility Conference
Ultra-low power MoS<sub>2</sub> optoelectronic synapse with wavelength sensitivity for color target recognition,10.1007/s11432-024-4200-5,2025,t,x,X4,,Springer Link,,Bo WeiYabo ChenXiaotong HanYan KangBujia LiangCheng LiXiaokuo YangLiang FangYuanxi Peng,,https://link.springer.com/article/10.1007/s11432-024-4200-5,Science China Information Sciences
Bridging the Accuracy Gap Between SNNs and DNNs via the Use of Pre-Processing for Radar Applications,10.1007/978-3-031-63565-6_2,2024,a,x,X4,,Springer Link,,Ali SafaLars KeuninckxGeorges GielenFrancky Catthoor,,https://link.springer.com/chapter/10.1007/978-3-031-63565-6_2,Neuromorphic Solutions for Sensor Fusion and Continual Learning Systems
Detection and localization of deceptive nodes in underwater wireless sensor networks using secure routing,10.1007/s10791-025-09776-y,2025,t,x,X4,,Springer Link,,R. Sambath KumarG. Sivaradje,,https://link.springer.com/article/10.1007/s10791-025-09776-y,Discover Computing
Improving the performance of learned descriptors in the matching of high spatial resolution aerial images by proposing a large-scale dataset of vertical images,10.1007/s12517-023-11747-w,2023,t,x,X4,,Springer Link,,Nima FarhadiHamid EbadiAbbas Kiani,,https://link.springer.com/article/10.1007/s12517-023-11747-w,Arabian Journal of Geosciences
Blockchain-empowered generalized simplicial quantum equivariant convolutional attention network for secure 6G wireless network management,10.1007/s41870-025-02947-6,2025,t,x,X4,,Springer Link,,B. RameshKrishna Prakash ArunachalamLeela Santosh Varma KRakesh K. Kadu,,https://link.springer.com/article/10.1007/s41870-025-02947-6,International Journal of Information Technology
Enhanced Load-Settlement Curve Forecasts for Open-Ended Pipe Piles Incorporating Soil Plug Constraints Using Shallow and Deep Neural Networks,10.1007/s13344-025-0041-6,2025,t,x,X4,,Springer Link,,Luttfi A. Al-HaddadMohammed Y. FattahWissam H. S. Al-SoudaniSinan A. Al-HaddadAlaa Abdulhady Jaber,,https://link.springer.com/article/10.1007/s13344-025-0041-6,China Ocean Engineering
DETR-SPP: a fine-tuned vehicle detection with transformer,10.1007/s11042-023-16502-7,2023,a,x,"X1,X4",drone view object detection,Springer Link,,Krishnendhu S PPrabu Mohandas,,https://link.springer.com/article/10.1007/s11042-023-16502-7,Multimedia Tools and Applications
Vehicular Perception Improvement in an Inclement Weather Context,10.1007/978-3-031-19523-5_1,2023,t,x,X4,,Springer Link,,Abderraouf KhezazManolo Dulva HinaHongyu GuanAmar Ramdane-Cherif,,https://link.springer.com/chapter/10.1007/978-3-031-19523-5_1,Advances in Computational Intelligence and Communication
Artificial intelligence-based classification for waste management: a systematic review and future direction,10.1007/s42044-025-00336-7,2025,t,x,X4,,Springer Link,,Dhanashree Vipul YevlePalvinder Singh Mann,,https://link.springer.com/article/10.1007/s42044-025-00336-7,Iran Journal of Computer Science
Synergizing skeletal graph and deep features through transfer learning: a multimodal framework for action recognition,10.1007/s41870-025-02840-2,2025,t,x,X4,,Springer Link,,Priyanka ChaudhariGeetanjali Kale,,https://link.springer.com/article/10.1007/s41870-025-02840-2,International Journal of Information Technology
Deep Learning for Cattle Face Identification,10.1007/978-3-031-66705-3_21,2024,t,x,X4,,Springer Link,,Sinan DedeEleni VrochidouVenetis KanakarisGeorge A. Papakostas,,https://link.springer.com/chapter/10.1007/978-3-031-66705-3_21,Deep Learning Theory and Applications
An event-oriented diffusion-refinement method for sparse events completion,10.1038/s41598-024-57333-2,2024,t,x,X4,,Springer Link,,Bo ZhangYuqi HanJinli SuoQionghai Dai,,https://link.springer.com/article/10.1038/s41598-024-57333-2,Scientific Reports
Volcanic disaster scene classification of remote sensing image based on deep multi-instance network,10.1007/s11600-024-01394-4,2024,t,x,X4,,Springer Link,,Chengfan LiJingxin HanChengzhi WuLan LiuXuefeng LiuJunjuan Zhao,,https://link.springer.com/article/10.1007/s11600-024-01394-4,Acta Geophysica
An Adaptive Battery Health Monitoring Framework Using Wavelet Scattering and Spiking Graph Transformers Optimized by Arctic Wolf Algorithm,10.1007/s40998-025-00885-4,2025,t,x,X4,,Springer Link,,Ramamoorthy ML.Selvaperumal S.Nagarajan R.,,https://link.springer.com/article/10.1007/s40998-025-00885-4,"Iranian Journal of Science and Technology, Transactions of Electrical Engineering"
"Artificial Intelligence in Earthquake Disaster Risk Management: A Systematic Review of Applications, Challenges, and Research Gaps",10.1007/978-3-031-97992-7_85,2025,t,x,X4,,Springer Link,,Nurşen SönmezOnur Behzat TokdemirHüsnü Murat Günaydın,,https://link.springer.com/chapter/10.1007/978-3-031-97992-7_85,Intelligent and Fuzzy Systems
"Advancing cloud virtualization: a comprehensive survey on integrating IoT, Edge, and Fog computing with FaaS for heterogeneous smart environments",10.1007/s11227-025-07799-2,2025,t,x,X4,,Springer Link,,Mohammad Mahdi GhaseminyaElahe EslamiSeyed Abolfazl Shahzadeh FazeliJamshid AboueiElham AbbasiSeyed Mehdi Karbassi,,https://link.springer.com/article/10.1007/s11227-025-07799-2,The Journal of Supercomputing
Pre-flood and Post-flood Classification of Landsat 8 OLI Images of Florida in USA with Low Time Complexity,10.1007/s12524-023-01784-z,2023,t,x,X4,,Springer Link,,Amit Kumar RaiNirupama MandalKrishna Kant Singh,,https://link.springer.com/article/10.1007/s12524-023-01784-z,Journal of the Indian Society of Remote Sensing
Specified Number of Nodes Travelling Salesman Problem,10.1007/978-3-031-95693-5_3,2025,t,x,X4,,Springer Link,,Trust TawandaSantosh KumarElias MunapoPhilimon Nyamugure,,https://link.springer.com/chapter/10.1007/978-3-031-95693-5_3,Advances in Mathematics for Engineering Sciences
Enhancing IoT Network Security by Anomaly Detection and Intrusion Prevention Using Gannet Optimization-Based Adaptive Deep Capsule Network,10.1007/s44196-025-00940-2,2025,t,x,X4,,Springer Link,,WeiWei HuJafar A. AlzubiJ. ShreyasMuna Al-RazganYasser A. AliA. Karthikayan,,https://link.springer.com/article/10.1007/s44196-025-00940-2,International Journal of Computational Intelligence Systems
A Multispectral Image Classification Framework for&#xa0;Estimating the&#xa0;Operational Risk of&#xa0;Lethal Wilt in&#xa0;Oil Palm Crops,10.1007/978-3-031-30229-9_32,2023,t,x,X4,,Springer Link,,Alejandro PeñaAlejandro PuertaIsis BonetFabio CaraffiniMario GongoraIvan Ochoa,,https://link.springer.com/chapter/10.1007/978-3-031-30229-9_32,Applications of Evolutionary Computation
Assessing Data-Driven of Discriminative Deep Learning Models in Classification Task Using Synthetic Pandemic Dataset,10.1007/978-3-031-78255-8_17,2025,t,x,X4,,Springer Link,,Sunday Adeola AjagbePragasen MudaliMatthew O. Adigun,,https://link.springer.com/chapter/10.1007/978-3-031-78255-8_17,Artificial Intelligence Research
Recent advances in halide perovskite memristors: From materials to applications,10.1007/s11467-023-1344-9,2023,t,x,X4,,Springer Link,,Sixian LiuJianmin ZengQilai ChenGang Liu,,https://link.springer.com/article/10.1007/s11467-023-1344-9,Frontiers of Physics
Advances in Sand Cat Swarm Optimization: A Comprehensive Study,10.1007/s11831-024-10217-0,2025,t,x,X4,,Springer Link,,Ferzat AnkaNazim Aghayev,,https://link.springer.com/article/10.1007/s11831-024-10217-0,Archives of Computational Methods in Engineering
Machine Learning Applications in VLSI Design and Testing,10.1007/978-981-95-0269-1_182,2026,a,x,X4,,Springer Link,,Pechetti SujaniSargari SwapnaVemula Shiva KumarSadula Sai PrasannaAppari Lakshmi PrasannaMaggidi Mounika,,https://link.springer.com/chapter/10.1007/978-981-95-0269-1_182,Proceedings of the 7th International Conference on Communications and Cyber Physical Engineering
Editorial,10.1007/s41870-025-02880-8,2025,a,x,X4,editorial letter about an issue but there is no SNN drone detection paper in it,Springer Link,,M. N. Hoda,,https://link.springer.com/article/10.1007/s41870-025-02880-8,International Journal of Information Technology
Addressing the Challenges in Federating Edge Resources,10.1007/978-3-031-96265-3_2,2026,a,x,X4,,Springer Link,,Ankit DubeySubham SharmaKhushboo DeviShailendra Pratap SinghBalamurugan BalusamyPrithi Samuel,,https://link.springer.com/chapter/10.1007/978-3-031-96265-3_2,"Integrating Cloud, Fog, and Edge Computing in Healthcare: Federated Learning and Blockchain Approaches"
Photonic signal processor based on a Kerr microcomb for real-time video image processing,10.1038/s44172-023-00135-7,2023,a,x,X4,,Springer Link,,Mengxi TanXingyuan XuAndreas BoesBill CorcoranThach G. NguyenSai T. ChuBrent E. LittleRoberto MorandottiJiayang WuArnan MitchellDavid J. Moss,,https://link.springer.com/article/10.1038/s44172-023-00135-7,Communications Engineering
Evolutionary Computation Modelling for Structural Health Monitoring of Critical Infrastructure,10.1007/s11831-022-09845-1,2022,t,x,X4,,Springer Link,,Charanjeet Singh TumrateDinesh Kumar SainiPunit GuptaDhaneshwar Mishra,,https://link.springer.com/article/10.1007/s11831-022-09845-1,Archives of Computational Methods in Engineering
Artificial morality basic device: transistor for mimicking morality logics,10.1007/s40843-023-2710-0,2024,t,x,X4,,Springer Link,,Shaomin ChenRengjian YuYi ZouXipeng YuChangfei LiuYuanyuan HuTailiang GuoHuipeng Chen,,https://link.springer.com/article/10.1007/s40843-023-2710-0,Science China Materials
The Future of Cybersecurity in Medical Devices,10.1007/978-3-032-07309-9_9,2025,t,x,X4,,Springer Link,,William HardingAndreas HartmannShayla O’BrienViktor SinzigGabriel BreakNatalie Sinzig,,https://link.springer.com/chapter/10.1007/978-3-032-07309-9_9,Securing a Connected Future
Deep learning techniques for enhanced security and privacy in 6G terrestrial–nonterrestrial network architecture,10.1007/s11227-025-07097-x,2025,t,x,X4,,Springer Link,,Maira KhalidJehad AliAhmed Raza MohsinByeong-hee RohMohammed J. F. Alenazi,,https://link.springer.com/article/10.1007/s11227-025-07097-x,The Journal of Supercomputing
AtomGAN: unsupervised deep learning for fast and accurate defect detection of 2D materials at the atomic scale,10.1007/s11432-022-3757-x,2023,t,x,X4,,Springer Link,,Danpeng ChengWuxin ShaZuo XuShide LiZhigao YinYuling LangShun TangYuan-Cheng Cao,,https://link.springer.com/article/10.1007/s11432-022-3757-x,Science China Information Sciences
The Convergence Effect,10.1007/979-8-8688-1177-7_5,2025,a,x,X4,,Springer Link,,Tal Elyashiv,,https://link.springer.com/chapter/10.1007/979-8-8688-1177-7_5,Investing in Revolutions
Semantic Image Segmentation of Agricultural Field Problem Areas Using Deep Neural Networks Based on the DeepLabV3 Model,10.1007/978-981-99-7093-3_30,2023,t,x,X4,,Springer Link,,Aleksey RogachevIlya BelousovDmitry Rogachev,,https://link.springer.com/chapter/10.1007/978-981-99-7093-3_30,Fourth International Conference on Image Processing and Capsule Networks
"Artificial Intelligence, Machine Learning, and Smart Technologies for Nondestructive Evaluation",10.1007/978-3-030-48200-8_70-1,2025,t,x,X4,,Springer Link,Count: 2 | Sources: Springer Link,Hossein TaheriArefeh Salimi Beni,,https://link.springer.com/rwe/10.1007/978-3-030-48200-8_70-1,Handbook of Nondestructive Evaluation 4.0
DeepSwarm: towards swarm deep learning with bi-directional optimization of data acquisition and processing,10.1007/s11704-024-40465-z,2024,t,x,X4,,Springer Link,,Sicong LiuBin GuoZiqi WangLehao WangZimu ZhouXiaochen LiZhiwen Yu,,https://link.springer.com/article/10.1007/s11704-024-40465-z,Frontiers of Computer Science
RRAM-Based Neuromorphic Computing Systems,10.1007/978-981-15-6912-8_12,2021,a,x,X4,,Springer Link,,Putu Andhita DananjayaRoshan GopalakrishnanWen Siang Lew,,https://link.springer.com/chapter/10.1007/978-981-15-6912-8_12,Emerging Non-volatile Memory Technologies
Advances in electrospun nanofiber-based electronic skin for smart sensing and energy harvesting,10.1007/s44291-025-00138-y,2025,t,x,X4,,Springer Link,,Muhammad Azam FareedKashan MemonBing ZhangZhicheng LiuGang Zhao,,https://link.springer.com/article/10.1007/s44291-025-00138-y,Discover Electronics
Deep and machine learning prediction of forest above-ground biomass using multi-source remote sensing data in coniferous planted forests in Iran,10.1007/s10342-024-01721-w,2024,t,x,X4,,Springer Link,,Hassan AliJahangir MohammadiShaban Shataee Jouibary,,https://link.springer.com/article/10.1007/s10342-024-01721-w,European Journal of Forest Research
Design of an improved model for secure routing using CAFR-net and EPM-core in adversarial network environments,10.1007/s41870-025-03011-z,2025,t,x,X4,,Springer Link,,Rahul MahajanSrikant V. Sonekar,,https://link.springer.com/article/10.1007/s41870-025-03011-z,International Journal of Information Technology
Multilayer spintronic neural networks with radiofrequency connections,10.1038/s41565-023-01452-w,2023,f,x,X2,"Drone detection but no SNN involved, only neuromorphic computing, input: RF signals",Springer Link,,Andrew RossNathan LerouxArnaud De RizDanijela MarkovićDédalo Sanz-HernándezJuan TrastoyPaolo BortolottiDamien QuerliozLeandro MartinsLuana BenettiMarcel S. ClaroPedro AnacletoAlejandro SchulmanThierry TarisJean-Baptiste BegueretSylvain SaïghiAlex S. JenkinsRicardo FerreiraAdrien F. VincentFrank Alice MizrahiJulie Grollier,,https://link.springer.com/article/10.1038/s41565-023-01452-w,Nature Nanotechnology
Fuzzy Adaptive Neurons Applied to the Identification of Parameters and Trajectory Tracking Control of a Multi-Rotor Unmanned Aerial Vehicle Based on Experimental Aerodynamic Data,10.1007/s10846-020-01198-w,2020,a,x,X4,,Springer Link,,A. M. E. Ramírez-MendozaJ. R. Covarrubias-FabelaL. A. Amezquita-BrooksO. García-SalazarW. Yu,,https://link.springer.com/article/10.1007/s10846-020-01198-w,Journal of Intelligent & Robotic Systems
"Transformative marketing strategies in the era of new-age technologies: Principles, plan, purpose, and practice",10.1007/s11747-025-01120-6,2025,t,x,X4,,Springer Link,,V. KumarPhilip KotlerAjay Kumar,,https://link.springer.com/article/10.1007/s11747-025-01120-6,Journal of the Academy of Marketing Science
An Adaptive Density Peak Clustering Algorithm Based on N-ary Bézier Reverse Curve Optimization,10.1007/978-981-96-9884-4_25,2025,t,x,X4,,Springer Link,,Le YangRui-dong QiJian-tao Zhou,,https://link.springer.com/chapter/10.1007/978-981-96-9884-4_25,Advanced Intelligent Computing Technology and Applications
AI-Enhanced Remote Sensing Applications in Earth Science Processes for Enhancing Sanitation Workers’ Safety,10.1007/s41976-024-00160-w,2024,t,x,X4,,Springer Link,,Ragavee Uthaya KumarKesavan Shobana Shoba JasminAsha Sundaram,,https://link.springer.com/article/10.1007/s41976-024-00160-w,Remote Sensing in Earth Systems Sciences
Evolution and future directions of video coding standards and emerging compression technologies,10.1007/s11042-025-21108-2,2025,t,x,X4,,Springer Link,,Wael Badawy,,https://link.springer.com/article/10.1007/s11042-025-21108-2,Multimedia Tools and Applications
"Technologies, Techniques, and Components",10.1007/978-3-031-56713-1_5,2024,t,x,X4,,Springer Link,,Arshad Khan,,https://link.springer.com/chapter/10.1007/978-3-031-56713-1_5,Artificial Intelligence: A Guide for Everyone
Machine Learning Innovations in Revolutionizing Earthquake Engineering: A Review,10.1007/s11831-025-10320-w,2025,t,x,X4,,Springer Link,,Umar Ahmad Noor,,https://link.springer.com/article/10.1007/s11831-025-10320-w,Archives of Computational Methods in Engineering
AI-Driven Cognitive Radio Networks for Transforming Industries and Sectors Towards a Smart World,10.1007/978-981-97-6790-8_1,2024,t,x,X4,,Springer Link,,Nandkishor JoshiNitin AroraHemant YadavS. C. Sharma,,https://link.springer.com/chapter/10.1007/978-981-97-6790-8_1,Recent Trends in Artificial Intelligence Towards a Smart World
A review of IoT-based smart energy solutions for photovoltaic systems,10.1007/s00202-025-03312-3,2025,t,x,X4,,Springer Link,,Challa Krishna RaoSarat Kumar SahooFranco Fernando Yanine,,https://link.springer.com/article/10.1007/s00202-025-03312-3,Electrical Engineering
The Horizon for AI in Our Society,10.1007/978-3-031-53747-9_9,2024,t,x,X4,,Springer Link,,Carlo Lipizzi,,https://link.springer.com/chapter/10.1007/978-3-031-53747-9_9,Societal Impacts of Artificial Intelligence and Machine Learning
Integrated bionic LiDAR for adaptive 4D machine vision,10.1038/s41467-025-66529-7,2025,a,x,X4,,Springer Link,,Ruixuan ChenYichen WuKe ZhangChuxin LiuWencan LiYikun ChenBitao ShenZhaoxi ChenHanke FengZhangfeng GeYan ZhouZihan TaoXuguang ZhangWeihan XuYimeng WangPengfei CaiDong PanHaowen ShuLinjie ZhouCheng WangXingjun Wang,,https://link.springer.com/article/10.1038/s41467-025-66529-7,Nature Communications
Target Detection in Infrared Image of Transmission Line Based on Faster-RCNN,10.1007/978-3-030-95408-6_21,2022,f,x,"X1,X2,X4","target detection, but no SNN, no uav detection",Springer Link,,Shifeng YanPeipei ChenShili LiangLei ZhangXiuping Li,,https://link.springer.com/chapter/10.1007/978-3-030-95408-6_21,Advanced Data Mining and Applications
"Landslide susceptibility assessment through bivariate models (weight of evidence and frequency ratio) in Pesanggaran, East Java, Indonesia",10.1186/s40677-025-00345-5,2025,t,x,X4,,Springer Link,,Syamsul BachriRajendra P. ShresthaSugeng UtayaSumarmi SumarmiMellinia PrastiwiNanda PutriA. Riyan HakikiTabita Hidiyah,,https://link.springer.com/article/10.1186/s40677-025-00345-5,Geoenvironmental Disasters
A modified vision transformer framework for image-based land cover segmentation in rural architectural design and planning,10.1038/s41598-025-19234-w,2025,t,x,X4,,Springer Link,,Sobia WassanAnas BilalAbdulkareem AlzahraniKhalid AlmohammadiMalek AlrashidiSeyed Jalaleddin Mousavirad,,https://link.springer.com/article/10.1038/s41598-025-19234-w,Scientific Reports
Multilevel Inter-modal and Intra-modal Transformer network with domain adversarial learning for multimodal sleep staging,10.1007/s11571-025-10262-w,2025,a,x,X4,,Springer Link,,Yang-yang HeJian-wei Liu,,https://link.springer.com/article/10.1007/s11571-025-10262-w,Cognitive Neurodynamics
Deferred Synchronous Communication in&#xa0;a&#xa0;Myo-to-Gesture Device,10.1007/978-3-031-85363-0_27,2025,a,x,X4,,Springer Link,,Uwe M. BorghoffKlaus Buchenrieder,,https://link.springer.com/chapter/10.1007/978-3-031-85363-0_27,Advances in Information and Communication
Triboelectric Nanogenerator for Tactile Sensing and AI,10.1007/978-3-031-05722-9_43-1,2023,a,x,X4,,Springer Link,Count: 2 | Sources: Springer Link,Shujia XuWenzhuo Wu,,https://link.springer.com/rwe/10.1007/978-3-031-05722-9_43-1,Handbook of Triboelectric Nanogenerators
"Vapor-Phase Deposited Polymer Dielectric Layers for Organic Electronics: Design, Characteristics, and Applications",10.1007/s11814-024-00210-5,2024,t,x,X4,,Springer Link,,Sukwon JangYouson KimChungryeol LeeTaehyun NamJeongik ParkJunyeong YangJuchan KimBohyun LeeSung Gap Im,,https://link.springer.com/article/10.1007/s11814-024-00210-5,Korean Journal of Chemical Engineering
The AI-Driven Transition to Industry/Society 6.0,10.1007/978-3-032-03127-3_9,2025,t,x,X4,,Springer Link,,Elias G. CarayannisVasilii Erokhin,,https://link.springer.com/chapter/10.1007/978-3-032-03127-3_9,"Democracy, Environment, and Technology"
Optimal parameter identification of solid oxide fuel cell using modified fire Hawk algorithm,10.1038/s41598-024-72541-6,2024,t,x,X4,,Springer Link,,Rahul KhajuriaMahipal BukyaRavita LambaRajesh Kumar,,https://link.springer.com/article/10.1038/s41598-024-72541-6,Scientific Reports
The Use of&#xa0;Artificial Intelligence in&#xa0;a&#xa0;Myo-to-Gesture Device,10.1007/978-3-032-07986-2_7,2026,t,x,X4,,Springer Link,,Uwe M. BorghoffKlaus Buchenrieder,,https://link.springer.com/chapter/10.1007/978-3-032-07986-2_7,"Proceedings of the Future Technologies Conference (FTC) 2025, Volume 1"
A comprehensive review of machine learning applications for internet of nano things: challenges and future directions,10.1007/s10462-025-11211-z,2025,t,x,X4,,Springer Link,,Aryan RanaDeepika GautamPankaj KumarKranti KumarAthanasios V. VasilakosAshok Kumar DasVivekananda Bhat K,,https://link.springer.com/article/10.1007/s10462-025-11211-z,Artificial Intelligence Review
A Conceptual Model of Sensor System Ontology with an Event-Based Information Processing Method,10.1007/s11055-023-01360-5,2022,a,x,X4,,Springer Link,,E. O. Cherskikh,,https://link.springer.com/article/10.1007/s11055-023-01360-5,Neuroscience and Behavioral Physiology
UREPtrack: single-branch PoolFormer for unified attention-free RGB-event visual object tracking,10.1007/s00371-025-04309-6,2025,f,x,X1,drone view object detection,Springer Link,,Min Lu,,https://link.springer.com/article/10.1007/s00371-025-04309-6,The Visual Computer
Artificial intelligence in biology and medicine,10.1007/s00114-025-02029-4,2025,t,x,X4,,Springer Link,,Liliya IskuzhinaZafarkhuja TuraevArtem RozhinAleksei RomanovEkaterina SkomorokhovaIlnur IshmukhametovElvira Rozhina,,https://link.springer.com/article/10.1007/s00114-025-02029-4,The Science of Nature
A Performance of Low-Cost NVIDIA Jetson Nano Embedded System in the Real-Time Siamese Single Object Tracking: A Comparison Study,10.1007/978-3-031-10551-7_22,2022,f,x,X2,"SNN=siamese NN in this paper, no spiking reported;drone detection",Springer Link,,Abbas Aqeel KareemDalal Abdulmohsin HammoodAhmed A. AlchalabyRuaa Ali Khamees,,https://link.springer.com/chapter/10.1007/978-3-031-10551-7_22,"Computing Science, Communication and Security"
From pixels to camera: scaling superconducting nanowire single-photon detectors for imaging at the quantum-limit,10.1186/s40580-025-00515-z,2025,t,x,X4,,Springer Link,,Jun GaoJin ChangBruno Lopez-RodriguezIman Esmaeil ZadehVal ZwillerAli W. Elshaari,,https://link.springer.com/article/10.1186/s40580-025-00515-z,Nano Convergence
Spintronic memristors for computing,10.1038/s44306-025-00078-z,2025,t,x,X4,,Springer Link,,Qiming ShaoZhongrui WangYan ZhouShunsuke FukamiDamien QuerliozLeon O. Chua,,https://www.nature.com/articles/s44306-025-00078-z,npj Spintronics
The Double-Edged Sword: Conceptualising AI in the Context of Crime,10.1007/978-3-032-06944-3_2,2025,t,x,X4,,Springer Link,,Błażej Kaucz,,https://link.springer.com/chapter/10.1007/978-3-032-06944-3_2,Artificial Intelligence and Crime
Artificial Intelligence Technology,10.1007/978-3-031-27765-8_2,2023,t,x,X4,,Springer Link,,Kutub ThakurAl-Sakib Khan PathanSadia Ismat,,https://link.springer.com/chapter/10.1007/978-3-031-27765-8_2,Emerging ICT Technologies and Cybersecurity
FPT-spike: a flexible precise-time-dependent single-spike neuromorphic computing architecture,10.1007/s42514-020-00037-6,2020,f,x,X4,mnist classification,Springer Link,,Tao LiuGang QuanWujie Wen,,https://link.springer.com/article/10.1007/s42514-020-00037-6,CCF Transactions on High Performance Computing
Frontiers of AI Technologies,10.1007/978-981-96-9263-7_11,2025,a,x,X4,,Springer Link,,Mohan LiBinxing Fang,,https://link.springer.com/chapter/10.1007/978-981-96-9263-7_11,Artificial Intelligence Security and Safety
The environmental effects of the “twin” green and digital transition in European regions,10.1007/s10640-022-00741-7,2022,t,x,X4,,Springer Link,,Stefano BianchiniGiacomo DamioliClaudia Ghisetti,,https://link.springer.com/article/10.1007/s10640-022-00741-7,Environmental and Resource Economics
SOTVerse: A User-Defined Task Space of Single Object Tracking,10.1007/s11263-023-01908-5,2023,f,x,X2,"SNN=siamese NN in this paper, no spiking reported;drone detection",Springer Link,,Shiyu HuXin ZhaoKaiqi Huang,,https://link.springer.com/article/10.1007/s11263-023-01908-5,International Journal of Computer Vision
Influence of Contact Area on Memristive Characteristics of Parylene-Based Structures in Single and Crossbar Geometry,10.1134/S1063784224070430,2024,t,x,X4,,Springer Link,,B. S. ShvetsovG. A. IukliaevskikhK. Yu. ChernoglazovA. V. Emelyanov,,https://link.springer.com/article/10.1134/S1063784224070430,Technical Physics
Perfect linear optics using silicon photonics,10.1038/s41467-024-49768-y,2024,t,x,X4,,Springer Link,,Miltiadis Moralis-PegiosGeorge GiamougiannisApostolos TsakyridisDavid LazovskyNikos Pleros,,https://link.springer.com/article/10.1038/s41467-024-49768-y,Nature Communications
Guest Editorial: Special Issue on Design and Architectures for Signal and Image Processing 2021,10.1007/s11265-022-01789-w,2022,t,x,X4,,Springer Link,,Tomasz KryjakAndrea Pinna,,https://link.springer.com/article/10.1007/s11265-022-01789-w,Journal of Signal Processing Systems
Land use land cover classification of remote sensing images based on the deep learning approaches: a statistical analysis and review,10.1007/s12517-022-10246-8,2022,t,x,X4,,Springer Link,,Monia DigraRenu DhirNonita Sharma,,https://link.springer.com/article/10.1007/s12517-022-10246-8,Arabian Journal of Geosciences
Crop Yield Prediction and Climate Change Impact Assessment Using Machine Learning Technology in Agriculture,10.1007/978-981-19-9304-6_33,2023,t,x,X4,,Springer Link,,AnshulRandeep Singh,,https://link.springer.com/chapter/10.1007/978-981-19-9304-6_33,Information and Communication Technology for Competitive Strategies (ICTCS 2022)
Optimization of optical convolution kernel of optoelectronic hybrid convolution neural network,10.1007/s11801-022-1183-x,2022,t,x,X4,,Springer Link,,Xiaofeng XuLianqing ZhuWei ZhuangDongliang ZhangLidan LuPei Yuan,,https://link.springer.com/article/10.1007/s11801-022-1183-x,Optoelectronics Letters
"Advancements in arithmetic optimization algorithm: theoretical foundations, variants, and applications",10.1007/s11042-023-17084-0,2023,t,x,X4,,Springer Link,,Vijay Kumar,,https://link.springer.com/article/10.1007/s11042-023-17084-0,Multimedia Tools and Applications
Physical-Based Event Camera Simulator,10.1007/978-3-031-72995-9_2,2025,f,x,X4,,Springer Link,,Haiqian HanJiacheng LyuJianing LiHenglu WeiCheng LiYajing WeiShu ChenXiangyang Ji,,https://link.springer.com/chapter/10.1007/978-3-031-72995-9_2,Computer Vision – ECCV 2024
Contactless Fall Detection for the Elderly,10.1007/978-3-030-68590-4_8,2021,t,x,X4,,Springer Link,,M. Jaber Al NahianMehedi Hasan RajuZarin TasnimMufti MahmudMd Atiqur Rahman AhadM Shamim Kaiser,,https://link.springer.com/chapter/10.1007/978-3-030-68590-4_8,Contactless Human Activity Analysis
Fusing handcrafted and deep features for multi-class cardiac diagnostic decision support model based on heart sound signals,10.1007/s12652-023-04528-6,2023,t,x,X4,,Springer Link,,Mohammad JabariKhosro RezaeeManizhe Zakeri,,https://link.springer.com/article/10.1007/s12652-023-04528-6,Journal of Ambient Intelligence and Humanized Computing
"Aktuelle Herausforderungen, Grenzen und zukünftige Trends an der Schnittstelle von KI und DSV",10.1007/978-3-662-72296-1_7,2025,t,x,X4,,Springer Link,,Ulrich Karrenberg,,https://link.springer.com/chapter/10.1007/978-3-662-72296-1_7,Das unzertrennliche Duo: Digitale Signalverarbeitung und Künstliche Intelligenz
Triboelectric Nanogenerator for Human-Machine Interfacing,10.1007/978-3-031-28111-2_44,2023,t,x,X4,,Springer Link,Count: 2 | Sources: Springer Link,Zhiyi Wu,,https://link.springer.com/rwe/10.1007/978-3-031-28111-2_44,Handbook of Triboelectric Nanogenerators
Edge computing in big data: challenges and benefits,10.1007/s41060-025-00855-3,2025,t,x,X4,,Springer Link,,Amin KaramiMehdi Karami,,https://link.springer.com/article/10.1007/s41060-025-00855-3,International Journal of Data Science and Analytics
Social Structure to Artificial Implementation: Honeybees,10.1007/978-981-16-9113-3_21,2022,t,x,X4,,Springer Link,,Amit Singh,,https://link.springer.com/chapter/10.1007/978-981-16-9113-3_21,Congress on Intelligent Systems
"Data-Centric Computing Paradigm Shift, and Domain-Specific Architecture and Hardware",10.1007/978-3-031-34233-2_1,2024,t,x,X4,,Springer Link,,Yasmin HalawaniBaker Mohammad,,https://link.springer.com/chapter/10.1007/978-3-031-34233-2_1,In-Memory Computing Hardware Accelerators for Data-Intensive Applications
Next Generation Smart Agricultural Technologies and Precision Farming with Industry 6.0 Innovations,10.1007/978-3-032-07278-8_13,2026,t,x,X4,,Springer Link,,Hammad MajeedTehreema Iftikhar,,https://link.springer.com/chapter/10.1007/978-3-032-07278-8_13,Intelligent Manufacturing in Industry 6.0
Maize and soybean yield prediction using machine learning methods: a systematic literature review,10.1007/s44279-025-00215-6,2025,t,x,X4,,Springer Link,,Ramandeep Kumar SharmaJasleen KaurGary FengYanbo HuangChandan KumarYi WangSandhir SharmaJohnie JenkinsJagmandeep Dhillon,,https://link.springer.com/article/10.1007/s44279-025-00215-6,Discover Agriculture
Artificial Neural Networks and Support Vector Machine for IoT,10.1007/978-3-030-87059-1_3,2022,t,x,X4,,Springer Link,,Bhanu Chander,,https://link.springer.com/chapter/10.1007/978-3-030-87059-1_3,Artificial Intelligence-based Internet of Things Systems
Harnessing optical forces with advanced nanophotonic structures: principles and applications,10.1186/s11671-025-04252-4,2025,t,x,X4,,Springer Link,,Geze GaoTianhua ShaoTianyue LiShuming Wang,,https://link.springer.com/article/10.1186/s11671-025-04252-4,Discover Nano
Outlook,10.1007/978-981-99-3228-3_4,2023,t,x,X3,outlook of a lecture series,Springer Link,,Nanning Zheng,,https://link.springer.com/chapter/10.1007/978-981-99-3228-3_4,Cognitive Computing of Visual and Auditory Information
Applications of Artificial Intelligence for Fault Diagnosis of Rotating Machines: A Review,10.1007/978-3-031-28725-1_4,2023,t,x,X4,,Springer Link,,Fasikaw KibreteDereje Engida Woldemichael,,https://link.springer.com/chapter/10.1007/978-3-031-28725-1_4,Artificial Intelligence and Digitalization for Sustainable Development
AutoDrone: Shortest Optimized Obstacle-Free Path Planning for Autonomous Drones,10.1007/978-981-19-1657-1_1,2022,t,x,X1,,Springer Link,,Prithwish JanaDebasish Jana,,https://link.springer.com/chapter/10.1007/978-981-19-1657-1_1,"Proceedings of International Conference on Computational Intelligence, Data Science and Cloud Computing"
Special kinetics features of scandium antimonide thin films conducive to swiftly embedded phase-change memory applications,10.1007/s40843-024-3086-6,2024,t,x,X4,,Springer Link,,Xue-Peng WangBin ChenHuang GongXinxin DuanYimin ChenFeng Rao,,https://link.springer.com/article/10.1007/s40843-024-3086-6,Science China Materials
Case Study B: AI Agents for the Tactical Edge,10.1007/978-3-031-29269-9_20,2023,t,x,X4,,Springer Link,,Pierre TrepagnierAllan Wollaber,,https://link.springer.com/chapter/10.1007/978-3-031-29269-9_20,Autonomous Intelligent Cyber Defense Agent (AICA)
Robust visual tracking using very deep generative model,10.1186/s40537-022-00682-4,2023,f,x,"X1,X4",drone view object detection w.o. uav→uav,Springer Link,,Eman R. AlBasiounyAbdel-Fattah AttiaHossam E. AbdelmunimHazem M. Abbas,,https://link.springer.com/article/10.1186/s40537-022-00682-4,Journal of Big Data
EMAPS: An Intelligent Agent-Based Technology for Simulation of Multiscale Systems,10.1007/978-3-031-11870-8_13,2023,t,x,X4,,Springer Link,,Yuri OmelchenkoHoma Karimabadi,,https://link.springer.com/chapter/10.1007/978-3-031-11870-8_13,Space and Astrophysical Plasma Simulation
Two-Legged Robot Motion Control With Recurrent Neural Networks,10.1007/s10846-021-01553-5,2022,t,x,X4,,Springer Link,,Bahadır ÇatalbaşÖmer Morgül,,https://link.springer.com/article/10.1007/s10846-021-01553-5,Journal of Intelligent & Robotic Systems
A Survey on Crop Rotation Using Machine Learning and IoT,10.1007/978-981-19-3575-6_7,2023,t,x,X4,,Springer Link,,Nidhi PatelAshna ShahYashvi SoniNikita SolankiManojkumar Shahu,,https://link.springer.com/chapter/10.1007/978-981-19-3575-6_7,IOT with Smart Systems
Advancing the cybersecurity of the healthcare system with self-optimising and self-adaptative artificial intelligence (part 2),10.1007/s12553-022-00691-6,2022,t,x,X4,,Springer Link,,Petar RadanlievDavid De Roure,,https://link.springer.com/article/10.1007/s12553-022-00691-6,Health and Technology
Nanostructured Systems and the Value of Biological Engineering,10.1007/978-3-031-90594-0_2,2025,t,x,X4,,Springer Link,,Donald MartinIsabelle Vilgrain,,https://link.springer.com/chapter/10.1007/978-3-031-90594-0_2,Biomimetic Membrane Technology
Deep Learning: Applications in Seismology and Volcanology,10.1007/978-3-031-15432-4_5,2023,t,x,X4,,Springer Link,,Alireza HajianGiuseppe NunnariRoohollah Kimiaefar,,https://link.springer.com/chapter/10.1007/978-3-031-15432-4_5,Intelligent Methods with Applications in Volcanology and Seismology
"Diagnosis and Compensation of Control Program, Sensor and Actuator Failures in Nonlinear Systems Using Hierarchical State Space Checks",10.1007/s10836-020-05914-0,2020,t,x,X4,,Springer Link,,Md Imran MomtazAbhijit Chatterjee,,https://link.springer.com/article/10.1007/s10836-020-05914-0,Journal of Electronic Testing
Leveraging Deep Learning Techniques on Remotely Sensing Agriculture Data,10.1007/978-981-16-1089-9_74,2021,t,x,X4,,Springer Link,,Ajaysinh Vikramsinh KathiyaJai Prakash VermaSanjay Garg,,https://link.springer.com/chapter/10.1007/978-981-16-1089-9_74,Communication and Intelligent Systems
Understanding the impact of IoT security patterns on CPU usage and energy consumption: a dynamic approach for selecting patterns with deep reinforcement learning,10.1007/s10207-025-01011-5,2025,t,x,X4,,Springer Link,,Saeid JamshidiAmin NikanjamKawser Wazed NafiFoutse Khomh,,https://link.springer.com/article/10.1007/s10207-025-01011-5,International Journal of Information Security
Benchmarks for progress in neuromorphic computing,10.1038/s42256-019-0097-1,2019,t,x,X4,,Springer Link,,Mike Davies,,https://link.springer.com/article/10.1038/s42256-019-0097-1,Nature Machine Intelligence
Enhancing decision-making with linear diophantine multi-fuzzy set: application of novel information measures in medical and engineering fields,10.1038/s41598-024-79725-0,2024,t,x,X4,,Springer Link,,Jeevitha KannanVimala JayakumarNasreen KausarDragan PamucarVladimir Simic,,https://link.springer.com/article/10.1038/s41598-024-79725-0,Scientific Reports
Unifying graph neural networks causal machine learning and conformal prediction for robust causal inference in rail transport systems,10.1038/s41598-025-26478-z,2025,t,x,X4,,Springer Link,,Mehmet Taciddin Akçay,,https://link.springer.com/article/10.1038/s41598-025-26478-z,Scientific Reports
All Things will be Dominated/Controlled by Humans’ Imaginations in the Next Generation of Internet of Brains,10.1007/s11277-024-11053-y,2024,t,x,X4,,Springer Link,,Saeed Banaeian FarAzadeh Imani Rad,,https://link.springer.com/article/10.1007/s11277-024-11053-y,Wireless Personal Communications
Federated Learning for Resource-Constrained IoT Devices: Panoramas and State of the Art,10.1007/978-3-031-11748-0_2,2023,t,x,X4,,Springer Link,,Ahmed ImteajKhandaker Mamun AhmedUrmish ThakkerShiqiang WangJian LiM. Hadi Amini,,https://link.springer.com/chapter/10.1007/978-3-031-11748-0_2,Federated and Transfer Learning
A Universal Event-Based Plug-In Module for Visual Object Tracking in Degraded Conditions,10.1007/s11263-023-01959-8,2023,f,x,X4,drone view object detection w.o. uav→uav,Springer Link,,Jiqing ZhangBo DongYingkai FuYuanchen WangXiaopeng WeiBaocai YinXin Yang,,https://link.springer.com/article/10.1007/s11263-023-01959-8,International Journal of Computer Vision
Biodegradable electronic materials for promoting sustainability in next-generation electronics - a comprehensive review,10.1007/s43939-025-00381-w,2025,t,x,X4,,Springer Link,,Milon Selvam DennisonKirubanidhi Jebabalan. SAravind SamrajOmar Suliman ZaroogTitus WanazusiAbisha Meji M.N. Rajamani,,https://link.springer.com/article/10.1007/s43939-025-00381-w,Discover Materials
Applications of MXenes in human-like sensors and actuators,10.1007/s12274-022-5272-8,2022,t,x,X4,,Springer Link,,Jinbo PangSongang PengChongyang HouXiao WangTing WangYu CaoWeijia ZhouDing SunKai WangMark H. RümmeliGianaurelio CunibertiHong Liu,,https://link.springer.com/article/10.1007/s12274-022-5272-8,Nano Research
Geoobjects and Reference Systems,10.1007/978-3-662-65758-4_4,2023,t,x,X4,,Springer Link,,Norbert de Lange,,https://link.springer.com/chapter/10.1007/978-3-662-65758-4_4,Geoinformatics in Theory and Practice
Thermal Object Detection Using Yolov3 and Spatial Pyramid Pooling,10.1007/978-981-33-4087-9_46,2021,a,x,X4,FLIR dataset has no UAV thermal object detection,Springer Link,,Sachin KumarDeepak Gaur,,https://link.springer.com/chapter/10.1007/978-981-33-4087-9_46,Proceedings of International Conference on Machine Intelligence and Data Science Applications
Artificial Intelligence and International Security,10.1007/978-3-030-74420-5_11,2021,t,x,X4,,Springer Link,,Nitin AgarwalaRana Divyank Chaudhary,,https://link.springer.com/chapter/10.1007/978-3-030-74420-5_11,Towards an International Political Economy of Artificial Intelligence
Rapid thin-layer WS<sub>2</sub> detection based on monochromatic illumination photographs,10.1007/s12274-020-3122-0,2020,t,x,X4,,Springer Link,,Xiangmin HuCuicui QiuDameng Liu,,https://link.springer.com/article/10.1007/s12274-020-3122-0,Nano Research
A hybrid flexible gas sensory system with perceptual learning,10.1007/s12274-021-3496-7,2021,t,x,X4,,Springer Link,,Qifeng LuFuqin SunYanbing DaiYingyi WangLin LiuZihao WangShuqi WangTing Zhang,,https://link.springer.com/article/10.1007/s12274-021-3496-7,Nano Research
Towards silicon photonic neural networks for artificial intelligence,10.1007/s11432-020-2872-3,2020,t,x,X4,,Springer Link,,Bowen BaiHaowen ShuXingjun WangWeiwen Zou,,https://link.springer.com/article/10.1007/s11432-020-2872-3,Science China Information Sciences
Future Technology and Research Trends in Automotive Sensing,10.1007/978-3-031-06780-8_6,2023,t,x,X4,,Springer Link,,Paul SchmalenbergJae S. LeeSean P. RodriguesDanil Prokhorov,,https://link.springer.com/chapter/10.1007/978-3-031-06780-8_6,AI-enabled Technologies for Autonomous and Connected Vehicles
A dynamic image encryption scheme using a memristive quantum-inspired chaotic system and Golden Jackal optimization,10.1007/s13198-025-03102-x,2025,t,x,X4,,Springer Link,,B. Sakthi KumarR. Revathi,,https://link.springer.com/article/10.1007/s13198-025-03102-x,International Journal of System Assurance Engineering and Management
AI Makes Crypto Evolve,10.1007/978-3-031-44807-2_3,2023,t,x,X4,,Springer Link,,Behrouz ZolfaghariHamid NematiNaoto YanaiKhodakhast Bibak,,https://link.springer.com/chapter/10.1007/978-3-031-44807-2_3,Crypto and AI
Chaos and firing patterns in a discrete fractional Hopfield neural network model,10.1007/s11071-023-08972-z,2023,t,x,X4,,Springer Link,,Shaobo HeD. VigneshLamberto RondoniSanto Banerjee,,https://link.springer.com/article/10.1007/s11071-023-08972-z,Nonlinear Dynamics
Identification of genomic enhancers through spatial integration of single‐cell transcriptomics and epigenomics,10.15252/msb.20209438,2020,t,x,X4,,Springer Link,,Carmen Bravo González‐BlasXiao‐Jiang QuanRamon Duran‐RomañaIbrahim Ihsan TaskiranDuygu KoldereKristofer DavieValerie ChristiaensSamira MakhzamiGert HulselmansMaxime de WaegeneerDavid MauduitSuresh PoovathingalSara AibarStein Aerts,,https://link.springer.com/article/10.15252/msb.20209438,Molecular Systems Biology
AI Governance for a Prosperous Future,10.1007/978-3-031-09245-9_3,2023,t,x,X4,,Springer Link,,Alexander Vocelka,,https://link.springer.com/chapter/10.1007/978-3-031-09245-9_3,Responsible Artificial Intelligence
Implementation of Memristor Towards Better Hardware/Software Security Design,10.1007/s42341-020-00269-x,2021,t,x,X4,,Springer Link,,Jeetendra Singh,,https://link.springer.com/article/10.1007/s42341-020-00269-x,Transactions on Electrical and Electronic Materials
Emerging Internet of Things driven carbon nanotubes-based devices,10.1007/s12274-021-3986-7,2022,t,x,X4,,Springer Link,,Shu ZhangJinbo PangYufen LiFeng YangThomas GemmingKai WangXiao WangSongang PengXiaoyan LiuBin ChangHong LiuWeijia ZhouGianaurelio CunibertiMark H. Rümmeli,,https://link.springer.com/article/10.1007/s12274-021-3986-7,Nano Research
PCA-RECT: An Energy-Efficient Object Detection Approach for Event Cameras,10.1007/978-3-030-21074-8_35,2019,f,x,X4,"Mnist, n-caltech dataset, no uav detection",Springer Link,,Bharath RameshAndrés UssaLuca Della VedovaHong YangGarrick Orchard,,https://link.springer.com/chapter/10.1007/978-3-030-21074-8_35,Computer Vision – ACCV 2018 Workshops
The business of building brains,10.1038/s41928-020-0449-1,2020,t,x,X4,,Springer Link,,Sunny Bains,,https://link.springer.com/article/10.1038/s41928-020-0449-1,Nature Electronics
"Vision, application scenarios, and key technology trends for 6G mobile communications",10.1007/s11432-021-3351-5,2022,t,x,X4,,Springer Link,,Zhiqin WangYing DuKejun WeiKaifeng HanXiaoyan XuGuiming WeiWen TongPeiying ZhuJianglei MaJun WangGuangjian WangXueqiang YanJiying XiangHe HuangRuyue LiXinhui WangYingmin WangShaohui SunShiqiang SuoQiubin GaoXin Su,,https://link.springer.com/article/10.1007/s11432-021-3351-5,Science China Information Sciences
Additive neural network for forest fire detection,10.1007/s11760-019-01600-7,2019,t,x,X4,,Springer Link,,Hongyi PanDiaa BadawiXi ZhangAhmet Enis Cetin,,https://link.springer.com/article/10.1007/s11760-019-01600-7,"Signal, Image and Video Processing"
A comparative analysis of localization algorithms for visible light communication,10.1007/s11082-021-02751-z,2021,t,x,X4,,Springer Link,,Mohamed A. DawoodSally S. SalehEl-Sayed A. El-BadawyMoustafa H. Aly,,https://link.springer.com/article/10.1007/s11082-021-02751-z,Optical and Quantum Electronics
Sensing the future of bio-informational engineering,10.1038/s41467-020-20764-2,2021,t,x,X4,,Springer Link,,Thomas A. DixonThomas C. WilliamsIsak S. Pretorius,,https://link.springer.com/article/10.1038/s41467-020-20764-2,Nature Communications
"6G CloudNet: Towards a Distributed, Autonomous, and Federated AI-Enabled Cloud and Edge Computing",10.1007/978-3-030-72777-2_13,2021,t,x,X4,,Springer Link,,Isiaka A. AlimiRomil K. PatelAziza ZaougaNelson J. MugaArmando N. PintoAntónio L. TeixeiraPaulo P. Monteiro,,https://link.springer.com/chapter/10.1007/978-3-030-72777-2_13,6G Mobile Wireless Networks
Characteristics of Changes in Karst Rocky Desertification in Southtern and Western China and Driving Mechanisms,10.1007/s11769-021-1243-3,2021,t,x,X4,,Springer Link,,Guoshuang ChongYue HaiHua ZhengWeihua XuZhiyun Ouyang,,https://link.springer.com/article/10.1007/s11769-021-1243-3,Chinese Geographical Science
"Comprehensive review of MAX phase and MXene materials: synthesis, properties, and applications",10.1007/s42823-025-00979-3,2025,t,x,X4,,Springer Link,,C. B. SubbaD. P. RaiMukhriddin E. TursunovAvazbek T. DekhkonovZ. Pachuau,,https://link.springer.com/article/10.1007/s42823-025-00979-3,Carbon Letters
The Future of AI or AI for the Future,10.1007/978-3-030-64246-4_3,2020,t,x,X4,,Springer Link,,Eunika Mercier-Laurent,,https://link.springer.com/chapter/10.1007/978-3-030-64246-4_3,Unimagined Futures – ICT Opportunities and Challenges
Technology-Led Disruptions and Innovations: The Trends Transforming Urban Mobility,10.1007/978-3-030-69698-6_51,2021,t,x,X4,,Springer Link,Count: 2 | Sources: Springer Link,Hussein DiaSaeed BagloeeHadi Ghaderi,,https://link.springer.com/rwe/10.1007/978-3-030-69698-6_51,Handbook of Smart Cities
Global phylogeography of a pantropical mangrove genus <i>Rhizophora</i>,10.1038/s41598-021-85844-9,2021,t,x,X4,,Springer Link,,Koji TakayamaYoichi TateishiTadashi Kajita,,https://link.springer.com/article/10.1038/s41598-021-85844-9,Scientific Reports
Continuous Network Information Technology Development,10.1007/978-981-15-4043-1_2,2020,t,x,X4,,Springer Link,,Chinese Academy of Cyberspace Studies,,https://link.springer.com/chapter/10.1007/978-981-15-4043-1_2,China Internet Development Report 2018
Modelling <i>Drosophila</i> motion vision pathways for decoding the direction of translating objects against cluttered moving backgrounds,10.1007/s00422-020-00841-x,2020,f,x,X4,,Springer Link,,Qinbing FuShigang Yue,,https://link.springer.com/article/10.1007/s00422-020-00841-x,Biological Cybernetics
Hybrid Intelligent Networks,10.1007/978-3-030-02161-0_1,2019,t,x,X4,,Springer Link,,Zhi-Hong GuanBin HuXuemin (Sherman) Shen,,https://link.springer.com/chapter/10.1007/978-3-030-02161-0_1,Introduction to Hybrid Intelligent Networks
Potential key technologies for 6G mobile communications,10.1007/s11432-019-2789-y,2020,t,x,X4,,Springer Link,,Yifei YuanYajun ZhaoBaiqing ZongSergio Parolari,,https://link.springer.com/article/10.1007/s11432-019-2789-y,Science China Information Sciences
Digital Earth Challenges and Future Trends,10.1007/978-981-32-9915-3_26,2020,t,x,X4,,Springer Link,,John van GenderenMichael F. GoodchildHuadong GuoChaowei YangStefano NativiLizhe WangCuizhen Wang,,https://link.springer.com/chapter/10.1007/978-981-32-9915-3_26,Manual of Digital Earth
Embedded Vision Systems: A Review of&#xa0;the Literature,10.1007/978-3-319-78890-6_17,2018,a,x,X4,,Springer Link,,Deepayan BhowmikKofi Appiah,,https://link.springer.com/chapter/10.1007/978-3-319-78890-6_17,"Applied Reconfigurable Computing. Architectures, Tools, and Applications"
Naturelike Technologies: New Opportunities and New Challenges,10.1134/S1019331619020102,2019,t,x,X4,,Springer Link,,M. V. Koval’chukO. S. NaraikinE. B. Yatsishina,,https://link.springer.com/article/10.1134/S1019331619020102,Herald of the Russian Academy of Sciences
The Colony Predation Algorithm,10.1007/s42235-021-0050-y,2021,t,x,X4,,Springer Link,,Jiaze TuHuiling ChenMingjing WangAmir H. Gandomi,,https://link.springer.com/article/10.1007/s42235-021-0050-y,Journal of Bionic Engineering
Neue Möglichkeiten für die Servicerobotik durch KI,10.1007/978-3-662-58042-4_7,2019,t,x,X4,,Springer Link,,Steffen WischmannMarieke Rohde,,https://link.springer.com/chapter/10.1007/978-3-662-58042-4_7,Künstliche Intelligenz
27th Annual Computational Neuroscience Meeting (CNS*2018): Part One,10.1186/s12868-018-0452-x,2018,f,x,X4,"in no section something about „drone“ or uav,",Springer Link,,,,https://link.springer.com/article/10.1186/s12868-018-0452-x,BMC Neuroscience
Polylateral Diplomacy: Diplomacy as Public–Private Collaboration,10.1007/978-3-030-00530-6_5,2019,t,x,X4,,Springer Link,,Yolanda Kemp Spies,,https://link.springer.com/chapter/10.1007/978-3-030-00530-6_5,Global South Perspectives on Diplomacy
"Image Based Techniques for Crack Detection, Classification and Quantification in Asphalt Pavement: A Review",10.1007/s11831-016-9194-z,2016,t,x,X4,,Springer Link,,H. ZakeriFereidoon Moghadas NejadAhmad Fahimifar,,https://link.springer.com/article/10.1007/s11831-016-9194-z,Archives of Computational Methods in Engineering
A neural network model for familiarity and context learning during honeybee foraging flights,10.1007/s00422-017-0732-z,2017,t,x,X4,,Springer Link,,Jurek MüllerMartin NawrotRandolf MenzelTim Landgraf,,https://link.springer.com/article/10.1007/s00422-017-0732-z,Biological Cybernetics
A scheme of GA acceleration based on domain generic IC,10.1007/s10586-018-2088-0,2018,t,x,X4,,Springer Link,,Mo ZhangYunzhou ZhangGang XieGang Zhang,,https://link.springer.com/article/10.1007/s10586-018-2088-0,Cluster Computing
Wide-Baseline Image Matching with Projective View Synthesis and Calibrated Geometric Verification,10.1007/s41064-017-0012-5,2017,t,x,X4,,Springer Link,,Lukas RothAndreas KuhnHelmut Mayer,,https://link.springer.com/article/10.1007/s41064-017-0012-5,"PFG – Journal of Photogrammetry, Remote Sensing and Geoinformation Science"
A survey of neural network accelerators,10.1007/s11704-016-6159-1,2017,t,x,X4,,Springer Link,,Zhen LiYuqing WangTian ZhiTianshi Chen,,https://link.springer.com/article/10.1007/s11704-016-6159-1,Frontiers of Computer Science
"Leadership, Growth, and the Future",10.1007/978-3-030-02348-5_5,2019,t,x,X4,,Springer Link,,Andrea TaylorFelix SantiagoJosephine HauerRilla HynesBethany K. Mickahail,,https://link.springer.com/chapter/10.1007/978-3-030-02348-5_5,Effective and Creative Leadership in Diverse Workforces
Online Multi-object Tracking-by-Clustering for Intelligent Transportation System with Neuromorphic Vision Sensor,10.1007/978-3-319-67190-1_11,2017,t,x,X4,,Springer Link,,Gereon HinzGuang ChenMuhammad AafaqueFlorian RöhrbeinJörg ConradtZhenshan BingZhongnan QuWalter StecheleAlois Knoll,,https://link.springer.com/chapter/10.1007/978-3-319-67190-1_11,KI 2017: Advances in Artificial Intelligence
Frontiers in Best Matching,10.1007/978-3-319-46070-3_8,2017,t,x,X4,,Springer Link,,Mohsen MoghaddamShimon Y. Nof,,https://link.springer.com/chapter/10.1007/978-3-319-46070-3_8,Best Matching Theory & Applications
26th Annual Computational Neuroscience Meeting (CNS*2017): Part 3,10.1186/s12868-017-0372-1,2017,t,x,X4,,Springer Link,,Adam J. H. NewtonAlexandra H. SeidensteinRobert A. McDougalAlberto Pérez-CerveraGemma HuguetTere M-SearaCaroline HaimerlDavid Angulo-GarciaAlessandro TorciniRosa CossartArnaud MalvacheKaoutar SkikerMounir MaoueneGianmarco RagognettiLetizia LorussoAndrea ViggianoAngelo MarcelliRosa SenatoreAntonio ParzialeS. StramagliaM. PellicoroL. AngeliniE. AmicoH. AertsJ. CortésS. LaureysD. MarinazzoS. StramagliaI. BassezL. FaesHannes AlmgrenAdeel RaziFrederik Van de SteenRuth KrebsHannelore AertsLida KanariPawel DlotkoMartina ScolamieroRan LeviJulian ShillcockChristiaan P.J. de KockKathryn HessHenry MarkramCheng LyGary MarsatTom GillespieMalin SandströmMathew AbramsJeffrey S. GretheMaryann MartoneRobin De GernierSergio SolinasChristian RössertMarc HaeltermanSerge MassarValentina PasqualeVito Paolo PastoreSergio MartinoiaPaolo MassobrioCristiano CaponeNúria Tort-ColetMaria V. Sanchez-VivesMaurizio MattiaAli AlmasiShaun L. ClohertyDavid B. GraydenYan T. WongMichael R. IbbotsonHamish MeffinLuke Y. PrinceKrasimira Tsaneva-AtanasovaJack R. MellorAlberto MazzoniManuela RosaJacopo CarpanetoLuigi M. RomitoAlberto PrioriSilvestro MiceraRosanna MiglioreCarmen Alina LupascuFrancesco FranchinaLuca Leonardo BolognaArmando RomaniSára SarayWerner Van GeitSzabolcs KáliAlex ThomsonAudrey MercerSigrun LangeJoanne FalckEilif MullerFelix SchürmannDmitrii TodorovRobert CappsWilliam BarnettYaroslav MolkovFederico DevalleDiego PazóErnest MontbrióGabriela MocholHabiba AzabBenjamin Y. HaydenRubén Moreno-BotePragathi Priyadharsini BalasubramaniSrinivasa V. ChakravarthyVignayanandam R. MuddapuMedorian D. GheorghiuBartul MimicaJonathan WithlockRaul C. MureșanJennifer L. ZickKelsey SchultzRachael K. BlackmanMatthew V. ChafeeTheoden I. NetoffNicholas RobertsVivek NagarajAndrew LamperskiTheoden I. NetoffLogan L. GradoMatthew D. JohnsonDavid P. DarrowDavide LonardoniHayder AminStefano Di MarcoAlessandro MaccioneLuca BerdondiniThierry NieusMarcel StimbergDan F. M. GoodmanThomas NowotnyVeronika KorenValentin DragoiKlaus ObermayerSamy CastroMariano FernandezWael El-DeredyKesheng XuJean Paul MaidanaPatricio OrioWeiliang ChenIain HepburnFrancesco CasalegnoAdrien DevresseAleksandr OvcharenkoFernando PereiraFabien DelalondreErik De SchutterPeter BratbyAndrew R. GallimoreGuido KlingbeilCriseida ZamoraYunliang ZangPatrick CrottyEric PalmerducaAlberto AntoniettiClaudia CasellatoCsaba EröEgidio D’AngeloMarc-Oliver GewaltigAlessandra PedrocchiIlja BytschokDominik DoldJohannes SchemmelKarlheinz MeierMihai A. PetroviciHui-An ShenSimone Carlo SuraceJean-Pascal PfisterBaptiste LefebvreOlivier MarrePierre YgerAthanasia PapoutsiJiyoung ParkRyan AshStelios SmirnakisPanayiota PoiraziRichard A. FelixAlexander G. DimitrovChristine PortforsSilvia DaunTibor I. TothJoanna Jędrzejewska-SzmekNadine KabbaniKim T. BlackwelBahar MoezziNatalie SchaworonkowLukas PlogmacherMitchell R. GoldsworthyBrenton HordacreMark D. McDonnellNicolangelo IannellaMichael C. RiddingJochen TrieschReinoud MaexKaren SafaryanVolker SteuberRongxiang TangYi-Yuan TangDarya V. VerveykoAlexey R. BrazheAndrey Yu VerisokinDmitry E. PostnovCengiz GünayGabriella PanuccioMichele GiuglianoAstrid A. PrinzPablo VaronaMikhail I. RabinovichJack DenhamThomas RannerNetta CohenMaria RevaNelson RebolaTekla KirizsZoltan NusserDavid DiGregorioEirini MavritsakiPanos RentzelasNikul H. UkaniAdam TomkinsChung-Heng YehWesley BruningAllison L. FenichelYiyin ZhouYu-Chi HuangDorian FlorescuCarlos Luna OrtizPaul RichmondChung-Chuan LoDaniel CocaAnn-Shyn ChiangAurel A. LazarBahar MoezziJennifer L. CreaserCongping LinPeter AshwinJonathan T. BrownThomas RidlerDaniel LevensteinBrendon O. WatsonGyörgy BuzsákiJohn RinzelRodica CurtuAnh NguyenSahand AssadzadehPeter A. RobinsonPaula Sanz-LeonCaroline G. ForlimLírio O. B. de AlmeidaReynaldo D. PintoFrancisco B. RodríguezÁngel LareoCaroline Garcia ForlimFrancisco B. RodríguezAaron MonteroThiago MosqueiroRamon HuertaFrancisco B. RodriguezVinicio ChangoluisaFrancisco B. RodriguezVinícius L. CordeiroCésar C. CeballosNilton L. KamijiAntonio C. RoqueWilliam W. LyttonAndrew KnoxJoshua J. C. RosenthalSilvia DaunSvitlana PopovychLiqing LiuBin A. WangTibor I. TóthChristian GrefkesGereon R. FinkNils RosjatAbraham Perez-TrujilloAndres EspinalMarco A. Sotelo-FigueroaIvan Cruz-AcevesHoracio Rostro-GonzalezMartin ZapotockyMartina HoskovcováJana KopeckáOlga UlmanováEvžen RůžičkaMatthias GärtnerSevil DuvarciJochen RoeperGaby SchneiderStefan AlbertKatharina SchmackMichiel RemmeSusanne SchreiberMichele MiglioreCarmen A. LupascuLuca L. BolognaStefano M. AntonelJean-Denis CourcolFelix SchürmannSami Utku ÇelikokEva M. Navarro-LópezNeslihan Serap ŞengörRahmi ElibolNeslihan Serap SengorMustafa Yasir ÖzdemirTianyi LiAngelo ArleoDenis SheynikhovichAkihiro NakamuraMasanori ShimonoYoungjo SongSol ParkIlhwan ChoiJaeseung JeongHee-sup ShinSadra SadehPadraig GleesonR. Angus SilverAlexandra Pierri ChatzikalymniouFrances K. SkinnerLazaro M. Sanchez-RodriguezRoberto C. SoteroLoreen HertägOwen MackwoodHenning SprekelerSteffen PuhlmannSimon N. WeberDavid HigginsLaura B. NaumannSimon N. WeberRamakrisnan IyerStefan MihalasValentina TiccinelliTomislav StankovskiPeter V. E. McClintockAneta StefanovskaPredrag JanjićDimitar SolevGerald SeifertLjupčo KocarevChristian SteinhäuserMehrdad SalmasiStefan GlasauerMartin StemmlerDanke ZhangChi ZhangArmen StepanyantsJulia GoncharenkoLieke KrosNeil DaveyChris de ZeeuwFreek HoebeekAnkur SinhaRoderick AdamsMichael SchmukerMaria PsarrouMaria SchilstraBenjamin Torben-NielsenChristoph MetznerAchim SchweikardTuomo Mäki-MarttunenBartosz ZurowskiDaniele MarinazzoLuca FaesSebastiano StramagliaHenry O. C. JordanSimon M. StringerElżbieta Gajewska-DendekPiotr SuffczyńskiNicoladie TamGeorge ZouridakisLuca PolloniniYi-Yuan TangMojtaba Madadi AslAlireza ValizadehPeter A. TassAndreas NoldWei FanSara KonradHeiko EndleJohannes VogtTatjana TchumatchenkoJuliane HerpichChristian TetzlaffJannik LuboeinskiTimo NachstedtManuel CibaAndreas BahmerChristiane ThielemannEric S. KueblerJoseph S. TauskelaJean-Philippe ThiviergeRembrandt BakkerMaría García-AmadoMarian EvangelioFrancisco ClascáPaul TiesingaChristopher L. BuckleyTaro ToyoizumiAlexis M. DubreuilRémi MonassonAlessandro TrevesDavide SpallaSophie RosayFlorence I. KlebergWilly WongBruno de Oliveira FlorianoToshihiko MatsuoTetsuya UchidaDomenica DibenedettoKâmil UludağAbdorreza GoodarzinickMaximilian SchmidtClaus C. HilgetagMarkus DiesmannSacha J. van AlbadaMichael FauthMark van RossumManuel Reyes-SánchezRodrigo AmaducciCarlos MuñizPablo VaronaIrene ElicesDavid ArroyoRafael LeviBen CohenCarson ChowShashaank VattikutiElena BertolottiRaffaella BurioniMatteo di VoloAlessandro VezzaniBayar MenzatTim P. VogelsNobuhiko WagatsumaSusmita SahaReena KapoorRobert KerrJohn WagnerLuis C. Garcia del MolinoGuangyu Robert YangJorge F. MejiasXiao-Jing WangHanbing SongJoseph GoodliffeJennifer LuebkeChristina M. WeaverJohn ThomasNishant SinhaNikhita ShajuTomasz MaszczykJing JinSydney S. CashJustin DauwelsM. Brandon WestoverMaryam KarimianMichelle MoerelPeter De WeerdThomas BurwickRonald L. WestraRomesh AbeysuriyaJonathan HadidaStamatios SotiropoulosSaad JbabdiMark WoolrichChama BensmailBorys WrobelXiaolong ZhouZilong JiXiao LiuYan XiaSi WuXiao WangMingsha ZhangSi WuNetanel OferOrit ShefiGur YaariTed CarnevaleAmit MajumdarSubhashini SivagnanamKenneth YoshimotoElena Y. SmirnovaDmitry V. AmakhinSergey L. MalkinAleksey V. ZaitsevAnton V. ChizhovMargarita ZaleshinaAlexander ZaleshinVictor J. BarrancaGeorge ZhuQuinton M. SkillingDaniel MaruyamaNicolette OgnjanovskiSara J. AtonMichal ZochowskiJiaxing WuSara AtonScott RichVictoria BoothMaral BudakSalvador Dura-BernalSamuel A. NeymotinBenjamin A. SuterGordon M. G. ShepherdMelvin A. Felton Jr.Alfred B. YuDavid L. BootheKelvin S. OiePiotr J. FranaszczukSergey A. ShuvaevBatuhan BaşerdemAnthony ZadorAlexei A. KoulakovVíctor J. López-MadronaErnesto PeredaClaudio R. MirassoSantiago CanalsStefano MasoliUdaya B. RongalaAlberto MazzoniAnton SpanneHenrik JorntellCalogero M. OddoAlexander V. VartanovAnastasia K. NeklyudovaStanislav A. KozlovskiyAndrey A. KiselnikovJulia A. MarakshinaMaria TeleńczukBartosz TeleńczukAlain DestexhePaula T. KuokkanenAnna KraemerThomas McColganCatherine E. CarrRichard Kempter,,https://link.springer.com/article/10.1186/s12868-017-0372-1,BMC Neuroscience
An Approach to Domain Generic IC with Acceleration of Multi-island GA,10.1007/s11277-018-5446-6,2018,t,x,X4,,Springer Link,,Mo ZhangYunzhou ZhangGang XieGang Zhang,,https://link.springer.com/article/10.1007/s11277-018-5446-6,Wireless Personal Communications
AmbISPDM,10.1007/s10489-017-1030-0,2017,t,x,X4,,Springer Link,,George HatzivasilisIoannis PapaefstathiouDimitris PlexousakisCharalampos ManifavasNikos Papadakis,,https://link.springer.com/article/10.1007/s10489-017-1030-0,Applied Intelligence
The cascading neural network: building the Internet of Smart Things,10.1007/s10115-017-1029-1,2017,t,x,X4,,Springer Link,,Sam LerouxSteven BohezElias De ConinckTim VerbelenBert VankeirsbilckPieter SimoensBart Dhoedt,,https://link.springer.com/article/10.1007/s10115-017-1029-1,Knowledge and Information Systems
Memristors in Unconventional Computing: How a Biomimetic Circuit Element Can be Used to Do Bioinspired Computation,10.1007/978-3-319-33921-4_19,2017,t,x,X4,,Springer Link,,Ella Gale,,https://link.springer.com/chapter/10.1007/978-3-319-33921-4_19,Advances in Unconventional Computing
"Science, technology and the future of small autonomous drones",10.1038/nature14542,2015,t,x,X4,,Springer Link,,Dario FloreanoRobert J. Wood,,https://link.springer.com/article/10.1038/nature14542,Nature
Using Enhanced Patent Data for Future-Oriented Technology Analysis,10.1007/978-3-319-39056-7_7,2016,t,x,X4,,Springer Link,,Christopher L. BensonChristopher L. Magee,,https://link.springer.com/chapter/10.1007/978-3-319-39056-7_7,Anticipating Future Innovation Pathways Through Large Data Analysis
Neural Net to Neuronal Network Memristor Interconnects,10.1007/978-3-319-16844-9_8,2015,t,x,X4,,Springer Link,,Ella GaleAttya IqbalJeffrey DaveyDeborah Gater,,https://link.springer.com/chapter/10.1007/978-3-319-16844-9_8,"Computational Intelligence, Medicine and Biology"
Neuroscience Advances and Future Warfare,10.1007/978-94-007-4707-4_139,2015,t,x,X4,,Springer Link,,Malcolm Dando,,https://link.springer.com/rwe/10.1007/978-94-007-4707-4_139,Handbook of Neuroethics
UAV Horizon Tracking Using Memristors and Cellular Automata Visual Processing,10.1007/978-3-662-43645-5_9,2014,a,x,"X1,X4","uav horizon tracking/detection, not UAV detection",Springer Link,,Ioannis GeorgilasElla GaleAndrew AdamatzkyChris Melhuish,,https://link.springer.com/chapter/10.1007/978-3-662-43645-5_9,Towards Autonomous Robotic Systems
Analysis of <i>Dahlia Mosaic Virus</i> Full-length Transcript Promoter-Driven Gene Expression in Transgenic Plants,10.1007/s11105-014-0738-9,2014,t,x,X4,,Springer Link,,Dipak Kumar SahooShayan SarkarSumita RahaNarayan Chandra DasJoydeep BanerjeeNrisingha DeyIndu B. Maiti,,https://link.springer.com/article/10.1007/s11105-014-0738-9,Plant Molecular Biology Reporter
Digital Consciousness,10.1007/978-3-642-28102-0_14,2012,t,x,X4,,Springer Link,,Ian Watson,,https://link.springer.com/chapter/10.1007/978-3-642-28102-0_14,The Universal Machine
Introduction to Cloud Connectivity,10.1007/978-1-4419-7545-4_1,2011,t,x,X4,,Springer Link,,Lambert SpaanenburgHendrik Spaanenburg,,https://link.springer.com/chapter/10.1007/978-1-4419-7545-4_1,Cloud Connectivity and Embedded Sensory Systems
The Sherrington-Kirkpatrick Model,10.1007/978-3-642-15202-3_1,2011,t,x,X4,,Springer Link,,Michel Talagrand,,https://link.springer.com/chapter/10.1007/978-3-642-15202-3_1,Mean Field Models for Spin Glasses
Extension of <i>Drosophila melanogaster</i> life span with a GPCR peptide inhibitor,10.1038/nchembio.2007.2,2007,t,x,X4,,Springer Link,,William W JaAnthony P West JrSilvia L DelkerPamela J BjorkmanSeymour BenzerRichard W Roberts,,https://link.springer.com/article/10.1038/nchembio.2007.2,Nature Chemical Biology
Basics of Reconfigurable Computing,10.1007/978-1-4020-5869-1_20,2007,t,x,X4,,Springer Link,,Reiner HartensteinTu Kaiserslautern,,https://link.springer.com/chapter/10.1007/978-1-4020-5869-1_20,Designing Embedded Processors
Development of the Drosophila and C. Elegans Neuromuscular Junctions,10.1007/978-0-387-32562-0_4,2006,t,x,X4,,Springer Link,,Heather Van EppsYishi Jin,,https://link.springer.com/chapter/10.1007/978-0-387-32562-0_4,Molecular Mechanisms of Synaptogenesis
"
              <i>PDC2</i>, a yeast gene essential for synthesis of pyruvate decarboxylase, encodes a novel transcription factor",10.1007/BF02927930,1994,t,x,X4,,Springer Link,,V. RaghuramZ. LoboP. K. Maitra,,https://link.springer.com/article/10.1007/BF02927930,Journal of Genetics
Hadron Production in Relativistic Heavy Ion Interactions and the Search for the Quark—Gluon Plasma,10.1007/978-3-642-75289-6_2,1990,t,x,X4,,Springer Link,,M. J. Tannenbaum,,https://link.springer.com/chapter/10.1007/978-3-642-75289-6_2,Quark—Gluon Plasma
Actinide solids 5f dependence of physical properties,10.1007/3-540-13752-1_1,1985,t,x,X4,,Springer Link,,J. M. FournierL. Manes,,https://link.springer.com/chapter/10.1007/3-540-13752-1_1,Actinides — Chemistry and Physical Properties
Centralizer lattices of finite simple groups,10.1007/BF00967150,1977,t,x,X4,,Springer Link,,A. V. Vasil'eva,,https://link.springer.com/article/10.1007/BF00967150,Siberian Mathematical Journal
Vegetabilische Nahrungs- und Genussmittel,10.1007/978-3-662-42042-3_3,1889,t,x,X4,,Springer Link,,J. König,,https://link.springer.com/chapter/10.1007/978-3-662-42042-3_3,Chemische Zusammensetzung der menschlichen Nahrungs- und Genussmittel
Pflanzliche Nahrungs- und Genussmittel,10.1007/978-3-642-90916-0_2,1903,t,x,X4,,Springer Link,,J. König,,https://link.springer.com/chapter/10.1007/978-3-642-90916-0_2,Chemische Zusammensetzung der menschlichen Nahrungs- und Genussmittel
Analyzing the Innovative Thinking and Optimization Strategies of Artificial Intelligence Development from the Wisdom of Thought in the Tao Te Ching,,2025,t,x,X4,,ACM,,"Xiao, Yong; Zhang, Zhenwei","The timeless masterpiece “Tao Te Ching” is one of the greatest works in Chinese history, focusing on the philosophical concept of “morality” and discussing the ways of self-cultivation, governance, military strategy, and health preservation. It mostly focuses on politics and is known as the study of “inner sage and outer king”. Its profound meaning and broad content make it the king of all classics. The Tao Te Ching has had a profound impact on traditional philosophy, science, politics, religion, and more. According to UNESCO statistics, the Tao Te Ching is the cultural masterpiece with the highest number of translations into foreign languages after the Bible. Known as the “source of Chinese culture” and the “king of ten thousand classics”. This article takes an interdisciplinary and historical perspective, using scientific and mathematical analysis methods, to analyze the guiding spirit of the philosophical ideas in the Tao Te Ching for innovative thinking and optimization strategies in the development of artificial intelligence. This article combines artificial intelligence technology to develop the underlying logic of algorithms from four aspects: “Dao follows nature”, “governing by inaction”, “coexistence of existence and non existence”, and “knowing white and guarding black”; Ethical governance architecture for artificial intelligence algorithms; Analyze and elaborate on the future development direction of artificial intelligence in society. Provided new ethical foundations, governance models, and innovative paradigms for the development of artificial intelligence.",https://doi.org/10.1145/3757749.3757841,Proceedings of the 2025 2nd International Conference on Computer and Multimedia Technology
Autonomous driving with spiking neural networks,,2024,t,x,X4,,ACM,,"Zhu, Rui-Jie; Wang, Ziqing; Gilpin, Leilani; Eshraghian, Jason K.","Autonomous driving demands an integrated approach that encompasses perception, prediction, and planning, all while operating under strict energy constraints to enhance scalability and environmental sustainability. We present Spiking Autonomous Driving (SAD), the first unified Spiking Neural Network (SNN) to address the energy challenges faced by autonomous driving systems through its event-driven and energy-efficient nature. SAD is trained end-to-end and consists of three main modules: perception, which processes inputs from multi-view cameras to construct a spatiotemporal bird's eye view; prediction, which utilizes a novel dual-pathway with spiking neurons to forecast future states; and planning, which generates safe trajectories considering predicted occupancy, traffic rules, and ride comfort. Evaluated on the nuScenes dataset, SAD achieves competitive performance in perception, prediction, and planning tasks, while drawing upon the energy efficiency of SNNs. This work highlights the potential of neuromorphic computing to be applied to energy-efficient autonomous driving, a critical step toward sustainable and safety-critical automotive technology. Our code is available at https://github.com/ridgerchu/SAD.",,Proceedings of the 38th International Conference on Neural Information Processing Systems
SoK: efficiency robustness of dynamic deep learning systems,,2025,t,x,X4,,ACM,,"Rathnasuriya, Ravishka; Li, Tingxi; Xu, Zexin; Song, Zihe; Haque, Mirazul; Chen, Simin; Yang, Wei","Deep Learning Systems (DLSs) are increasingly deployed in real-time applications, including those in resource-constrained environments such as mobile and IoT devices. To address efficiency challenges, Dynamic Deep Learning Systems (DDLSs) adapt inference computation based on input complexity, reducing overhead. While this dynamic behavior improves efficiency, such behavior introduces new attack surfaces. In particular, efficiency adversarial attacks exploit these dynamic mechanisms to degrade system performance.This paper systematically explores efficiency robustness of DDLSs, presenting the first comprehensive taxonomy of efficiency attacks. We categorize these attacks based on three dynamic behaviors: (i) attacks on dynamic computations per inference, (ii) attacks on dynamic inference iterations, and (iii) attacks on dynamic output production for downstream tasks. Through an in-depth evaluation, we analyze adversarial strategies that target DDLSs efficiency and identify key challenges in securing these systems. In addition, we investigate existing defense mechanisms, demonstrating their limitations against increasingly popular efficiency attacks and the necessity for novel mitigation strategies to secure future adaptive DDLSs.",,Proceedings of the 34th USENIX Conference on Security Symposium
A pattern for a UAV-aided wireless sensor network,,2021,t,x,X4,,ACM,,"Papa, Rafael; Fernandez, Eduardo B.; Cardei, Mihaela","Energy efficiency is a critical constraint in wireless sensor networks. Wireless sensor networks (WSNs) consist of a large number of battery-powered sensor nodes, connected to each other and equipped with low-power transmission radios. Usually, the sensor nodes closer to the sink are more likely to become overloaded and subject to draining their battery faster than the nodes farther away, creating a funneling effect. The use of a mobile device as a sink node to perform data gathering is a well known solution to balance the energy consumption in the entire network. To address this problem, we consider here the use of a UAV as a mobile sink. An unmanned aircraft vehicle (UAV) is an aircraft without a human pilot on-board, commonly known as Drone. A pattern for a UAV-aided Wireles Sensor Network simplifies the design and implementation of a network with such complexity and makes easy to integrate it with the remaining IT systems. This work presents an example of how this pattern can be applied to implement a mining dam monitoring system to warn and possibly avoid a deadly collapse.",,Proceedings of the 26th Conference on Pattern Languages of Programs
Self-supervised learning of event-based optical flow with spiking neural networks,,2021,t,x,X4,,ACM,,"Hagenaars, Jesse J.; Paredes-Vallés, Federico; de Croon, Guido C. H. E.","The field of neuromorphic computing promises extremely low-power and low-latency sensing and processing. Challenges in transferring learning algorithms from traditional artificial neural networks (ANNs) to spiking neural networks (SNNs) have so far prevented their application to large-scale, complex regression tasks. Furthermore, realizing a truly asynchronous and fully neuromorphic pipeline that maximally attains the abovementioned benefits involves rethinking the way in which this pipeline takes in and accumulates information. In the case of perception, spikes would be passed as-is and one-by-one between an event camera and an SNN, meaning all temporal integration of information must happen inside the network. In this article, we tackle these two problems. We focus on the complex task of learning to estimate optical flow from event-based camera inputs in a self-supervised manner, and modify the state-of-the-art ANN training pipeline to encode minimal temporal information in its inputs. Moreover, we reformulate the self-supervised loss function for event-based optical flow to improve its convexity. We perform experiments with various types of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs, we investigate the effects of elements such as parameter initialization and optimization, surrogate gradient shape, and adaptive neuronal mechanisms. We find that initialization and surrogate gradient width play a crucial part in enabling learning with sparse inputs, while the inclusion of adaptivity and learnable neuronal parameters can improve performance. We show that the performance of the proposed ANNs and SNNs are on par with that of the current state-of-the-art ANNs trained in a self-supervised manner.",,Proceedings of the 35th International Conference on Neural Information Processing Systems
An FPGA-based accelerator for cortical object classification,10.1109/DATE.2012.6176559,2012,a,x,X4,,ACM,,"Park, Mi Sun; Kestur, Srinidhi; Sabarad, Jagdish; Narayanan, Vijaykrishnan; Irwin, Mary Jane","Recently significant advances have been achieved in understanding the visual information processing in the human brain. The focus of this work is on the design of an architecture to support HMAX, a widely accepted model of the human visual pathway. The computationally intensive nature of HMAX and wide applicability in real-time visual analysis application makes the design of hardware accelerators a key necessity. In this work, we propose a configurable accelerator mapped efficiently on a FPGA to realize real-time feature extraction for vision-based classification algorithms. Our innovations include the efficient mapping of the proposed architecture on the FPGA as well as the design of an efficient memory structure. Our evaluation shows that the proposed approach is significantly faster than other contemporary solutions on different platforms.",,"Proceedings of the Conference on Design, Automation and Test in Europe"
Learning optical flow from continuous spike streams,,2022,t,x,X4,,ACM,,"Zhao, Rui; Xiong, Ruiqin; Zhao, Jing; Yu, Zhaofei; Fan, Xiaopeng; Huang, Tiejun","Spike camera is an emerging bio-inspired vision sensor with ultra-high temporal resolution. It records scenes by accumulating photons and outputting continuous binary spike streams. Optical flow is a key task for spike cameras and their applications. A previous attempt has been made for spike-based optical flow. However, the previous work only focuses on motion between two moments, and it uses graphics-based data for training, whose generalization is limited. In this paper, we propose a tailored network, Spike2Flow that extracts information from binary spikes with temporal-spatial representation based on the differential of spike firing time and spatial information aggregation. The network utilizes continuous motion clues through joint correlation decoding. Besides, a new dataset with real-world scenes is proposed for better generalization. Experimental results show that our approach achieves state-of-the-art performance on existing synthetic datasets and real data captured by spike cameras.",,Proceedings of the 36th International Conference on Neural Information Processing Systems
Computational challenges in modeling &amp; simulation of complex systems,,2017,t,x,X4,,ACM,,"Fujimoto, Richard M.; Carothers, Christopher; Ferscha, Alois; Jefferson, David; Loper, Margaret; Marathe, Madhav; Taylor, Simon J. E.","Modeling and simulation faces many new computational challenges in the design of complex engineered systems. The systems that need to be modeled are increasingly interconnected and interdependent, achieving unprecedented levels of complexity. The computational platforms upon which simulations execute have undergone dramatic changes in recent years. Position statements by leading researchers are presented concerning important computational challenges and opportunities facing the M&amp;S community.",,Proceedings of the 2017 Winter Simulation Conference
ALERT-transformer: bridging asynchronous and synchronous machine learning for real-time event-based spatio-temporal data,,2024,f,x,X4,,ACM,,"Martin-Turrero, Carmen; Bouvier, Maxence; Breitenstein, Manuel; Zanuttigh, Pietro; Parret, Vincent","We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models - the ALERT module - that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling rate.",,Proceedings of the 41st International Conference on Machine Learning
Lawyer Up! Joint Introductory Computer Science and Law Courses,,2024,t,x,X4,,ACM,,"Beck, Shannon; Goines, Timothy; Biller, Jeffrey","Courses typically focus on a single discipline, limiting exposure to cross-disciplinary topics. To address this, we designed an interdisciplinary two-course set within our undergraduate Honors program: an introductory computing course and an introductory law course. This initiative breaks down barriers between computing and law, enabling students to integrate both disciplines and foster a comprehensive understanding of complex issues. The Computer Science (CS) course covers introductory programming and principles, while the Law course surveys American Law and basic legal reasoning. Initially, the topics are independent but they strongly converge in the term's second half. Students explore the intersection of CS and Law through discussions, debates, guest speakers, and a cross-disciplinary project. Conducted for two years at the United States Air Force Academy (USAFA), this report shares our curriculum and experiences, aiming to inspire wider adoption of our inter-departmental model.",,J. Comput. Sci. Coll.
Spiking Swin Transformer for UAV Object Detection Based on Event Cameras,10.1109/ISCTech63666.2024.10845340,2024,f,i,,,bf,,"Zhang, Heng; Chen, Nuo; Li, Miao; An, Wei","Unmanned aerial vehicle (UAV) detection tasks have always been a hot issue in the field of computer vision. Event cameras focus solely on the motion within a scene, featuring high dynamic range and low latency. For small UAVs with high speeds, event cameras can acutely perceive their motion information in various complex scenarios. Therefore, in this work, we utilize event cameras to capture event stream motion data of UAVs with low background redundancy. Simultaneously, we combine the Swin Transformer which pays attention to local spatial correlation with the Spiking Neural Network (SNN) which is sensitive to temporal features, and propose an energy-efficient backbone network for spatiotemporal feature extraction of small targets—Spiking Swin Transformer (SST). Utilizing the latest advancements in spike backpropagation research—surrogate gradient learning and Spikingjelly framework, based on Feature Pyramid Networks (FPN) and Single Shot MultiBox Detector (SSD), we propose a motion small target detection algorithm that can be directly trained on event stream datasets with SST as the backbone network. In this paper, we conducted experiments on our self-made event stream UAV object detection dataset and established a new state-of-the-art SNNs detection result.",https://ieeexplore.ieee.org/document/10845340,2024 12th International Conference on Information Systems and Computing Technology (ISCTech)
SA-YOLO: Spike-Driven Attention for Energy-Efficient UAV-Based Small Object Detection,10.1109/JIOT.2025.3596434,2025,f,x,X1,drone view object detection; could work for UAV detection as well but not reported,bf,,"Shen, Yiyu; Liu, Hu; Zha, Keke; Liu, Xu; Ding, Yanan","unmanned aerial vehicles (UAVs) are increasingly employed in Internet of Things (IoT) applications to enable real-time visual perception. However, the limited computational and energy resources available onboard demand low-latency and energy-efficient edge processing. Moreover, the low resolution and scale variation of aerial imagery present significant challenges for accurate object detection. To address these challenges, we propose the spike multi-scale attention YOLO (SA-YOLO), a spiking neural network (SNN)-based object detection model designed for UAV scenarios, which achieves a favorable balance between detection accuracy and energy efficiency. SA-YOLO leverages event-driven, sparse computations that primarily involve addition, significantly reducing energy consumption compared to artificial neural network (ANN)-based methods that rely heavily on multiplication operations. To further improve efficiency, a multiscale attention mechanism (S-MSA) is proposed, which integrates temporal and channel-wise features to enhance informative feature extraction while reducing spike firing rates. Unlike ANN-to-SNN conversion approaches, which transfer pretrained ANNs to the spiking domain and typically require many time steps, the proposed method adopts direct training with spiking neurons and achieves comparable recognition performance using only two time steps, leading to improved energy efficiency and lower computational cost. Experimental results on HIT-UAV and CARPK datasets demonstrate mean average precision (mAP)@0.5 of 87.33% and 95.60% with improved energy efficiency. Our model surpasses mainstream lightweight SNN models in both detection accuracy and computational efficiency, while ensuring robust performance across diverse UAV environments.",https://ieeexplore.ieee.org/document/11115118,IEEE Internet of Things Journal
UAV Detection: A STDP Trained Deep Convolutional Spiking Neural Network Retina-Neuromorphic Approach,10.1007/978-3-030-30487-4_56,2019,f,i,,,bf,,"Kirkland, Paul; Di Caterina, Gaetano; Soraghan, John; Andreopoulos, Yiannis; Matich, George","The Dynamic Vision Sensor (DVS) has many attributes, such as sub-millisecond response time along with a good low light dynamic range, that allows it to be well suited to the task for UAV Detection. This paper proposes a system that exploits the features of an event camera solely for UAV detection while combining it with a Spiking Neural Network (SNN) trained using the unsupervised approach of Spike Time-Dependent Plasticity (STDP), to create an asynchronous, low power system with low computational overhead. Utilising the unique features of both the sensor and the network, this result in a system that is robust to a wide variety in lighting conditions, has a high temporal resolution, propagates only the minimal amount of information through the network, while training using the equivalent of 43,000 images. The network returns a 91% detection rate when shown other objects and can detect a UAV with less than 1% of pixels on the sensor being used for processing.",https://doi.org/10.1007/978-3-030-30487-4_56,"Artificial Neural Networks and Machine Learning – ICANN 2019: Theoretical Neural Computation: 28th International Conference on Artificial Neural Networks, Munich, Germany, September 17–19, 2019, Proceedings, Part I"
Motion feature extraction using magnocellular-inspired spiking neural networks for drone detection,10.3389/fncom.2025.1452203,2025,f,i,,,bf,,"Zheng, Jiayi; Wan, Yaping; Yang, Xin; Zhong, Hua; Du, Minghua; Wang, Gang","Traditional object detection methods usually underperform when locating tiny or small drones against complex backgrounds, since the appearance features of the targets and the backgrounds are highly similar. To address this, inspired by the magnocellular motion processing mechanisms, we proposed to utilize the spatial–temporal characteristics of the flying drones based on spiking neural networks, thereby developing the Magno-Spiking Neural Network (MG-SNN) for drone detection. The MG-SNN can learn to identify potential regions of moving targets through motion saliency estimation and subsequently integrates the information into the popular object detection algorithms to design the retinal-inspired spiking neural network module for drone motion extraction and object detection architecture, which integrates motion and spatial features before object detection to enhance detection accuracy. To design and train the MG-SNN, we propose a new backpropagation method called Dynamic Threshold Multi-frame Spike Time Sequence (DT-MSTS), and establish a dataset for the training and validation of MG-SNN, effectively extracting and updating visual motion features. Experimental results in terms of drone detection performance indicate that the incorporation of MG-SNN significantly improves the accuracy of low-altitude drone detection tasks compared to popular small object detection algorithms, acting as a cheap plug-and-play module in detecting small flying targets against complex backgrounds.",https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2025.1452203/full,Frontiers in Computational Neuroscience
SpikeRF-YOLO for drone radio frequency signal detection,10.1117/12.3067066,2025,f,i,,,bf,,"Liu, Jianyu; Liu, Chao; Si, Zheng; Zhou, Yinhao","Drone detection based on radio frequency (RF) signals has become a mainstream method. Spiking Neural Networks (SNNs), known for their superior energy efficiency and temporal dynamic processing capabilities, provide an ideal solution for drone RF signal detection. We propose SpikeRF-YOLO, an low-power and efficient method for detecting drone RF signals. We designe the full-spike SCDSDown module with shortcut branches to mitigate vanishing gradients, improving spectral feature extraction and downsampling efficiency. To better leverage the diverse frequency characteristics of multidrone RF signals, we propose the ESMS module, which merges multi-scale spectral features to enhance detection performance in complex electromagnetic environments. Experimental results show that SpikeRF-YOLO improves mAP@0.5 by 11.4% and 9.3% on the ZK_RF and DroneRFa datasets, while consuming only 15.9% of the power of YOLOv10 and maintaining comparable performance.",https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13574/135740V/SpikeRF-YOLO-for-drone-radio-frequency-signal-detection/10.1117/12.3067066.full,Fourth International Conference on Electronic Information Engineering and Data Processing (EIEDP 2025)
Event-based Tiny Object Detection: A Benchmark Dataset and Baseline,,,f,i,,,bf,,"Chen, Nuo; Xiao, Chao; Dai, Yimian; He, Shiman; Li, Miao; An, Wei","Small object detection (SOD) in anti-UAV task is a challenging problem due to the small size of UAVs and complex backgrounds. Traditional frame-based cameras struggle to detect small objects in complex environments due to their low frame rates, limited dynamic range, and data redundancy. Event cameras, with microsecond temporal resolution and high dynamic range, provide a more effective solution for SOD. However, existing event-based object detection datasets are limited in scale, feature large targets size, and lack diverse backgrounds, making them unsuitable for SOD benchmarks. In this paper, we introduce a Eventbased Small object detection (EVSOD) dataset (namely EVUAV), the ﬁrst large-scale, highly diverse benchmark for anti-UAV tasks. It includes 147 sequences with over 2.3 million event-level annotations, featuring extremely small targets (averaging 6.8 × 5.4 pixels) and diverse scenarios such as urban clutter and extreme lighting conditions. Furthermore, based on the observation that small moving targets form continuous curves in spatiotemporal event point clouds, we propose Event based Sparse Segmentation Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud space, along with a Spatiotemporal Correlation (STC) loss that leverages motion continuity to guide the network in retaining target events. Extensive experiments on the EV-UAV dataset demonstrate the superiority of our method and provide a benchmark for future research in EVSOD. The dataset and code are at https: //github.com/ChenYichen9527/Ev-UAV .",,
Object Detection using Event Camera: A MoE Heat Conduction based Detector and A New Benchmark Dataset,,2025,f,i,,the anti UAV datatset basically from the arxiv paper → SNN benchmarks CVPR 2025,Anti-uav-wang,,"Xiao Wang, Yu Jin, Wentao Wu, Wei Zhang, Lin Zhu, Bo Jiang, Yonghong Tian",,https://openaccess.thecvf.com/content/CVPR2025/html/Wang_Object_Detection_using_Event_Camera_A_MoE_Heat_Conduction_based_CVPR_2025_paper.html,